{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tools.torch_lib import *\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "from torchmetrics.regression import MeanAbsolutePercentageError"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "gpu = torch.device('cuda')\n",
    "cpu = torch.device('cpu')\n",
    "device = cpu\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = gpu\n",
    "    # The flag below controls whether to allow TF32 on matmul. This flag defaults to False\n",
    "    # in PyTorch 1.12 and later.\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    # The flag below controls whether to allow TF32 on cuDNN. This flag defaults to True.\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "dataset_dir = \"dataset/\"\n",
    "dataset_file_name = \"1D_2A.csv\"\n",
    "plots_dir = \"plots/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "   ro_well  ro_formation  kanisotrop   A02M01N   A04M01N   A10M01N   A20M05N  \\\n0     0.01           0.1         1.0  0.110922  0.134909  0.118898  0.105459   \n1     0.01           0.1         1.0  0.107744  0.134384  0.120232  0.105946   \n2     0.01           0.1         1.0  0.104604  0.133653  0.121536  0.106451   \n3     0.01           0.1         1.0  0.101519  0.132742  0.122802  0.106971   \n4     0.01           0.1         1.0  0.098501  0.131673  0.124024  0.107506   \n\n    A40M05N   A80M10N  rad_well  \n0  0.101749  0.100513     0.040  \n1  0.101906  0.100559     0.042  \n2  0.102069  0.100607     0.044  \n3  0.102238  0.100657     0.046  \n4  0.102412  0.100709     0.048  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ro_well</th>\n      <th>ro_formation</th>\n      <th>kanisotrop</th>\n      <th>A02M01N</th>\n      <th>A04M01N</th>\n      <th>A10M01N</th>\n      <th>A20M05N</th>\n      <th>A40M05N</th>\n      <th>A80M10N</th>\n      <th>rad_well</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.01</td>\n      <td>0.1</td>\n      <td>1.0</td>\n      <td>0.110922</td>\n      <td>0.134909</td>\n      <td>0.118898</td>\n      <td>0.105459</td>\n      <td>0.101749</td>\n      <td>0.100513</td>\n      <td>0.040</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.01</td>\n      <td>0.1</td>\n      <td>1.0</td>\n      <td>0.107744</td>\n      <td>0.134384</td>\n      <td>0.120232</td>\n      <td>0.105946</td>\n      <td>0.101906</td>\n      <td>0.100559</td>\n      <td>0.042</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.01</td>\n      <td>0.1</td>\n      <td>1.0</td>\n      <td>0.104604</td>\n      <td>0.133653</td>\n      <td>0.121536</td>\n      <td>0.106451</td>\n      <td>0.102069</td>\n      <td>0.100607</td>\n      <td>0.044</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.01</td>\n      <td>0.1</td>\n      <td>1.0</td>\n      <td>0.101519</td>\n      <td>0.132742</td>\n      <td>0.122802</td>\n      <td>0.106971</td>\n      <td>0.102238</td>\n      <td>0.100657</td>\n      <td>0.046</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.01</td>\n      <td>0.1</td>\n      <td>1.0</td>\n      <td>0.098501</td>\n      <td>0.131673</td>\n      <td>0.124024</td>\n      <td>0.107506</td>\n      <td>0.102412</td>\n      <td>0.100709</td>\n      <td>0.048</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(dataset_dir + dataset_file_name)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "         ro_well  ro_formation  kanisotrop    A04M01N     A10M01N  \\\n0        0.01000           0.1         1.0   0.134909    0.118898   \n1        0.01000           0.1         1.0   0.134384    0.120232   \n2        0.01000           0.1         1.0   0.133653    0.121536   \n3        0.01000           0.1         1.0   0.132742    0.122802   \n4        0.01000           0.1         1.0   0.131673    0.124024   \n...          ...           ...         ...        ...         ...   \n1184113  3.16228       10000.0         5.0  72.021300  377.083000   \n1184114  3.16228       10000.0         5.0  62.264400  327.135000   \n1184115  3.16228       10000.0         5.0  54.364500  286.489000   \n1184116  3.16228       10000.0         5.0  40.133700  212.736000   \n1184117  3.16228       10000.0         5.0  30.857400  164.185000   \n\n             A20M05N      A40M05N       A80M10N  rad_well  \n0           0.105459     0.101749      0.100513     0.040  \n1           0.105946     0.101906      0.100559     0.042  \n2           0.106451     0.102069      0.100607     0.044  \n3           0.106971     0.102238      0.100657     0.046  \n4           0.107506     0.102412      0.100709     0.048  \n...              ...          ...           ...       ...  \n1184113  1556.150000  4787.300000  13859.000000     0.130  \n1184114  1359.080000  4226.380000  12506.000000     0.140  \n1184115  1197.160000  3757.950000  11334.100000     0.150  \n1184116   899.431000  2877.150000   9017.940000     0.175  \n1184117   700.325000  2272.420000   7333.120000     0.200  \n\n[1184118 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ro_well</th>\n      <th>ro_formation</th>\n      <th>kanisotrop</th>\n      <th>A04M01N</th>\n      <th>A10M01N</th>\n      <th>A20M05N</th>\n      <th>A40M05N</th>\n      <th>A80M10N</th>\n      <th>rad_well</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.01000</td>\n      <td>0.1</td>\n      <td>1.0</td>\n      <td>0.134909</td>\n      <td>0.118898</td>\n      <td>0.105459</td>\n      <td>0.101749</td>\n      <td>0.100513</td>\n      <td>0.040</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.01000</td>\n      <td>0.1</td>\n      <td>1.0</td>\n      <td>0.134384</td>\n      <td>0.120232</td>\n      <td>0.105946</td>\n      <td>0.101906</td>\n      <td>0.100559</td>\n      <td>0.042</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.01000</td>\n      <td>0.1</td>\n      <td>1.0</td>\n      <td>0.133653</td>\n      <td>0.121536</td>\n      <td>0.106451</td>\n      <td>0.102069</td>\n      <td>0.100607</td>\n      <td>0.044</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.01000</td>\n      <td>0.1</td>\n      <td>1.0</td>\n      <td>0.132742</td>\n      <td>0.122802</td>\n      <td>0.106971</td>\n      <td>0.102238</td>\n      <td>0.100657</td>\n      <td>0.046</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.01000</td>\n      <td>0.1</td>\n      <td>1.0</td>\n      <td>0.131673</td>\n      <td>0.124024</td>\n      <td>0.107506</td>\n      <td>0.102412</td>\n      <td>0.100709</td>\n      <td>0.048</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1184113</th>\n      <td>3.16228</td>\n      <td>10000.0</td>\n      <td>5.0</td>\n      <td>72.021300</td>\n      <td>377.083000</td>\n      <td>1556.150000</td>\n      <td>4787.300000</td>\n      <td>13859.000000</td>\n      <td>0.130</td>\n    </tr>\n    <tr>\n      <th>1184114</th>\n      <td>3.16228</td>\n      <td>10000.0</td>\n      <td>5.0</td>\n      <td>62.264400</td>\n      <td>327.135000</td>\n      <td>1359.080000</td>\n      <td>4226.380000</td>\n      <td>12506.000000</td>\n      <td>0.140</td>\n    </tr>\n    <tr>\n      <th>1184115</th>\n      <td>3.16228</td>\n      <td>10000.0</td>\n      <td>5.0</td>\n      <td>54.364500</td>\n      <td>286.489000</td>\n      <td>1197.160000</td>\n      <td>3757.950000</td>\n      <td>11334.100000</td>\n      <td>0.150</td>\n    </tr>\n    <tr>\n      <th>1184116</th>\n      <td>3.16228</td>\n      <td>10000.0</td>\n      <td>5.0</td>\n      <td>40.133700</td>\n      <td>212.736000</td>\n      <td>899.431000</td>\n      <td>2877.150000</td>\n      <td>9017.940000</td>\n      <td>0.175</td>\n    </tr>\n    <tr>\n      <th>1184117</th>\n      <td>3.16228</td>\n      <td>10000.0</td>\n      <td>5.0</td>\n      <td>30.857400</td>\n      <td>164.185000</td>\n      <td>700.325000</td>\n      <td>2272.420000</td>\n      <td>7333.120000</td>\n      <td>0.200</td>\n    </tr>\n  </tbody>\n</table>\n<p>1184118 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['ro_well', 'ro_formation', 'kanisotrop', 'A02M01N', 'A04M01N',\n       'A10M01N', 'A20M05N', 'A40M05N', 'A80M10N', 'rad_well'],\n      dtype='object')"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# print attribute's min max"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ro_well: min=0.01 max=3.16228\n",
      "ro_formation: min=0.1 max=10000.0\n",
      "kanisotrop: min=1.0 max=5.0\n",
      "A02M01N: min=0.0201144 max=221.578\n",
      "A04M01N: min=0.042906 max=700.451\n",
      "A10M01N: min=0.0910916 max=3299.02\n",
      "A20M05N: min=0.0945373 max=11120.5\n",
      "A40M05N: min=0.0976365 max=24778.3\n",
      "A80M10N: min=0.0991788 max=38051.0\n",
      "rad_well: min=0.04 max=0.2\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(f\"{column}: min={df[column].min()} max={df[column].max()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ro_well, ro_formation correlation=7.871373887361991e-17\n"
     ]
    }
   ],
   "source": [
    "print(f\"ro_well, ro_formation correlation=\"\n",
    "      f\"{np.corrcoef(df['ro_well'].to_numpy(), df['ro_formation'].to_numpy())[1][0]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ro_well: log_min=-4.605170185988091 log_max=1.1512932864164753 mean=0.5898747846153845 std=0.8332104926178117\n",
      "ro_formation: log_min=-2.3025850929940455 log_max=9.210340371976184 mean=953.3484185098038 std=2098.6398911467427\n",
      "kanisotrop: log_min=0.0 log_max=1.6094379124341003 mean=2.183226068969074 std=1.276033218172284\n",
      "A02M01N: log_min=-3.9063193025114678 log_max=5.4007746719664045 mean=6.371209325846917 std=14.800333932490414\n",
      "A04M01N: log_min=-3.1487436026878233 log_max=6.551724413294755 mean=17.46536963673781 std=43.020996417288764\n",
      "A10M01N: log_min=-2.3958896853341227 log_max=8.10138073365337 mean=67.88229960240388 std=179.56774512510788\n",
      "A20M05N: log_min=-2.3587608133648343 log_max=9.316545530822498 mean=202.81547035922395 std=562.7142969127794\n",
      "A40M05N: log_min=-2.326503880064628 log_max=10.11772354911712 mean=457.00361950074904 std=1288.8514523369136\n",
      "A80M10N: log_min=-2.3108309972078964 log_max=10.546682644153423 mean=931.5971180226402 std=2574.9932316569184\n",
      "rad_well: log_min=-3.2188758248682006 log_max=-1.6094379124341003 mean=0.08936170212765956 std=0.03429870385983213\n"
     ]
    }
   ],
   "source": [
    "# attributes in logarithmic scale:\n",
    "for column in df.columns:\n",
    "    if column == 'd_well':\n",
    "        continue\n",
    "    col_data = df[column].to_numpy()\n",
    "    print(f\"{column}: log_min={np.log(col_data.min())} log_max={np.log(col_data.max())} mean={np.mean(col_data)} std={np.std(col_data)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "   ro_well  ro_formation  kanisotrop   A04M01N   A10M01N   A20M05N   A40M05N  \\\n0     0.01           0.1         1.0  0.134909  0.118898  0.105459  0.101749   \n1     0.01           0.1         1.0  0.134384  0.120232  0.105946  0.101906   \n2     0.01           0.1         1.0  0.133653  0.121536  0.106451  0.102069   \n3     0.01           0.1         1.0  0.132742  0.122802  0.106971  0.102238   \n4     0.01           0.1         1.0  0.131673  0.124024  0.107506  0.102412   \n\n    A80M10N  rad_well  \n0  0.100513     0.040  \n1  0.100559     0.042  \n2  0.100607     0.044  \n3  0.100657     0.046  \n4  0.100709     0.048  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ro_well</th>\n      <th>ro_formation</th>\n      <th>kanisotrop</th>\n      <th>A04M01N</th>\n      <th>A10M01N</th>\n      <th>A20M05N</th>\n      <th>A40M05N</th>\n      <th>A80M10N</th>\n      <th>rad_well</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.01</td>\n      <td>0.1</td>\n      <td>1.0</td>\n      <td>0.134909</td>\n      <td>0.118898</td>\n      <td>0.105459</td>\n      <td>0.101749</td>\n      <td>0.100513</td>\n      <td>0.040</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.01</td>\n      <td>0.1</td>\n      <td>1.0</td>\n      <td>0.134384</td>\n      <td>0.120232</td>\n      <td>0.105946</td>\n      <td>0.101906</td>\n      <td>0.100559</td>\n      <td>0.042</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.01</td>\n      <td>0.1</td>\n      <td>1.0</td>\n      <td>0.133653</td>\n      <td>0.121536</td>\n      <td>0.106451</td>\n      <td>0.102069</td>\n      <td>0.100607</td>\n      <td>0.044</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.01</td>\n      <td>0.1</td>\n      <td>1.0</td>\n      <td>0.132742</td>\n      <td>0.122802</td>\n      <td>0.106971</td>\n      <td>0.102238</td>\n      <td>0.100657</td>\n      <td>0.046</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.01</td>\n      <td>0.1</td>\n      <td>1.0</td>\n      <td>0.131673</td>\n      <td>0.124024</td>\n      <td>0.107506</td>\n      <td>0.102412</td>\n      <td>0.100709</td>\n      <td>0.048</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes_to_drop = ['A02M01N']\n",
    "df.drop(attributes_to_drop, axis=1, inplace=True)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add dataframe transforms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "inputs = np.array(['ro_well', 'ro_formation', 'rad_well', 'kanisotrop'])\n",
    "outputs = np.array(['A04M01N', 'A10M01N', 'A20M05N', 'A40M05N', 'A80M10N']) # 'A02M01N' dropped"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "         ro_well  ro_formation  kanisotrop   A04M01N   A10M01N   A20M05N  \\\n0           -1.0          -1.0        -1.0 -0.763808 -0.949244 -0.981272   \n1           -1.0          -1.0        -1.0 -0.764611 -0.947118 -0.980483   \n2           -1.0          -1.0        -1.0 -0.765736 -0.945063 -0.979668   \n3           -1.0          -1.0        -1.0 -0.767146 -0.943088 -0.978833   \n4           -1.0          -1.0        -1.0 -0.768813 -0.941202 -0.977979   \n...          ...           ...         ...       ...       ...       ...   \n1184113      1.0           1.0         1.0  0.530999  0.586766  0.663122   \n1184114      1.0           1.0         1.0  0.500986  0.559694  0.639927   \n1184115      1.0           1.0         1.0  0.473012  0.534416  0.618196   \n1184116      1.0           1.0         1.0  0.410439  0.477706  0.569213   \n1184117      1.0           1.0         1.0  0.356248  0.428349  0.526351   \n\n          A40M05N   A80M10N  rad_well  \n0       -0.993369 -0.997921   -1.0000  \n1       -0.993121 -0.997850   -0.9750  \n2       -0.992865 -0.997776   -0.9500  \n3       -0.992599 -0.997699   -0.9250  \n4       -0.992325 -0.997618   -0.9000  \n...           ...       ...       ...  \n1184113  0.735781  0.842895    0.1250  \n1184114  0.715752  0.826915    0.2500  \n1184115  0.696872  0.811610    0.3750  \n1184116  0.653949  0.776051    0.6875  \n1184117  0.616027  0.743881    1.0000  \n\n[1184118 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ro_well</th>\n      <th>ro_formation</th>\n      <th>kanisotrop</th>\n      <th>A04M01N</th>\n      <th>A10M01N</th>\n      <th>A20M05N</th>\n      <th>A40M05N</th>\n      <th>A80M10N</th>\n      <th>rad_well</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-0.763808</td>\n      <td>-0.949244</td>\n      <td>-0.981272</td>\n      <td>-0.993369</td>\n      <td>-0.997921</td>\n      <td>-1.0000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-0.764611</td>\n      <td>-0.947118</td>\n      <td>-0.980483</td>\n      <td>-0.993121</td>\n      <td>-0.997850</td>\n      <td>-0.9750</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-0.765736</td>\n      <td>-0.945063</td>\n      <td>-0.979668</td>\n      <td>-0.992865</td>\n      <td>-0.997776</td>\n      <td>-0.9500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-0.767146</td>\n      <td>-0.943088</td>\n      <td>-0.978833</td>\n      <td>-0.992599</td>\n      <td>-0.997699</td>\n      <td>-0.9250</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-0.768813</td>\n      <td>-0.941202</td>\n      <td>-0.977979</td>\n      <td>-0.992325</td>\n      <td>-0.997618</td>\n      <td>-0.9000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1184113</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.530999</td>\n      <td>0.586766</td>\n      <td>0.663122</td>\n      <td>0.735781</td>\n      <td>0.842895</td>\n      <td>0.1250</td>\n    </tr>\n    <tr>\n      <th>1184114</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.500986</td>\n      <td>0.559694</td>\n      <td>0.639927</td>\n      <td>0.715752</td>\n      <td>0.826915</td>\n      <td>0.2500</td>\n    </tr>\n    <tr>\n      <th>1184115</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.473012</td>\n      <td>0.534416</td>\n      <td>0.618196</td>\n      <td>0.696872</td>\n      <td>0.811610</td>\n      <td>0.3750</td>\n    </tr>\n    <tr>\n      <th>1184116</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.410439</td>\n      <td>0.477706</td>\n      <td>0.569213</td>\n      <td>0.653949</td>\n      <td>0.776051</td>\n      <td>0.6875</td>\n    </tr>\n    <tr>\n      <th>1184117</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.356248</td>\n      <td>0.428349</td>\n      <td>0.526351</td>\n      <td>0.616027</td>\n      <td>0.743881</td>\n      <td>1.0000</td>\n    </tr>\n  </tbody>\n</table>\n<p>1184118 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logarithmic_columns = ['ro_formation', 'ro_well']\n",
    "# normalize data ('min/max' normalization):\n",
    "interval_th = [-1, 1]     # normalization interval for 'th' activation function\n",
    "interval_sigmoid = [0, 1] # normalization interval for 'sigmoid' activation function\n",
    "normalize_interval = interval_th\n",
    "\n",
    "attributes_transform_dict = {}\n",
    "df_transformed = df.copy()\n",
    "\n",
    "# transform output attributes:\n",
    "for output_attr in outputs:\n",
    "    attr_transformer = attributes_transform_dict[output_attr] = AttributeTransformer(df_transformed[output_attr].to_numpy())\n",
    "\n",
    "    # logarithmic transform\n",
    "    forward, backward = np.log, np.exp\n",
    "    df_transformed[output_attr] = attr_transformer.transform(forward, backward)\n",
    "    # scaling transform\n",
    "    forward, backward = get_standard_scaler_transform(attr_transformer.data)\n",
    "    df_transformed[output_attr] = attr_transformer.transform(forward, backward)\n",
    "    # normalize transform\n",
    "    forward, backward = get_normalize_transforms(attr_transformer.data, normalize_interval)\n",
    "    df_transformed[output_attr] = attr_transformer.transform(forward, backward)\n",
    "\n",
    "# logarithm resistance:\n",
    "for col in logarithmic_columns:\n",
    "    if col in outputs:\n",
    "        continue\n",
    "    df_transformed[col] = df_transformed[col].apply(np.log)\n",
    "\n",
    "# add normalization\n",
    "for attribute in df_transformed.columns:\n",
    "    if attribute in outputs:\n",
    "        continue\n",
    "    transform, _ = get_standard_scaler_transform(df_transformed[attribute].to_numpy())\n",
    "    df_transformed[attribute] = transform(df_transformed[attribute].to_numpy())\n",
    "\n",
    "    transform, _ = get_normalize_transforms(df_transformed[attribute].to_numpy(), normalize_interval)\n",
    "    df_transformed[attribute] = transform(df_transformed[attribute].to_numpy())\n",
    "\n",
    "df_transformed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ro_well: mean=-1.7269386497605308 std=1.7269388050893328\n",
      "ro_well: min=-1.6666667792427492 max=1.666667010837201\n",
      "ro_formation: mean=3.4538777271899646 std=3.389313407249595\n",
      "ro_formation: min=-1.6984156165290543 max=1.6984155647788115\n",
      "kanisotrop: mean=2.183226068969074 std=1.276033218172284\n",
      "kanisotrop: min=-0.9272690178582171 max=2.207445614202356\n",
      "A04M01N: mean=1.1696066630906665 std=1.8981222952922183\n",
      "A04M01N: min=-2.2750642972209936 max=2.835495775774292\n",
      "A10M01N: mean=2.1549688040161925 std=2.255211124359088\n",
      "A10M01N: min=-2.0179301353187635 max=2.636742904204633\n",
      "A20M05N: mean=2.8295580213737046 std=2.6552511938592653\n",
      "A20M05N: min=-1.953984183017199 max=2.4430786527659194\n",
      "A40M05N: mean=3.2474607202004897 std=3.0011638205846554\n",
      "A40M05N: min=-1.8572676912982564 max=2.289199537124314\n",
      "A80M10N: mean=3.547436036617802 std=3.3244960293369976\n",
      "A80M10N: min=-1.7621519117873663 max=2.105355682717262\n",
      "rad_well: mean=0.08936170212765956 std=0.03429870385983213\n",
      "rad_well: min=-1.4391710639966195 max=3.225728246888976\n"
     ]
    }
   ],
   "source": [
    "# print statistic data for inference transforms:\n",
    "for column in df.columns:\n",
    "    col_data = df[column].to_numpy()\n",
    "\n",
    "    if column in logarithmic_columns or column in outputs:\n",
    "        col_data = np.log(col_data) # first transform - log\n",
    "\n",
    "    col_mean = np.mean(col_data)\n",
    "    col_std = np.std(col_data)\n",
    "\n",
    "    print(f\"{column}: mean={col_mean} std={col_std}\")\n",
    "    col_data = (col_data - col_mean) / col_std\n",
    "    print(f\"{column}: min={np.min(col_data)} max={np.max(col_data)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def print_inference_statistic(attributes, df_):\n",
    "    means = []\n",
    "    stds = []\n",
    "    mins = []\n",
    "    maxes = []\n",
    "\n",
    "    for column in attributes:\n",
    "        col_data = df_[column].to_numpy()\n",
    "\n",
    "        if column in logarithmic_columns or column in outputs:\n",
    "            col_data = np.log(col_data) # first transform - log\n",
    "\n",
    "        col_mean = np.mean(col_data)\n",
    "        col_std = np.std(col_data)\n",
    "\n",
    "        means.append(col_mean)\n",
    "        stds.append(col_std)\n",
    "\n",
    "        col_data = (col_data - col_mean) / col_std\n",
    "\n",
    "        mins.append(np.min(col_data))\n",
    "        maxes.append(np.max(col_data))\n",
    "\n",
    "    print(f\"means={means}\")\n",
    "    print(f\"stds={stds}\")\n",
    "    print(f\"mins={mins}\")\n",
    "    print(f\"maxes={maxes}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means=[-1.7269386497605308, 3.4538777271899646, 0.08936170212765956, 2.183226068969074]\n",
      "stds=[1.7269388050893328, 3.389313407249595, 0.03429870385983213, 1.276033218172284]\n",
      "mins=[-1.6666667792427492, -1.6984156165290543, -1.4391710639966195, -0.9272690178582171]\n",
      "maxes=[1.666667010837201, 1.6984155647788115, 3.225728246888976, 2.207445614202356]\n"
     ]
    }
   ],
   "source": [
    "print_inference_statistic(inputs, df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means=[1.1696066630906665, 2.1549688040161925, 2.8295580213737046, 3.2474607202004897, 3.547436036617802]\n",
      "stds=[1.8981222952922183, 2.255211124359088, 2.6552511938592653, 3.0011638205846554, 3.3244960293369976]\n",
      "mins=[-2.2750642972209936, -2.0179301353187635, -1.953984183017199, -1.8572676912982564, -1.7621519117873663]\n",
      "maxes=[2.835495775774292, 2.636742904204633, 2.4430786527659194, 2.289199537124314, 2.105355682717262]\n"
     ]
    }
   ],
   "source": [
    "print_inference_statistic(outputs, df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build Datasets and create dataloaders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, df_, inputs, outputs, device):\n",
    "        self.df = df_\n",
    "        self.inputs = torch.from_numpy(df_[inputs].to_numpy()).float().to(device)\n",
    "        self.outputs = torch.from_numpy(df_[outputs].to_numpy()).float().to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item, label = self.inputs[idx], self.outputs[idx]\n",
    "\n",
    "        return item, label\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "train_df, test_df = train_test_split(df_transformed, shuffle=True, test_size=0.3)\n",
    "\n",
    "train_dataset = SimpleDataset(train_df, inputs, outputs, device)\n",
    "test_dataset = SimpleDataset(test_df, inputs, outputs, device)\n",
    "full_dataset = SimpleDataset(df_transformed, inputs, outputs, device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "full_dataset_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "class WeightedMAE(nn.Module):\n",
    "    def __init__(self, weights):\n",
    "        super(WeightedMAE, self).__init__()\n",
    "        self.mae = nn.L1Loss()\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        weighted_inputs = inputs * self.weights\n",
    "\n",
    "        return self.mae(weighted_inputs, targets)\n",
    "\n",
    "    def to(self, device):\n",
    "        super().to(device)\n",
    "        self.weights = self.weights.to(device)\n",
    "\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, layers_dims, act_str_list, output_dim):\n",
    "        super().__init__()\n",
    "        layers_count = len(layers_dims)\n",
    "        assert layers_count > 0\n",
    "\n",
    "        module_list = []\n",
    "        for i in range(layers_count - 1):\n",
    "            module_list.append(nn.Linear(layers_dims[i], layers_dims[i + 1]))\n",
    "        module_list.append(nn.Linear(layers_dims[layers_count - 1], output_dim))\n",
    "\n",
    "        activations_list = []\n",
    "        for i in range(layers_count):\n",
    "            activations_list.append(activations[act_str_list[i]])\n",
    "\n",
    "        self.linears = nn.ModuleList(module_list)\n",
    "        self.activations = nn.ModuleList(activations_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "\n",
    "        for lin, act in zip(self.linears, self.activations):\n",
    "            y = lin(y)\n",
    "            y = act(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class LinearLNormModel(nn.Module):\n",
    "    def __init__(self, layers_dims, act_str_list, output_dim):\n",
    "        super().__init__()\n",
    "        layers_count = len(layers_dims)\n",
    "        assert layers_count > 0\n",
    "\n",
    "        linears_list = []\n",
    "        layers_norm_list = []\n",
    "\n",
    "        for i in range(layers_count - 1):\n",
    "            in_features, out_features = layers_dims[i], layers_dims[i + 1]\n",
    "            linears_list.append(nn.Linear(in_features, out_features))\n",
    "            layers_norm_list.append(nn.LayerNorm(out_features))\n",
    "        # add last layer\n",
    "        linears_list.append(nn.Linear(layers_dims[layers_count - 1], output_dim))\n",
    "        layers_norm_list.append(nn.LayerNorm(output_dim))\n",
    "\n",
    "        self.linears = nn.ModuleList(linears_list)\n",
    "        self.activations = nn.ModuleList([activations[act_str_list[i]] for i in range(len(act_str_list))])\n",
    "        self.layer_normalizations = nn.ModuleList(layers_norm_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "\n",
    "        for lin, act, norm in zip(self.linears, self.activations, self.layer_normalizations):\n",
    "            y = lin(y)\n",
    "            y = norm(y)\n",
    "            y = act(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "# add batch normalization\n",
    "class LinearBNormModel(nn.Module):\n",
    "    def __init__(self, layers_dims, act_str_list, output_dim):\n",
    "        super().__init__()\n",
    "        layers_count = len(layers_dims)\n",
    "        assert layers_count > 0\n",
    "\n",
    "        linears_list = []\n",
    "        batch_norm_list = []\n",
    "\n",
    "        for i in range(layers_count - 1):\n",
    "            in_features, out_features = layers_dims[i], layers_dims[i + 1]\n",
    "            linears_list.append(nn.Linear(in_features, out_features))\n",
    "            batch_norm_list.append(nn.BatchNorm1d(out_features))\n",
    "\n",
    "        linears_list.append(nn.Linear(layers_dims[layers_count - 1], output_dim))\n",
    "        batch_norm_list.append(nn.BatchNorm1d(output_dim))\n",
    "\n",
    "        activations_list = []\n",
    "        for i in range(layers_count):\n",
    "            activations_list.append(activations[act_str_list[i]])\n",
    "\n",
    "        self.linears = nn.ModuleList(linears_list)\n",
    "        self.activations = nn.ModuleList(activations_list)\n",
    "        self.batch_normalizations = nn.ModuleList(batch_norm_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "\n",
    "        for lin, act, norm in zip(self.linears, self.activations, self.batch_normalizations):\n",
    "            y = lin(y)\n",
    "            y = norm(y)\n",
    "            y = act(y)\n",
    "\n",
    "        return y\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "LinearModel(\n  (linears): ModuleList(\n    (0): Linear(in_features=4, out_features=40, bias=True)\n    (1): Linear(in_features=40, out_features=120, bias=True)\n    (2): Linear(in_features=120, out_features=1200, bias=True)\n    (3): Linear(in_features=1200, out_features=120, bias=True)\n    (4): Linear(in_features=120, out_features=50, bias=True)\n    (5): Linear(in_features=50, out_features=5, bias=True)\n  )\n  (activations): ModuleList(\n    (0-5): 6 x LeakyReLU(negative_slope=0.01)\n  )\n)"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_dims = [len(inputs), 40, 120, 1200, 120, 50]\n",
    "layers_count = len(layers_dims)\n",
    "activations_string_list = ['leaky-relu' for i in range(layers_count)]\n",
    "#activations_string_list[-1] = 'sigmoid'\n",
    "\n",
    "linear_model = LinearModel(layers_dims, activations_string_list, len(outputs)).to(device)\n",
    "#linear_bn_model = LinearBNormModel(layers_dims, activations_string_list, len(outputs)).to(device)\n",
    "#linear_ln_model = LinearLNormModel(layers_dims, activations_string_list, len(outputs)).to(device)\n",
    "\n",
    "model = linear_model\n",
    "model_name = \"linear_model\"\n",
    "linear_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "epoch_count = 1500\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#loss_function = WeightedMAE(torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0], dtype=float))\n",
    "loss_function = nn.L1Loss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; train loss=0.248373; validation loss=0.085334\n",
      "Epoch: 1; train loss=0.056940; validation loss=0.051239\n",
      "Epoch: 2; train loss=0.049298; validation loss=0.046200\n",
      "Epoch: 3; train loss=0.037637; validation loss=0.025714\n",
      "Epoch: 4; train loss=0.020479; validation loss=0.017020\n",
      "Epoch: 5; train loss=0.015683; validation loss=0.014307\n",
      "Epoch: 6; train loss=0.014397; validation loss=0.013656\n",
      "Epoch: 7; train loss=0.013252; validation loss=0.012904\n",
      "Epoch: 8; train loss=0.012287; validation loss=0.012338\n",
      "Epoch: 9; train loss=0.011650; validation loss=0.011171\n",
      "Epoch: 10; train loss=0.010885; validation loss=0.011375\n",
      "Epoch: 11; train loss=0.010172; validation loss=0.010646\n",
      "Epoch: 12; train loss=0.009418; validation loss=0.011976\n",
      "Epoch: 13; train loss=0.009227; validation loss=0.008275\n",
      "Epoch: 14; train loss=0.008718; validation loss=0.008296\n",
      "Epoch: 15; train loss=0.008375; validation loss=0.007806\n",
      "Epoch: 16; train loss=0.008171; validation loss=0.007232\n",
      "Epoch: 17; train loss=0.007664; validation loss=0.007175\n",
      "Epoch: 18; train loss=0.007303; validation loss=0.007156\n",
      "Epoch: 19; train loss=0.007208; validation loss=0.007299\n",
      "Epoch: 20; train loss=0.007154; validation loss=0.007518\n",
      "Epoch: 21; train loss=0.006646; validation loss=0.006193\n",
      "Epoch: 22; train loss=0.006536; validation loss=0.006391\n",
      "Epoch: 23; train loss=0.006513; validation loss=0.006971\n",
      "Epoch: 24; train loss=0.006102; validation loss=0.005526\n",
      "Epoch: 25; train loss=0.006165; validation loss=0.006343\n",
      "Epoch: 26; train loss=0.005903; validation loss=0.005272\n",
      "Epoch: 27; train loss=0.005703; validation loss=0.006746\n",
      "Epoch: 28; train loss=0.005619; validation loss=0.005532\n",
      "Epoch: 29; train loss=0.005357; validation loss=0.006086\n",
      "Epoch: 30; train loss=0.005409; validation loss=0.004650\n",
      "Epoch: 31; train loss=0.005248; validation loss=0.004592\n",
      "Epoch: 32; train loss=0.005031; validation loss=0.004981\n",
      "Epoch: 33; train loss=0.004983; validation loss=0.005059\n",
      "Epoch: 34; train loss=0.005071; validation loss=0.005204\n",
      "Epoch: 35; train loss=0.004762; validation loss=0.004356\n",
      "Epoch: 36; train loss=0.004721; validation loss=0.004706\n",
      "Epoch: 37; train loss=0.004682; validation loss=0.004056\n",
      "Epoch: 38; train loss=0.004617; validation loss=0.005071\n",
      "Epoch: 39; train loss=0.004599; validation loss=0.004108\n",
      "Epoch: 40; train loss=0.004440; validation loss=0.004812\n",
      "Epoch: 41; train loss=0.004301; validation loss=0.003917\n",
      "Epoch: 42; train loss=0.004398; validation loss=0.004563\n",
      "Epoch: 43; train loss=0.004173; validation loss=0.003872\n",
      "Epoch: 44; train loss=0.004159; validation loss=0.006402\n",
      "Epoch: 45; train loss=0.004299; validation loss=0.003741\n",
      "Epoch: 46; train loss=0.004078; validation loss=0.004313\n",
      "Epoch: 47; train loss=0.003927; validation loss=0.003955\n",
      "Epoch: 48; train loss=0.004036; validation loss=0.003495\n",
      "Epoch: 49; train loss=0.003795; validation loss=0.003607\n",
      "Epoch: 50; train loss=0.004074; validation loss=0.003371\n",
      "Epoch: 51; train loss=0.003609; validation loss=0.003389\n",
      "Epoch: 52; train loss=0.003788; validation loss=0.003629\n",
      "Epoch: 53; train loss=0.003727; validation loss=0.004581\n",
      "Epoch: 54; train loss=0.003691; validation loss=0.004186\n",
      "Epoch: 55; train loss=0.003517; validation loss=0.003560\n",
      "Epoch: 56; train loss=0.003640; validation loss=0.004105\n",
      "Epoch: 57; train loss=0.003649; validation loss=0.003662\n",
      "Epoch: 58; train loss=0.003429; validation loss=0.003330\n",
      "Epoch: 59; train loss=0.003485; validation loss=0.002916\n",
      "Epoch: 60; train loss=0.003428; validation loss=0.003223\n",
      "Epoch: 61; train loss=0.003386; validation loss=0.003196\n",
      "Epoch: 62; train loss=0.003241; validation loss=0.003200\n",
      "Epoch: 63; train loss=0.003222; validation loss=0.002992\n",
      "Epoch: 64; train loss=0.003358; validation loss=0.003725\n",
      "Epoch: 65; train loss=0.003305; validation loss=0.003898\n",
      "Epoch: 66; train loss=0.003007; validation loss=0.002791\n",
      "Epoch: 67; train loss=0.003133; validation loss=0.002771\n",
      "Epoch: 68; train loss=0.003171; validation loss=0.003662\n",
      "Epoch: 69; train loss=0.003071; validation loss=0.003106\n",
      "Epoch: 70; train loss=0.003078; validation loss=0.002979\n",
      "Epoch: 71; train loss=0.002942; validation loss=0.003061\n",
      "Epoch: 72; train loss=0.003011; validation loss=0.002869\n",
      "Epoch: 73; train loss=0.002774; validation loss=0.002595\n",
      "Epoch: 74; train loss=0.002917; validation loss=0.002389\n",
      "Epoch: 75; train loss=0.002990; validation loss=0.002889\n",
      "Epoch: 76; train loss=0.002835; validation loss=0.003245\n",
      "Epoch: 77; train loss=0.002740; validation loss=0.002466\n",
      "Epoch: 78; train loss=0.002815; validation loss=0.003186\n",
      "Epoch: 79; train loss=0.002894; validation loss=0.003075\n",
      "Epoch: 80; train loss=0.002718; validation loss=0.002413\n",
      "Epoch: 81; train loss=0.002763; validation loss=0.003285\n",
      "Epoch: 82; train loss=0.002592; validation loss=0.002523\n",
      "Epoch: 83; train loss=0.002678; validation loss=0.002866\n",
      "Epoch: 84; train loss=0.002665; validation loss=0.002994\n",
      "Epoch: 85; train loss=0.002641; validation loss=0.002634\n",
      "Epoch: 86; train loss=0.002634; validation loss=0.003186\n",
      "Epoch: 87; train loss=0.002612; validation loss=0.002180\n",
      "Epoch: 88; train loss=0.002492; validation loss=0.003067\n",
      "Epoch: 89; train loss=0.002551; validation loss=0.002159\n",
      "Epoch: 90; train loss=0.002493; validation loss=0.002275\n",
      "Epoch: 91; train loss=0.002582; validation loss=0.002620\n",
      "Epoch: 92; train loss=0.002493; validation loss=0.002118\n",
      "Epoch: 93; train loss=0.002493; validation loss=0.002581\n",
      "Epoch: 94; train loss=0.002545; validation loss=0.002514\n",
      "Epoch: 95; train loss=0.002422; validation loss=0.002846\n",
      "Epoch: 96; train loss=0.002465; validation loss=0.001931\n",
      "Epoch: 97; train loss=0.002420; validation loss=0.002122\n",
      "Epoch: 98; train loss=0.002347; validation loss=0.002438\n",
      "Epoch: 99; train loss=0.002402; validation loss=0.002046\n",
      "Epoch: 100; train loss=0.002324; validation loss=0.002088\n",
      "Epoch: 101; train loss=0.002314; validation loss=0.002196\n",
      "Epoch: 102; train loss=0.002332; validation loss=0.002356\n",
      "Epoch: 103; train loss=0.002340; validation loss=0.002316\n",
      "Epoch: 104; train loss=0.002278; validation loss=0.002927\n",
      "Epoch: 105; train loss=0.002394; validation loss=0.001900\n",
      "Epoch: 106; train loss=0.002289; validation loss=0.002121\n",
      "Epoch: 107; train loss=0.002260; validation loss=0.001979\n",
      "Epoch: 108; train loss=0.002309; validation loss=0.002109\n",
      "Epoch: 109; train loss=0.002195; validation loss=0.002288\n",
      "Epoch: 110; train loss=0.002246; validation loss=0.002305\n",
      "Epoch: 111; train loss=0.002195; validation loss=0.002121\n",
      "Epoch: 112; train loss=0.002241; validation loss=0.002808\n",
      "Epoch: 113; train loss=0.002111; validation loss=0.002230\n",
      "Epoch: 114; train loss=0.002158; validation loss=0.002628\n",
      "Epoch: 115; train loss=0.002181; validation loss=0.001811\n",
      "Epoch: 116; train loss=0.002175; validation loss=0.002234\n",
      "Epoch: 117; train loss=0.002167; validation loss=0.001908\n",
      "Epoch: 118; train loss=0.002110; validation loss=0.002038\n",
      "Epoch: 119; train loss=0.002116; validation loss=0.002273\n",
      "Epoch: 120; train loss=0.002221; validation loss=0.001976\n",
      "Epoch: 121; train loss=0.002059; validation loss=0.001975\n",
      "Epoch: 122; train loss=0.002127; validation loss=0.002131\n",
      "Epoch: 123; train loss=0.002098; validation loss=0.002166\n",
      "Epoch: 124; train loss=0.002000; validation loss=0.002351\n",
      "Epoch: 125; train loss=0.001993; validation loss=0.001769\n",
      "Epoch: 126; train loss=0.002130; validation loss=0.001616\n",
      "Epoch: 127; train loss=0.002054; validation loss=0.002234\n",
      "Epoch: 128; train loss=0.002018; validation loss=0.002321\n",
      "Epoch: 129; train loss=0.002096; validation loss=0.001615\n",
      "Epoch: 130; train loss=0.001951; validation loss=0.001928\n",
      "Epoch: 131; train loss=0.002069; validation loss=0.001902\n",
      "Epoch: 132; train loss=0.001984; validation loss=0.002140\n",
      "Epoch: 133; train loss=0.001978; validation loss=0.002532\n",
      "Epoch: 134; train loss=0.002032; validation loss=0.002224\n",
      "Epoch: 135; train loss=0.001971; validation loss=0.002605\n",
      "Epoch: 136; train loss=0.001953; validation loss=0.001757\n",
      "Epoch: 137; train loss=0.001930; validation loss=0.001935\n",
      "Epoch: 138; train loss=0.001968; validation loss=0.001902\n",
      "Epoch: 139; train loss=0.001938; validation loss=0.001491\n",
      "Epoch: 140; train loss=0.002008; validation loss=0.001546\n",
      "Epoch: 141; train loss=0.001931; validation loss=0.001791\n",
      "Epoch: 142; train loss=0.002031; validation loss=0.001694\n",
      "Epoch: 143; train loss=0.001842; validation loss=0.001554\n",
      "Epoch: 144; train loss=0.001904; validation loss=0.001792\n",
      "Epoch: 145; train loss=0.001872; validation loss=0.002048\n",
      "Epoch: 146; train loss=0.001977; validation loss=0.001851\n",
      "Epoch: 147; train loss=0.001920; validation loss=0.001833\n",
      "Epoch: 148; train loss=0.001779; validation loss=0.001667\n",
      "Epoch: 149; train loss=0.001921; validation loss=0.002216\n",
      "Epoch: 150; train loss=0.001899; validation loss=0.001567\n",
      "Epoch: 151; train loss=0.001801; validation loss=0.001596\n",
      "Epoch: 152; train loss=0.001805; validation loss=0.001972\n",
      "Epoch: 153; train loss=0.001880; validation loss=0.001559\n",
      "Epoch: 154; train loss=0.001869; validation loss=0.001767\n",
      "Epoch: 155; train loss=0.001800; validation loss=0.002070\n",
      "Epoch: 156; train loss=0.001817; validation loss=0.001521\n",
      "Epoch: 157; train loss=0.001802; validation loss=0.001722\n",
      "Epoch: 158; train loss=0.001784; validation loss=0.001742\n",
      "Epoch: 159; train loss=0.001758; validation loss=0.001715\n",
      "Epoch: 160; train loss=0.001848; validation loss=0.001832\n",
      "Epoch: 161; train loss=0.001781; validation loss=0.003213\n",
      "Epoch: 162; train loss=0.001803; validation loss=0.001763\n",
      "Epoch: 163; train loss=0.001743; validation loss=0.001687\n",
      "Epoch: 164; train loss=0.001760; validation loss=0.001739\n",
      "Epoch: 165; train loss=0.001780; validation loss=0.002346\n",
      "Epoch: 166; train loss=0.001738; validation loss=0.001824\n",
      "Epoch: 167; train loss=0.001780; validation loss=0.002585\n",
      "Epoch: 168; train loss=0.001811; validation loss=0.001933\n",
      "Epoch: 169; train loss=0.001716; validation loss=0.001987\n",
      "Epoch: 170; train loss=0.001714; validation loss=0.001742\n",
      "Epoch: 171; train loss=0.001747; validation loss=0.001932\n",
      "Epoch: 172; train loss=0.001797; validation loss=0.001681\n",
      "Epoch: 173; train loss=0.001728; validation loss=0.001457\n",
      "Epoch: 174; train loss=0.001746; validation loss=0.002078\n",
      "Epoch: 175; train loss=0.001665; validation loss=0.001857\n",
      "Epoch: 176; train loss=0.001713; validation loss=0.001496\n",
      "Epoch: 177; train loss=0.001712; validation loss=0.001723\n",
      "Epoch: 178; train loss=0.001667; validation loss=0.001354\n",
      "Epoch: 179; train loss=0.001748; validation loss=0.001546\n",
      "Epoch: 180; train loss=0.001680; validation loss=0.001726\n",
      "Epoch: 181; train loss=0.001635; validation loss=0.001543\n",
      "Epoch: 182; train loss=0.001710; validation loss=0.001445\n",
      "Epoch: 183; train loss=0.001699; validation loss=0.001472\n",
      "Epoch: 184; train loss=0.001737; validation loss=0.002003\n",
      "Epoch: 185; train loss=0.001661; validation loss=0.001670\n",
      "Epoch: 186; train loss=0.001654; validation loss=0.001420\n",
      "Epoch: 187; train loss=0.001666; validation loss=0.001538\n",
      "Epoch: 188; train loss=0.001646; validation loss=0.001614\n",
      "Epoch: 189; train loss=0.001661; validation loss=0.001383\n",
      "Epoch: 190; train loss=0.001592; validation loss=0.001492\n",
      "Epoch: 191; train loss=0.001617; validation loss=0.001661\n",
      "Epoch: 192; train loss=0.001662; validation loss=0.001655\n",
      "Epoch: 193; train loss=0.001614; validation loss=0.001613\n",
      "Epoch: 194; train loss=0.001596; validation loss=0.001712\n",
      "Epoch: 195; train loss=0.001690; validation loss=0.001828\n",
      "Epoch: 196; train loss=0.001610; validation loss=0.001995\n",
      "Epoch: 197; train loss=0.001635; validation loss=0.001430\n",
      "Epoch: 198; train loss=0.001655; validation loss=0.001697\n",
      "Epoch: 199; train loss=0.001558; validation loss=0.001422\n",
      "Epoch: 200; train loss=0.001617; validation loss=0.001649\n",
      "Epoch: 201; train loss=0.001617; validation loss=0.001732\n",
      "Epoch: 202; train loss=0.001610; validation loss=0.001461\n",
      "Epoch: 203; train loss=0.001607; validation loss=0.001738\n",
      "Epoch: 204; train loss=0.001572; validation loss=0.001525\n",
      "Epoch: 205; train loss=0.001577; validation loss=0.001549\n",
      "Epoch: 206; train loss=0.001573; validation loss=0.001445\n",
      "Epoch: 207; train loss=0.001561; validation loss=0.001992\n",
      "Epoch: 208; train loss=0.001561; validation loss=0.002019\n",
      "Epoch: 209; train loss=0.001571; validation loss=0.001484\n",
      "Epoch: 210; train loss=0.001627; validation loss=0.001616\n",
      "Epoch: 211; train loss=0.001566; validation loss=0.001357\n",
      "Epoch: 212; train loss=0.001590; validation loss=0.001460\n",
      "Epoch: 213; train loss=0.001563; validation loss=0.002195\n",
      "Epoch: 214; train loss=0.001598; validation loss=0.001845\n",
      "Epoch: 215; train loss=0.001528; validation loss=0.001291\n",
      "Epoch: 216; train loss=0.001536; validation loss=0.001430\n",
      "Epoch: 217; train loss=0.001527; validation loss=0.001430\n",
      "Epoch: 218; train loss=0.001533; validation loss=0.001490\n",
      "Epoch: 219; train loss=0.001570; validation loss=0.001561\n",
      "Epoch: 220; train loss=0.001523; validation loss=0.001332\n",
      "Epoch: 221; train loss=0.001527; validation loss=0.001337\n",
      "Epoch: 222; train loss=0.001536; validation loss=0.002678\n",
      "Epoch: 223; train loss=0.001524; validation loss=0.001471\n",
      "Epoch: 224; train loss=0.001541; validation loss=0.001481\n",
      "Epoch: 225; train loss=0.001479; validation loss=0.001375\n",
      "Epoch: 226; train loss=0.001498; validation loss=0.001645\n",
      "Epoch: 227; train loss=0.001570; validation loss=0.001603\n",
      "Epoch: 228; train loss=0.001543; validation loss=0.001882\n",
      "Epoch: 229; train loss=0.001416; validation loss=0.001768\n",
      "Epoch: 230; train loss=0.001485; validation loss=0.001366\n",
      "Epoch: 231; train loss=0.001525; validation loss=0.001417\n",
      "Epoch: 232; train loss=0.001475; validation loss=0.001303\n",
      "Epoch: 233; train loss=0.001492; validation loss=0.001613\n",
      "Epoch: 234; train loss=0.001470; validation loss=0.001585\n",
      "Epoch: 235; train loss=0.001461; validation loss=0.001543\n",
      "Epoch: 236; train loss=0.001475; validation loss=0.001467\n",
      "Epoch: 237; train loss=0.001510; validation loss=0.001445\n",
      "Epoch: 238; train loss=0.001447; validation loss=0.001330\n",
      "Epoch: 239; train loss=0.001551; validation loss=0.001733\n",
      "Epoch: 240; train loss=0.001466; validation loss=0.001244\n",
      "Epoch: 241; train loss=0.001441; validation loss=0.002015\n",
      "Epoch: 242; train loss=0.001467; validation loss=0.001366\n",
      "Epoch: 243; train loss=0.001474; validation loss=0.001257\n",
      "Epoch: 244; train loss=0.001401; validation loss=0.001359\n",
      "Epoch: 245; train loss=0.001485; validation loss=0.001235\n",
      "Epoch: 246; train loss=0.001440; validation loss=0.001246\n",
      "Epoch: 247; train loss=0.001386; validation loss=0.001675\n",
      "Epoch: 248; train loss=0.001475; validation loss=0.001254\n",
      "Epoch: 249; train loss=0.001467; validation loss=0.001551\n",
      "Epoch: 250; train loss=0.001469; validation loss=0.001819\n",
      "Epoch: 251; train loss=0.001468; validation loss=0.001928\n",
      "Epoch: 252; train loss=0.001394; validation loss=0.001224\n",
      "Epoch: 253; train loss=0.001521; validation loss=0.001514\n",
      "Epoch: 254; train loss=0.001464; validation loss=0.001614\n",
      "Epoch: 255; train loss=0.001433; validation loss=0.001209\n",
      "Epoch: 256; train loss=0.001405; validation loss=0.001868\n",
      "Epoch: 257; train loss=0.001408; validation loss=0.001864\n",
      "Epoch: 258; train loss=0.001387; validation loss=0.001632\n",
      "Epoch: 259; train loss=0.001521; validation loss=0.001456\n",
      "Epoch: 260; train loss=0.001414; validation loss=0.001437\n",
      "Epoch: 261; train loss=0.001395; validation loss=0.001342\n",
      "Epoch: 262; train loss=0.001434; validation loss=0.001390\n",
      "Epoch: 263; train loss=0.001440; validation loss=0.001402\n",
      "Epoch: 264; train loss=0.001378; validation loss=0.001656\n",
      "Epoch: 265; train loss=0.001432; validation loss=0.001311\n",
      "Epoch: 266; train loss=0.001398; validation loss=0.001281\n",
      "Epoch: 267; train loss=0.001377; validation loss=0.001425\n",
      "Epoch: 268; train loss=0.001443; validation loss=0.001324\n",
      "Epoch: 269; train loss=0.001388; validation loss=0.001190\n",
      "Epoch: 270; train loss=0.001458; validation loss=0.001201\n",
      "Epoch: 271; train loss=0.001378; validation loss=0.001287\n",
      "Epoch: 272; train loss=0.001409; validation loss=0.001297\n",
      "Epoch: 273; train loss=0.001392; validation loss=0.001270\n",
      "Epoch: 274; train loss=0.001406; validation loss=0.001179\n",
      "Epoch: 275; train loss=0.001371; validation loss=0.001256\n",
      "Epoch: 276; train loss=0.001377; validation loss=0.001405\n",
      "Epoch: 277; train loss=0.001428; validation loss=0.001395\n",
      "Epoch: 278; train loss=0.001357; validation loss=0.001270\n",
      "Epoch: 279; train loss=0.001418; validation loss=0.001945\n",
      "Epoch: 280; train loss=0.001380; validation loss=0.001657\n",
      "Epoch: 281; train loss=0.001305; validation loss=0.001152\n",
      "Epoch: 282; train loss=0.001378; validation loss=0.001352\n",
      "Epoch: 283; train loss=0.001394; validation loss=0.001358\n",
      "Epoch: 284; train loss=0.001366; validation loss=0.001503\n",
      "Epoch: 285; train loss=0.001376; validation loss=0.001178\n",
      "Epoch: 286; train loss=0.001417; validation loss=0.001527\n",
      "Epoch: 287; train loss=0.001369; validation loss=0.001295\n",
      "Epoch: 288; train loss=0.001387; validation loss=0.001213\n",
      "Epoch: 289; train loss=0.001446; validation loss=0.001397\n",
      "Epoch: 290; train loss=0.001315; validation loss=0.001222\n",
      "Epoch: 291; train loss=0.001305; validation loss=0.001111\n",
      "Epoch: 292; train loss=0.001322; validation loss=0.001361\n",
      "Epoch: 293; train loss=0.001329; validation loss=0.001208\n",
      "Epoch: 294; train loss=0.001359; validation loss=0.001275\n",
      "Epoch: 295; train loss=0.001320; validation loss=0.001427\n",
      "Epoch: 296; train loss=0.001340; validation loss=0.001180\n",
      "Epoch: 297; train loss=0.001371; validation loss=0.001309\n",
      "Epoch: 298; train loss=0.001348; validation loss=0.001707\n",
      "Epoch: 299; train loss=0.001358; validation loss=0.001133\n",
      "Epoch: 300; train loss=0.001316; validation loss=0.001131\n",
      "Epoch: 301; train loss=0.001371; validation loss=0.001139\n",
      "Epoch: 302; train loss=0.001314; validation loss=0.001667\n",
      "Epoch: 303; train loss=0.001342; validation loss=0.001217\n",
      "Epoch: 304; train loss=0.001323; validation loss=0.001500\n",
      "Epoch: 305; train loss=0.001358; validation loss=0.001136\n",
      "Epoch: 306; train loss=0.001350; validation loss=0.002306\n",
      "Epoch: 307; train loss=0.001322; validation loss=0.001517\n",
      "Epoch: 308; train loss=0.001338; validation loss=0.001127\n",
      "Epoch: 309; train loss=0.001288; validation loss=0.001066\n",
      "Epoch: 310; train loss=0.001396; validation loss=0.001528\n",
      "Epoch: 311; train loss=0.001306; validation loss=0.001487\n",
      "Epoch: 312; train loss=0.001270; validation loss=0.001008\n",
      "Epoch: 313; train loss=0.001299; validation loss=0.001839\n",
      "Epoch: 314; train loss=0.001368; validation loss=0.001243\n",
      "Epoch: 315; train loss=0.001283; validation loss=0.001745\n",
      "Epoch: 316; train loss=0.001389; validation loss=0.001123\n",
      "Epoch: 317; train loss=0.001243; validation loss=0.001449\n",
      "Epoch: 318; train loss=0.001359; validation loss=0.001133\n",
      "Epoch: 319; train loss=0.001313; validation loss=0.001629\n",
      "Epoch: 320; train loss=0.001265; validation loss=0.001491\n",
      "Epoch: 321; train loss=0.001236; validation loss=0.001771\n",
      "Epoch: 322; train loss=0.001299; validation loss=0.001181\n",
      "Epoch: 323; train loss=0.001262; validation loss=0.001197\n",
      "Epoch: 324; train loss=0.001305; validation loss=0.001242\n",
      "Epoch: 325; train loss=0.001304; validation loss=0.001094\n",
      "Epoch: 326; train loss=0.001280; validation loss=0.001509\n",
      "Epoch: 327; train loss=0.001331; validation loss=0.001240\n",
      "Epoch: 328; train loss=0.001281; validation loss=0.001143\n",
      "Epoch: 329; train loss=0.001269; validation loss=0.001154\n",
      "Epoch: 330; train loss=0.001263; validation loss=0.001145\n",
      "Epoch: 331; train loss=0.001273; validation loss=0.001270\n",
      "Epoch: 332; train loss=0.001310; validation loss=0.001355\n",
      "Epoch: 333; train loss=0.001276; validation loss=0.001262\n",
      "Epoch: 334; train loss=0.001278; validation loss=0.001558\n",
      "Epoch: 335; train loss=0.001254; validation loss=0.000995\n",
      "Epoch: 336; train loss=0.001326; validation loss=0.001197\n",
      "Epoch: 337; train loss=0.001258; validation loss=0.001042\n",
      "Epoch: 338; train loss=0.001296; validation loss=0.001157\n",
      "Epoch: 339; train loss=0.001252; validation loss=0.001631\n",
      "Epoch: 340; train loss=0.001248; validation loss=0.001170\n",
      "Epoch: 341; train loss=0.001256; validation loss=0.001491\n",
      "Epoch: 342; train loss=0.001244; validation loss=0.001316\n",
      "Epoch: 343; train loss=0.001312; validation loss=0.001300\n",
      "Epoch: 344; train loss=0.001287; validation loss=0.001422\n",
      "Epoch: 345; train loss=0.001303; validation loss=0.001124\n",
      "Epoch: 346; train loss=0.001239; validation loss=0.001051\n",
      "Epoch: 347; train loss=0.001222; validation loss=0.001055\n",
      "Epoch: 348; train loss=0.001274; validation loss=0.001222\n",
      "Epoch: 349; train loss=0.001286; validation loss=0.001768\n",
      "Epoch: 350; train loss=0.001241; validation loss=0.001687\n",
      "Epoch: 351; train loss=0.001262; validation loss=0.001662\n",
      "Epoch: 352; train loss=0.001204; validation loss=0.001318\n",
      "Epoch: 353; train loss=0.001271; validation loss=0.001169\n",
      "Epoch: 354; train loss=0.001254; validation loss=0.001162\n",
      "Epoch: 355; train loss=0.001229; validation loss=0.001392\n",
      "Epoch: 356; train loss=0.001212; validation loss=0.001044\n",
      "Epoch: 357; train loss=0.001284; validation loss=0.001466\n",
      "Epoch: 358; train loss=0.001211; validation loss=0.001121\n",
      "Epoch: 359; train loss=0.001280; validation loss=0.001096\n",
      "Epoch: 360; train loss=0.001213; validation loss=0.001407\n",
      "Epoch: 361; train loss=0.001167; validation loss=0.001062\n",
      "Epoch: 362; train loss=0.001194; validation loss=0.001434\n",
      "Epoch: 363; train loss=0.001301; validation loss=0.001398\n",
      "Epoch: 364; train loss=0.001196; validation loss=0.001771\n",
      "Epoch: 365; train loss=0.001245; validation loss=0.001225\n",
      "Epoch: 366; train loss=0.001247; validation loss=0.001070\n",
      "Epoch: 367; train loss=0.001252; validation loss=0.002434\n",
      "Epoch: 368; train loss=0.001230; validation loss=0.001181\n",
      "Epoch: 369; train loss=0.001168; validation loss=0.001386\n",
      "Epoch: 370; train loss=0.001237; validation loss=0.001212\n",
      "Epoch: 371; train loss=0.001165; validation loss=0.001128\n",
      "Epoch: 372; train loss=0.001285; validation loss=0.001029\n",
      "Epoch: 373; train loss=0.001240; validation loss=0.001344\n",
      "Epoch: 374; train loss=0.001206; validation loss=0.001026\n",
      "Epoch: 375; train loss=0.001205; validation loss=0.001089\n",
      "Epoch: 376; train loss=0.001177; validation loss=0.001215\n",
      "Epoch: 377; train loss=0.001212; validation loss=0.001011\n",
      "Epoch: 378; train loss=0.001175; validation loss=0.001115\n",
      "Epoch: 379; train loss=0.001223; validation loss=0.001642\n",
      "Epoch: 380; train loss=0.001219; validation loss=0.001481\n",
      "Epoch: 381; train loss=0.001257; validation loss=0.001393\n",
      "Epoch: 382; train loss=0.001185; validation loss=0.001123\n",
      "Epoch: 383; train loss=0.001173; validation loss=0.001219\n",
      "Epoch: 384; train loss=0.001215; validation loss=0.001480\n",
      "Epoch: 385; train loss=0.001218; validation loss=0.000948\n",
      "Epoch: 386; train loss=0.001260; validation loss=0.001055\n",
      "Epoch: 387; train loss=0.001241; validation loss=0.001150\n",
      "Epoch: 388; train loss=0.001184; validation loss=0.000937\n",
      "Epoch: 389; train loss=0.001243; validation loss=0.000971\n",
      "Epoch: 390; train loss=0.001194; validation loss=0.001322\n",
      "Epoch: 391; train loss=0.001179; validation loss=0.001263\n",
      "Epoch: 392; train loss=0.001240; validation loss=0.000950\n",
      "Epoch: 393; train loss=0.001170; validation loss=0.001086\n",
      "Epoch: 394; train loss=0.001160; validation loss=0.001142\n",
      "Epoch: 395; train loss=0.001215; validation loss=0.001178\n",
      "Epoch: 396; train loss=0.001182; validation loss=0.001108\n",
      "Epoch: 397; train loss=0.001204; validation loss=0.001398\n",
      "Epoch: 398; train loss=0.001146; validation loss=0.001134\n",
      "Epoch: 399; train loss=0.001238; validation loss=0.001350\n",
      "Epoch: 400; train loss=0.001161; validation loss=0.001027\n",
      "Epoch: 401; train loss=0.001183; validation loss=0.001392\n",
      "Epoch: 402; train loss=0.001204; validation loss=0.000906\n",
      "Epoch: 403; train loss=0.001213; validation loss=0.001172\n",
      "Epoch: 404; train loss=0.001275; validation loss=0.001388\n",
      "Epoch: 405; train loss=0.001122; validation loss=0.001006\n",
      "Epoch: 406; train loss=0.001168; validation loss=0.000967\n",
      "Epoch: 407; train loss=0.001183; validation loss=0.001694\n",
      "Epoch: 408; train loss=0.001200; validation loss=0.001052\n",
      "Epoch: 409; train loss=0.001175; validation loss=0.001208\n",
      "Epoch: 410; train loss=0.001152; validation loss=0.000943\n",
      "Epoch: 411; train loss=0.001161; validation loss=0.001208\n",
      "Epoch: 412; train loss=0.001189; validation loss=0.001469\n",
      "Epoch: 413; train loss=0.001204; validation loss=0.001373\n",
      "Epoch: 414; train loss=0.001150; validation loss=0.001030\n",
      "Epoch: 415; train loss=0.001196; validation loss=0.001024\n",
      "Epoch: 416; train loss=0.001156; validation loss=0.001356\n",
      "Epoch: 417; train loss=0.001160; validation loss=0.000997\n",
      "Epoch: 418; train loss=0.001154; validation loss=0.001277\n",
      "Epoch: 419; train loss=0.001123; validation loss=0.001225\n",
      "Epoch: 420; train loss=0.001134; validation loss=0.001093\n",
      "Epoch: 421; train loss=0.001155; validation loss=0.001061\n",
      "Epoch: 422; train loss=0.001158; validation loss=0.001157\n",
      "Epoch: 423; train loss=0.001191; validation loss=0.001127\n",
      "Epoch: 424; train loss=0.001157; validation loss=0.001203\n",
      "Epoch: 425; train loss=0.001122; validation loss=0.001211\n",
      "Epoch: 426; train loss=0.001180; validation loss=0.001309\n",
      "Epoch: 427; train loss=0.001150; validation loss=0.001022\n",
      "Epoch: 428; train loss=0.001160; validation loss=0.001000\n",
      "Epoch: 429; train loss=0.001138; validation loss=0.001074\n",
      "Epoch: 430; train loss=0.001185; validation loss=0.000913\n",
      "Epoch: 431; train loss=0.001158; validation loss=0.001352\n",
      "Epoch: 432; train loss=0.001152; validation loss=0.001016\n",
      "Epoch: 433; train loss=0.001140; validation loss=0.001078\n",
      "Epoch: 434; train loss=0.001130; validation loss=0.001098\n",
      "Epoch: 435; train loss=0.001192; validation loss=0.000950\n",
      "Epoch: 436; train loss=0.001126; validation loss=0.001092\n",
      "Epoch: 437; train loss=0.001174; validation loss=0.000972\n",
      "Epoch: 438; train loss=0.001146; validation loss=0.001053\n",
      "Epoch: 439; train loss=0.001124; validation loss=0.001223\n",
      "Epoch: 440; train loss=0.001147; validation loss=0.001044\n",
      "Epoch: 441; train loss=0.001104; validation loss=0.001046\n",
      "Epoch: 442; train loss=0.001156; validation loss=0.000979\n",
      "Epoch: 443; train loss=0.001104; validation loss=0.000974\n",
      "Epoch: 444; train loss=0.001133; validation loss=0.001245\n",
      "Epoch: 445; train loss=0.001160; validation loss=0.001071\n",
      "Epoch: 446; train loss=0.001139; validation loss=0.001327\n",
      "Epoch: 447; train loss=0.001127; validation loss=0.001080\n",
      "Epoch: 448; train loss=0.001110; validation loss=0.001070\n",
      "Epoch: 449; train loss=0.001159; validation loss=0.001119\n",
      "Epoch: 450; train loss=0.001094; validation loss=0.001480\n",
      "Epoch: 451; train loss=0.001129; validation loss=0.000857\n",
      "Epoch: 452; train loss=0.001150; validation loss=0.001080\n",
      "Epoch: 453; train loss=0.001110; validation loss=0.001157\n",
      "Epoch: 454; train loss=0.001125; validation loss=0.001252\n",
      "Epoch: 455; train loss=0.001134; validation loss=0.001236\n",
      "Epoch: 456; train loss=0.001117; validation loss=0.001016\n",
      "Epoch: 457; train loss=0.001124; validation loss=0.000940\n",
      "Epoch: 458; train loss=0.001100; validation loss=0.001292\n",
      "Epoch: 459; train loss=0.001152; validation loss=0.000957\n",
      "Epoch: 460; train loss=0.001098; validation loss=0.000888\n",
      "Epoch: 461; train loss=0.001144; validation loss=0.000971\n",
      "Epoch: 462; train loss=0.001077; validation loss=0.001297\n",
      "Epoch: 463; train loss=0.001098; validation loss=0.001126\n",
      "Epoch: 464; train loss=0.001141; validation loss=0.000965\n",
      "Epoch: 465; train loss=0.001122; validation loss=0.001313\n",
      "Epoch: 466; train loss=0.001099; validation loss=0.001075\n",
      "Epoch: 467; train loss=0.001135; validation loss=0.000958\n",
      "Epoch: 468; train loss=0.001106; validation loss=0.001087\n",
      "Epoch: 469; train loss=0.001140; validation loss=0.001116\n",
      "Epoch: 470; train loss=0.001077; validation loss=0.001309\n",
      "Epoch: 471; train loss=0.001148; validation loss=0.000925\n",
      "Epoch: 472; train loss=0.001083; validation loss=0.001061\n",
      "Epoch: 473; train loss=0.001109; validation loss=0.001472\n",
      "Epoch: 474; train loss=0.001085; validation loss=0.001280\n",
      "Epoch: 475; train loss=0.001216; validation loss=0.000928\n",
      "Epoch: 476; train loss=0.001078; validation loss=0.001011\n",
      "Epoch: 477; train loss=0.001079; validation loss=0.001085\n",
      "Epoch: 478; train loss=0.001094; validation loss=0.001064\n",
      "Epoch: 479; train loss=0.001092; validation loss=0.001136\n",
      "Epoch: 480; train loss=0.001141; validation loss=0.001199\n",
      "Epoch: 481; train loss=0.001086; validation loss=0.001101\n",
      "Epoch: 482; train loss=0.001103; validation loss=0.001071\n",
      "Epoch: 483; train loss=0.001069; validation loss=0.000965\n",
      "Epoch: 484; train loss=0.001122; validation loss=0.001148\n",
      "Epoch: 485; train loss=0.001091; validation loss=0.001394\n",
      "Epoch: 486; train loss=0.001053; validation loss=0.000925\n",
      "Epoch: 487; train loss=0.001074; validation loss=0.001054\n",
      "Epoch: 488; train loss=0.001140; validation loss=0.001008\n",
      "Epoch: 489; train loss=0.001070; validation loss=0.001207\n",
      "Epoch: 490; train loss=0.001063; validation loss=0.001010\n",
      "Epoch: 491; train loss=0.001103; validation loss=0.001042\n",
      "Epoch: 492; train loss=0.001079; validation loss=0.001126\n",
      "Epoch: 493; train loss=0.001046; validation loss=0.001066\n",
      "Epoch: 494; train loss=0.001059; validation loss=0.000977\n",
      "Epoch: 495; train loss=0.001121; validation loss=0.001038\n",
      "Epoch: 496; train loss=0.001034; validation loss=0.000966\n",
      "Epoch: 497; train loss=0.001129; validation loss=0.001242\n",
      "Epoch: 498; train loss=0.001036; validation loss=0.000922\n",
      "Epoch: 499; train loss=0.001051; validation loss=0.000852\n",
      "Epoch: 500; train loss=0.001121; validation loss=0.001211\n",
      "Epoch: 501; train loss=0.001071; validation loss=0.001251\n",
      "Epoch: 502; train loss=0.001074; validation loss=0.001368\n",
      "Epoch: 503; train loss=0.001115; validation loss=0.001252\n",
      "Epoch: 504; train loss=0.001084; validation loss=0.000948\n",
      "Epoch: 505; train loss=0.001077; validation loss=0.000945\n",
      "Epoch: 506; train loss=0.001001; validation loss=0.001254\n",
      "Epoch: 507; train loss=0.001102; validation loss=0.001394\n",
      "Epoch: 508; train loss=0.001097; validation loss=0.001114\n",
      "Epoch: 509; train loss=0.001065; validation loss=0.001258\n",
      "Epoch: 510; train loss=0.001059; validation loss=0.000946\n",
      "Epoch: 511; train loss=0.001049; validation loss=0.001002\n",
      "Epoch: 512; train loss=0.001041; validation loss=0.000919\n",
      "Epoch: 513; train loss=0.001100; validation loss=0.001256\n",
      "Epoch: 514; train loss=0.001041; validation loss=0.001311\n",
      "Epoch: 515; train loss=0.001124; validation loss=0.000819\n",
      "Epoch: 516; train loss=0.001039; validation loss=0.001067\n",
      "Epoch: 517; train loss=0.001077; validation loss=0.001001\n",
      "Epoch: 518; train loss=0.001051; validation loss=0.001026\n",
      "Epoch: 519; train loss=0.001038; validation loss=0.001344\n",
      "Epoch: 520; train loss=0.001057; validation loss=0.001595\n",
      "Epoch: 521; train loss=0.001082; validation loss=0.001250\n",
      "Epoch: 522; train loss=0.001084; validation loss=0.001377\n",
      "Epoch: 523; train loss=0.001048; validation loss=0.000957\n",
      "Epoch: 524; train loss=0.001046; validation loss=0.000994\n",
      "Epoch: 525; train loss=0.001057; validation loss=0.001070\n",
      "Epoch: 526; train loss=0.001042; validation loss=0.000961\n",
      "Epoch: 527; train loss=0.001078; validation loss=0.001239\n",
      "Epoch: 528; train loss=0.001058; validation loss=0.001499\n",
      "Epoch: 529; train loss=0.001074; validation loss=0.001294\n",
      "Epoch: 530; train loss=0.001051; validation loss=0.000923\n",
      "Epoch: 531; train loss=0.001059; validation loss=0.001693\n",
      "Epoch: 532; train loss=0.001077; validation loss=0.001467\n",
      "Epoch: 533; train loss=0.001040; validation loss=0.001345\n",
      "Epoch: 534; train loss=0.001054; validation loss=0.000942\n",
      "Epoch: 535; train loss=0.001034; validation loss=0.001093\n",
      "Epoch: 536; train loss=0.001029; validation loss=0.000860\n",
      "Epoch: 537; train loss=0.001034; validation loss=0.000901\n",
      "Epoch: 538; train loss=0.001106; validation loss=0.001130\n",
      "Epoch: 539; train loss=0.001003; validation loss=0.001027\n",
      "Epoch: 540; train loss=0.001060; validation loss=0.000962\n",
      "Epoch: 541; train loss=0.001084; validation loss=0.000908\n",
      "Epoch: 542; train loss=0.000991; validation loss=0.000821\n",
      "Epoch: 543; train loss=0.001050; validation loss=0.001267\n",
      "Epoch: 544; train loss=0.001060; validation loss=0.001090\n",
      "Epoch: 545; train loss=0.001025; validation loss=0.001092\n",
      "Epoch: 546; train loss=0.001032; validation loss=0.000932\n",
      "Epoch: 547; train loss=0.001081; validation loss=0.000914\n",
      "Epoch: 548; train loss=0.001042; validation loss=0.000814\n",
      "Epoch: 549; train loss=0.001034; validation loss=0.001088\n",
      "Epoch: 550; train loss=0.001056; validation loss=0.001324\n",
      "Epoch: 551; train loss=0.001016; validation loss=0.000974\n",
      "Epoch: 552; train loss=0.001020; validation loss=0.000912\n",
      "Epoch: 553; train loss=0.001036; validation loss=0.001307\n",
      "Epoch: 554; train loss=0.001035; validation loss=0.001021\n",
      "Epoch: 555; train loss=0.001012; validation loss=0.001076\n",
      "Epoch: 556; train loss=0.001030; validation loss=0.001033\n",
      "Epoch: 557; train loss=0.001055; validation loss=0.000813\n",
      "Epoch: 558; train loss=0.001055; validation loss=0.000797\n",
      "Epoch: 559; train loss=0.001051; validation loss=0.000983\n",
      "Epoch: 560; train loss=0.001099; validation loss=0.000968\n",
      "Epoch: 561; train loss=0.001029; validation loss=0.001171\n",
      "Epoch: 562; train loss=0.000988; validation loss=0.000944\n",
      "Epoch: 563; train loss=0.001033; validation loss=0.001149\n",
      "Epoch: 564; train loss=0.001054; validation loss=0.001458\n",
      "Epoch: 565; train loss=0.001027; validation loss=0.001236\n",
      "Epoch: 566; train loss=0.001059; validation loss=0.001051\n",
      "Epoch: 567; train loss=0.001034; validation loss=0.000885\n",
      "Epoch: 568; train loss=0.001003; validation loss=0.000828\n",
      "Epoch: 569; train loss=0.001043; validation loss=0.001013\n",
      "Epoch: 570; train loss=0.000989; validation loss=0.000890\n",
      "Epoch: 571; train loss=0.001040; validation loss=0.001297\n",
      "Epoch: 572; train loss=0.001009; validation loss=0.000972\n",
      "Epoch: 573; train loss=0.001000; validation loss=0.000967\n",
      "Epoch: 574; train loss=0.001074; validation loss=0.000958\n",
      "Epoch: 575; train loss=0.001019; validation loss=0.001058\n",
      "Epoch: 576; train loss=0.001028; validation loss=0.000936\n",
      "Epoch: 577; train loss=0.001019; validation loss=0.000901\n",
      "Epoch: 578; train loss=0.000986; validation loss=0.000955\n",
      "Epoch: 579; train loss=0.001001; validation loss=0.001069\n",
      "Epoch: 580; train loss=0.001035; validation loss=0.000908\n",
      "Epoch: 581; train loss=0.000998; validation loss=0.001303\n",
      "Epoch: 582; train loss=0.001022; validation loss=0.001305\n",
      "Epoch: 583; train loss=0.001019; validation loss=0.000886\n",
      "Epoch: 584; train loss=0.000988; validation loss=0.000825\n",
      "Epoch: 585; train loss=0.001032; validation loss=0.000824\n",
      "Epoch: 586; train loss=0.000980; validation loss=0.001080\n",
      "Epoch: 587; train loss=0.001016; validation loss=0.001125\n",
      "Epoch: 588; train loss=0.001057; validation loss=0.001225\n",
      "Epoch: 589; train loss=0.001010; validation loss=0.000979\n",
      "Epoch: 590; train loss=0.000969; validation loss=0.001368\n",
      "Epoch: 591; train loss=0.001019; validation loss=0.000987\n",
      "Epoch: 592; train loss=0.001004; validation loss=0.000930\n",
      "Epoch: 593; train loss=0.000995; validation loss=0.000851\n",
      "Epoch: 594; train loss=0.000962; validation loss=0.000791\n",
      "Epoch: 595; train loss=0.001036; validation loss=0.000851\n",
      "Epoch: 596; train loss=0.000979; validation loss=0.001309\n",
      "Epoch: 597; train loss=0.001036; validation loss=0.001107\n",
      "Epoch: 598; train loss=0.000988; validation loss=0.000811\n",
      "Epoch: 599; train loss=0.001001; validation loss=0.000968\n",
      "Epoch: 600; train loss=0.000997; validation loss=0.001059\n",
      "Epoch: 601; train loss=0.000986; validation loss=0.000918\n",
      "Epoch: 602; train loss=0.001007; validation loss=0.000770\n",
      "Epoch: 603; train loss=0.000971; validation loss=0.000967\n",
      "Epoch: 604; train loss=0.001042; validation loss=0.000967\n",
      "Epoch: 605; train loss=0.000971; validation loss=0.001156\n",
      "Epoch: 606; train loss=0.001008; validation loss=0.001169\n",
      "Epoch: 607; train loss=0.001055; validation loss=0.001023\n",
      "Epoch: 608; train loss=0.000989; validation loss=0.001043\n",
      "Epoch: 609; train loss=0.000962; validation loss=0.000740\n",
      "Epoch: 610; train loss=0.001023; validation loss=0.000883\n",
      "Epoch: 611; train loss=0.000992; validation loss=0.000818\n",
      "Epoch: 612; train loss=0.000980; validation loss=0.000811\n",
      "Epoch: 613; train loss=0.000994; validation loss=0.000888\n",
      "Epoch: 614; train loss=0.000985; validation loss=0.000710\n",
      "Epoch: 615; train loss=0.000998; validation loss=0.001067\n",
      "Epoch: 616; train loss=0.000976; validation loss=0.000860\n",
      "Epoch: 617; train loss=0.000969; validation loss=0.000855\n",
      "Epoch: 618; train loss=0.000970; validation loss=0.001142\n",
      "Epoch: 619; train loss=0.001020; validation loss=0.000904\n",
      "Epoch: 620; train loss=0.000979; validation loss=0.000918\n",
      "Epoch: 621; train loss=0.000988; validation loss=0.001220\n",
      "Epoch: 622; train loss=0.000952; validation loss=0.001152\n",
      "Epoch: 623; train loss=0.001011; validation loss=0.000972\n",
      "Epoch: 624; train loss=0.001048; validation loss=0.000908\n",
      "Epoch: 625; train loss=0.001016; validation loss=0.000860\n",
      "Epoch: 626; train loss=0.000950; validation loss=0.000989\n",
      "Epoch: 627; train loss=0.001015; validation loss=0.001091\n",
      "Epoch: 628; train loss=0.001008; validation loss=0.000965\n",
      "Epoch: 629; train loss=0.000994; validation loss=0.001203\n",
      "Epoch: 630; train loss=0.000948; validation loss=0.000769\n",
      "Epoch: 631; train loss=0.001021; validation loss=0.001737\n",
      "Epoch: 632; train loss=0.001002; validation loss=0.000796\n",
      "Epoch: 633; train loss=0.000998; validation loss=0.001075\n",
      "Epoch: 634; train loss=0.000997; validation loss=0.001340\n",
      "Epoch: 635; train loss=0.000927; validation loss=0.000777\n",
      "Epoch: 636; train loss=0.000985; validation loss=0.001058\n",
      "Epoch: 637; train loss=0.001000; validation loss=0.000989\n",
      "Epoch: 638; train loss=0.000926; validation loss=0.000918\n",
      "Epoch: 639; train loss=0.001013; validation loss=0.001153\n",
      "Epoch: 640; train loss=0.000977; validation loss=0.000887\n",
      "Epoch: 641; train loss=0.000971; validation loss=0.001192\n",
      "Epoch: 642; train loss=0.000958; validation loss=0.000979\n",
      "Epoch: 643; train loss=0.000997; validation loss=0.001160\n",
      "Epoch: 644; train loss=0.000985; validation loss=0.000853\n",
      "Epoch: 645; train loss=0.000970; validation loss=0.000959\n",
      "Epoch: 646; train loss=0.000987; validation loss=0.000846\n",
      "Epoch: 647; train loss=0.000996; validation loss=0.000795\n",
      "Epoch: 648; train loss=0.000958; validation loss=0.000908\n",
      "Epoch: 649; train loss=0.000969; validation loss=0.000948\n",
      "Epoch: 650; train loss=0.000979; validation loss=0.000937\n",
      "Epoch: 651; train loss=0.000964; validation loss=0.000763\n",
      "Epoch: 652; train loss=0.000927; validation loss=0.000709\n",
      "Epoch: 653; train loss=0.000981; validation loss=0.001328\n",
      "Epoch: 654; train loss=0.000986; validation loss=0.000865\n",
      "Epoch: 655; train loss=0.001002; validation loss=0.001008\n",
      "Epoch: 656; train loss=0.000955; validation loss=0.000742\n",
      "Epoch: 657; train loss=0.000952; validation loss=0.000945\n",
      "Epoch: 658; train loss=0.000945; validation loss=0.000740\n",
      "Epoch: 659; train loss=0.000961; validation loss=0.000779\n",
      "Epoch: 660; train loss=0.001010; validation loss=0.000830\n",
      "Epoch: 661; train loss=0.000933; validation loss=0.000794\n",
      "Epoch: 662; train loss=0.000984; validation loss=0.001303\n",
      "Epoch: 663; train loss=0.000927; validation loss=0.000929\n",
      "Epoch: 664; train loss=0.000939; validation loss=0.000880\n",
      "Epoch: 665; train loss=0.000991; validation loss=0.001123\n",
      "Epoch: 666; train loss=0.000995; validation loss=0.000798\n",
      "Epoch: 667; train loss=0.000962; validation loss=0.001143\n",
      "Epoch: 668; train loss=0.000935; validation loss=0.000945\n",
      "Epoch: 669; train loss=0.000989; validation loss=0.000774\n",
      "Epoch: 670; train loss=0.000942; validation loss=0.001133\n",
      "Epoch: 671; train loss=0.000948; validation loss=0.001387\n",
      "Epoch: 672; train loss=0.000937; validation loss=0.001068\n",
      "Epoch: 673; train loss=0.000984; validation loss=0.001069\n",
      "Epoch: 674; train loss=0.000956; validation loss=0.000979\n",
      "Epoch: 675; train loss=0.000919; validation loss=0.000846\n",
      "Epoch: 676; train loss=0.001008; validation loss=0.001086\n",
      "Epoch: 677; train loss=0.000895; validation loss=0.001032\n",
      "Epoch: 678; train loss=0.000987; validation loss=0.001093\n",
      "Epoch: 679; train loss=0.000928; validation loss=0.000985\n",
      "Epoch: 680; train loss=0.000963; validation loss=0.001411\n",
      "Epoch: 681; train loss=0.000951; validation loss=0.001037\n",
      "Epoch: 682; train loss=0.000961; validation loss=0.000866\n",
      "Epoch: 683; train loss=0.000938; validation loss=0.000726\n",
      "Epoch: 684; train loss=0.000932; validation loss=0.001378\n",
      "Epoch: 685; train loss=0.000939; validation loss=0.001008\n",
      "Epoch: 686; train loss=0.000988; validation loss=0.000899\n",
      "Epoch: 687; train loss=0.000912; validation loss=0.001199\n",
      "Epoch: 688; train loss=0.000972; validation loss=0.000877\n",
      "Epoch: 689; train loss=0.000958; validation loss=0.001330\n",
      "Epoch: 690; train loss=0.000945; validation loss=0.000837\n",
      "Epoch: 691; train loss=0.000924; validation loss=0.000919\n",
      "Epoch: 692; train loss=0.000948; validation loss=0.001070\n",
      "Epoch: 693; train loss=0.000913; validation loss=0.000694\n",
      "Epoch: 694; train loss=0.000927; validation loss=0.000724\n",
      "Epoch: 695; train loss=0.000940; validation loss=0.000899\n",
      "Epoch: 696; train loss=0.000965; validation loss=0.001036\n",
      "Epoch: 697; train loss=0.000931; validation loss=0.000723\n",
      "Epoch: 698; train loss=0.000959; validation loss=0.001036\n",
      "Epoch: 699; train loss=0.000896; validation loss=0.000858\n",
      "Epoch: 700; train loss=0.000963; validation loss=0.000809\n",
      "Epoch: 701; train loss=0.000925; validation loss=0.000790\n",
      "Epoch: 702; train loss=0.000942; validation loss=0.001012\n",
      "Epoch: 703; train loss=0.000940; validation loss=0.000901\n",
      "Epoch: 704; train loss=0.000941; validation loss=0.001067\n",
      "Epoch: 705; train loss=0.000949; validation loss=0.001326\n",
      "Epoch: 706; train loss=0.000935; validation loss=0.001239\n",
      "Epoch: 707; train loss=0.000909; validation loss=0.000968\n",
      "Epoch: 708; train loss=0.000937; validation loss=0.000790\n",
      "Epoch: 709; train loss=0.000944; validation loss=0.000740\n",
      "Epoch: 710; train loss=0.000932; validation loss=0.001035\n",
      "Epoch: 711; train loss=0.000936; validation loss=0.000803\n",
      "Epoch: 712; train loss=0.000891; validation loss=0.000833\n",
      "Epoch: 713; train loss=0.000938; validation loss=0.001103\n",
      "Epoch: 714; train loss=0.000957; validation loss=0.000800\n",
      "Epoch: 715; train loss=0.000889; validation loss=0.001048\n",
      "Epoch: 716; train loss=0.000945; validation loss=0.001073\n",
      "Epoch: 717; train loss=0.000931; validation loss=0.000980\n",
      "Epoch: 718; train loss=0.000899; validation loss=0.000751\n",
      "Epoch: 719; train loss=0.000969; validation loss=0.001097\n",
      "Epoch: 720; train loss=0.000872; validation loss=0.000849\n",
      "Epoch: 721; train loss=0.000944; validation loss=0.000834\n",
      "Epoch: 722; train loss=0.000910; validation loss=0.000840\n",
      "Epoch: 723; train loss=0.000950; validation loss=0.000908\n",
      "Epoch: 724; train loss=0.000932; validation loss=0.000674\n",
      "Epoch: 725; train loss=0.000908; validation loss=0.000895\n",
      "Epoch: 726; train loss=0.000909; validation loss=0.000947\n",
      "Epoch: 727; train loss=0.000903; validation loss=0.001352\n",
      "Epoch: 728; train loss=0.000933; validation loss=0.000816\n",
      "Epoch: 729; train loss=0.000928; validation loss=0.001018\n",
      "Epoch: 730; train loss=0.000966; validation loss=0.000897\n",
      "Epoch: 731; train loss=0.000865; validation loss=0.000984\n",
      "Epoch: 732; train loss=0.000943; validation loss=0.000698\n",
      "Epoch: 733; train loss=0.000923; validation loss=0.000786\n",
      "Epoch: 734; train loss=0.000868; validation loss=0.000769\n",
      "Epoch: 735; train loss=0.000948; validation loss=0.000871\n",
      "Epoch: 736; train loss=0.000915; validation loss=0.000998\n",
      "Epoch: 737; train loss=0.000910; validation loss=0.000747\n",
      "Epoch: 738; train loss=0.000887; validation loss=0.000859\n",
      "Epoch: 739; train loss=0.000952; validation loss=0.000795\n",
      "Epoch: 740; train loss=0.000933; validation loss=0.000872\n",
      "Epoch: 741; train loss=0.000886; validation loss=0.000933\n",
      "Epoch: 742; train loss=0.000883; validation loss=0.000803\n",
      "Epoch: 743; train loss=0.000912; validation loss=0.000780\n",
      "Epoch: 744; train loss=0.000921; validation loss=0.000895\n",
      "Epoch: 745; train loss=0.000890; validation loss=0.000921\n",
      "Epoch: 746; train loss=0.000870; validation loss=0.000976\n",
      "Epoch: 747; train loss=0.000948; validation loss=0.000792\n",
      "Epoch: 748; train loss=0.000949; validation loss=0.000788\n",
      "Epoch: 749; train loss=0.000871; validation loss=0.000720\n",
      "Epoch: 750; train loss=0.000924; validation loss=0.001066\n",
      "Epoch: 751; train loss=0.000914; validation loss=0.000760\n",
      "Epoch: 752; train loss=0.000910; validation loss=0.001015\n",
      "Epoch: 753; train loss=0.000899; validation loss=0.001171\n",
      "Epoch: 754; train loss=0.000898; validation loss=0.000674\n",
      "Epoch: 755; train loss=0.000900; validation loss=0.000906\n",
      "Epoch: 756; train loss=0.000934; validation loss=0.000801\n",
      "Epoch: 757; train loss=0.000914; validation loss=0.000731\n",
      "Epoch: 758; train loss=0.000893; validation loss=0.001147\n",
      "Epoch: 759; train loss=0.000873; validation loss=0.000940\n",
      "Epoch: 760; train loss=0.000913; validation loss=0.000708\n",
      "Epoch: 761; train loss=0.000861; validation loss=0.000831\n",
      "Epoch: 762; train loss=0.000898; validation loss=0.000843\n",
      "Epoch: 763; train loss=0.000883; validation loss=0.000728\n",
      "Epoch: 764; train loss=0.000938; validation loss=0.000748\n",
      "Epoch: 765; train loss=0.000923; validation loss=0.000668\n",
      "Epoch: 766; train loss=0.000881; validation loss=0.000841\n",
      "Epoch: 767; train loss=0.000887; validation loss=0.000790\n",
      "Epoch: 768; train loss=0.000906; validation loss=0.000720\n",
      "Epoch: 769; train loss=0.000942; validation loss=0.000952\n",
      "Epoch: 770; train loss=0.000872; validation loss=0.000748\n",
      "Epoch: 771; train loss=0.000863; validation loss=0.000906\n",
      "Epoch: 772; train loss=0.000886; validation loss=0.001037\n",
      "Epoch: 773; train loss=0.000927; validation loss=0.001112\n",
      "Epoch: 774; train loss=0.000869; validation loss=0.000924\n",
      "Epoch: 775; train loss=0.000903; validation loss=0.001293\n",
      "Epoch: 776; train loss=0.000891; validation loss=0.001055\n",
      "Epoch: 777; train loss=0.000893; validation loss=0.000674\n",
      "Epoch: 778; train loss=0.000879; validation loss=0.000846\n",
      "Epoch: 779; train loss=0.000940; validation loss=0.000925\n",
      "Epoch: 780; train loss=0.000872; validation loss=0.000989\n",
      "Epoch: 781; train loss=0.000865; validation loss=0.000935\n",
      "Epoch: 782; train loss=0.000922; validation loss=0.001424\n",
      "Epoch: 783; train loss=0.000908; validation loss=0.000746\n",
      "Epoch: 784; train loss=0.000896; validation loss=0.000843\n",
      "Epoch: 785; train loss=0.000913; validation loss=0.000893\n",
      "Epoch: 786; train loss=0.000867; validation loss=0.000827\n",
      "Epoch: 787; train loss=0.000912; validation loss=0.000887\n",
      "Epoch: 788; train loss=0.000882; validation loss=0.000885\n",
      "Epoch: 789; train loss=0.000871; validation loss=0.000751\n",
      "Epoch: 790; train loss=0.000847; validation loss=0.000828\n",
      "Epoch: 791; train loss=0.000885; validation loss=0.000872\n",
      "Epoch: 792; train loss=0.000921; validation loss=0.000771\n",
      "Epoch: 793; train loss=0.000874; validation loss=0.000764\n",
      "Epoch: 794; train loss=0.000946; validation loss=0.001041\n",
      "Epoch: 795; train loss=0.000881; validation loss=0.000876\n",
      "Epoch: 796; train loss=0.000858; validation loss=0.001038\n",
      "Epoch: 797; train loss=0.000863; validation loss=0.001268\n",
      "Epoch: 798; train loss=0.000895; validation loss=0.000817\n",
      "Epoch: 799; train loss=0.000862; validation loss=0.000905\n",
      "Epoch: 800; train loss=0.000875; validation loss=0.000959\n",
      "Epoch: 801; train loss=0.000889; validation loss=0.000732\n",
      "Epoch: 802; train loss=0.000904; validation loss=0.000964\n",
      "Epoch: 803; train loss=0.000865; validation loss=0.000687\n",
      "Epoch: 804; train loss=0.000885; validation loss=0.000831\n",
      "Epoch: 805; train loss=0.000840; validation loss=0.000731\n",
      "Epoch: 806; train loss=0.000947; validation loss=0.000848\n",
      "Epoch: 807; train loss=0.000877; validation loss=0.000664\n",
      "Epoch: 808; train loss=0.000841; validation loss=0.000797\n",
      "Epoch: 809; train loss=0.000853; validation loss=0.000691\n",
      "Epoch: 810; train loss=0.000831; validation loss=0.001047\n",
      "Epoch: 811; train loss=0.000930; validation loss=0.000799\n",
      "Epoch: 812; train loss=0.000847; validation loss=0.000769\n",
      "Epoch: 813; train loss=0.000888; validation loss=0.000869\n",
      "Epoch: 814; train loss=0.000853; validation loss=0.000806\n",
      "Epoch: 815; train loss=0.000843; validation loss=0.001113\n",
      "Epoch: 816; train loss=0.000876; validation loss=0.000706\n",
      "Epoch: 817; train loss=0.000875; validation loss=0.000921\n",
      "Epoch: 818; train loss=0.000876; validation loss=0.000893\n",
      "Epoch: 819; train loss=0.000907; validation loss=0.000880\n",
      "Epoch: 820; train loss=0.000866; validation loss=0.000860\n",
      "Epoch: 821; train loss=0.000859; validation loss=0.000823\n",
      "Epoch: 822; train loss=0.000838; validation loss=0.000719\n",
      "Epoch: 823; train loss=0.000842; validation loss=0.000798\n",
      "Epoch: 824; train loss=0.000886; validation loss=0.001038\n",
      "Epoch: 825; train loss=0.000811; validation loss=0.000721\n",
      "Epoch: 826; train loss=0.000830; validation loss=0.000897\n",
      "Epoch: 827; train loss=0.000905; validation loss=0.000901\n",
      "Epoch: 828; train loss=0.000877; validation loss=0.000841\n",
      "Epoch: 829; train loss=0.000864; validation loss=0.000723\n",
      "Epoch: 830; train loss=0.000849; validation loss=0.000971\n",
      "Epoch: 831; train loss=0.000844; validation loss=0.000781\n",
      "Epoch: 832; train loss=0.000876; validation loss=0.001238\n",
      "Epoch: 833; train loss=0.000824; validation loss=0.000614\n",
      "Epoch: 834; train loss=0.000834; validation loss=0.000661\n",
      "Epoch: 835; train loss=0.000844; validation loss=0.000783\n",
      "Epoch: 836; train loss=0.000902; validation loss=0.000850\n",
      "Epoch: 837; train loss=0.000840; validation loss=0.001119\n",
      "Epoch: 838; train loss=0.000873; validation loss=0.000767\n",
      "Epoch: 839; train loss=0.000822; validation loss=0.000870\n",
      "Epoch: 840; train loss=0.000852; validation loss=0.000773\n",
      "Epoch: 841; train loss=0.000813; validation loss=0.000874\n",
      "Epoch: 842; train loss=0.000872; validation loss=0.000710\n",
      "Epoch: 843; train loss=0.000870; validation loss=0.001466\n",
      "Epoch: 844; train loss=0.000883; validation loss=0.000681\n",
      "Epoch: 845; train loss=0.000818; validation loss=0.000896\n",
      "Epoch: 846; train loss=0.000815; validation loss=0.000844\n",
      "Epoch: 847; train loss=0.000819; validation loss=0.000827\n",
      "Epoch: 848; train loss=0.000883; validation loss=0.000921\n",
      "Epoch: 849; train loss=0.000821; validation loss=0.000708\n",
      "Epoch: 850; train loss=0.000864; validation loss=0.001016\n",
      "Epoch: 851; train loss=0.000829; validation loss=0.000755\n",
      "Epoch: 852; train loss=0.000817; validation loss=0.000698\n",
      "Epoch: 853; train loss=0.000879; validation loss=0.000990\n",
      "Epoch: 854; train loss=0.000817; validation loss=0.000802\n",
      "Epoch: 855; train loss=0.000849; validation loss=0.000731\n",
      "Epoch: 856; train loss=0.000820; validation loss=0.000781\n",
      "Epoch: 857; train loss=0.000798; validation loss=0.000680\n",
      "Epoch: 858; train loss=0.000890; validation loss=0.000912\n",
      "Epoch: 859; train loss=0.000828; validation loss=0.000686\n",
      "Epoch: 860; train loss=0.000855; validation loss=0.000639\n",
      "Epoch: 861; train loss=0.000808; validation loss=0.000760\n",
      "Epoch: 862; train loss=0.000861; validation loss=0.001182\n",
      "Epoch: 863; train loss=0.000849; validation loss=0.000974\n",
      "Epoch: 864; train loss=0.000808; validation loss=0.001104\n",
      "Epoch: 865; train loss=0.000831; validation loss=0.000699\n",
      "Epoch: 866; train loss=0.000837; validation loss=0.001270\n",
      "Epoch: 867; train loss=0.000819; validation loss=0.000884\n",
      "Epoch: 868; train loss=0.000844; validation loss=0.001030\n",
      "Epoch: 869; train loss=0.000854; validation loss=0.000586\n",
      "Epoch: 870; train loss=0.000806; validation loss=0.000833\n",
      "Epoch: 871; train loss=0.000827; validation loss=0.000902\n",
      "Epoch: 872; train loss=0.000869; validation loss=0.000659\n",
      "Epoch: 873; train loss=0.000816; validation loss=0.000826\n",
      "Epoch: 874; train loss=0.000826; validation loss=0.000847\n",
      "Epoch: 875; train loss=0.000821; validation loss=0.000893\n",
      "Epoch: 876; train loss=0.000834; validation loss=0.000830\n",
      "Epoch: 877; train loss=0.000820; validation loss=0.000989\n",
      "Epoch: 878; train loss=0.000807; validation loss=0.000705\n",
      "Epoch: 879; train loss=0.000827; validation loss=0.000976\n",
      "Epoch: 880; train loss=0.000787; validation loss=0.000826\n",
      "Epoch: 881; train loss=0.000820; validation loss=0.000636\n",
      "Epoch: 882; train loss=0.000833; validation loss=0.000608\n",
      "Epoch: 883; train loss=0.000819; validation loss=0.000873\n",
      "Epoch: 884; train loss=0.000781; validation loss=0.000658\n",
      "Epoch: 885; train loss=0.000864; validation loss=0.000630\n",
      "Epoch: 886; train loss=0.000841; validation loss=0.000682\n",
      "Epoch: 887; train loss=0.000762; validation loss=0.000816\n",
      "Epoch: 888; train loss=0.000837; validation loss=0.000820\n",
      "Epoch: 889; train loss=0.000780; validation loss=0.000721\n",
      "Epoch: 890; train loss=0.000856; validation loss=0.000791\n",
      "Epoch: 891; train loss=0.000782; validation loss=0.000656\n",
      "Epoch: 892; train loss=0.000852; validation loss=0.000824\n",
      "Epoch: 893; train loss=0.000815; validation loss=0.000587\n",
      "Epoch: 894; train loss=0.000804; validation loss=0.000775\n",
      "Epoch: 895; train loss=0.000762; validation loss=0.000741\n",
      "Epoch: 896; train loss=0.000827; validation loss=0.000571\n",
      "Epoch: 897; train loss=0.000833; validation loss=0.001146\n",
      "Epoch: 898; train loss=0.000811; validation loss=0.000700\n",
      "Epoch: 899; train loss=0.000768; validation loss=0.000710\n",
      "Epoch: 900; train loss=0.000806; validation loss=0.001014\n",
      "Epoch: 901; train loss=0.000818; validation loss=0.000878\n",
      "Epoch: 902; train loss=0.000771; validation loss=0.000802\n",
      "Epoch: 903; train loss=0.000818; validation loss=0.000873\n",
      "Epoch: 904; train loss=0.000840; validation loss=0.000760\n",
      "Epoch: 905; train loss=0.000766; validation loss=0.000828\n",
      "Epoch: 906; train loss=0.000833; validation loss=0.000804\n",
      "Epoch: 907; train loss=0.000780; validation loss=0.000788\n",
      "Epoch: 908; train loss=0.000803; validation loss=0.000621\n",
      "Epoch: 909; train loss=0.000821; validation loss=0.000920\n",
      "Epoch: 910; train loss=0.000791; validation loss=0.000968\n",
      "Epoch: 911; train loss=0.000758; validation loss=0.000890\n",
      "Epoch: 912; train loss=0.000839; validation loss=0.000867\n",
      "Epoch: 913; train loss=0.000784; validation loss=0.000720\n",
      "Epoch: 914; train loss=0.000799; validation loss=0.000746\n",
      "Epoch: 915; train loss=0.000772; validation loss=0.000695\n",
      "Epoch: 916; train loss=0.000791; validation loss=0.000720\n",
      "Epoch: 917; train loss=0.000763; validation loss=0.000759\n",
      "Epoch: 918; train loss=0.000767; validation loss=0.001088\n",
      "Epoch: 919; train loss=0.000820; validation loss=0.000768\n",
      "Epoch: 920; train loss=0.000757; validation loss=0.000631\n",
      "Epoch: 921; train loss=0.000769; validation loss=0.000644\n",
      "Epoch: 922; train loss=0.000773; validation loss=0.000776\n",
      "Epoch: 923; train loss=0.000775; validation loss=0.000631\n",
      "Epoch: 924; train loss=0.000771; validation loss=0.000671\n",
      "Epoch: 925; train loss=0.000797; validation loss=0.000664\n",
      "Epoch: 926; train loss=0.000734; validation loss=0.000640\n",
      "Epoch: 927; train loss=0.000793; validation loss=0.000682\n",
      "Epoch: 928; train loss=0.000770; validation loss=0.000636\n",
      "Epoch: 929; train loss=0.000793; validation loss=0.000649\n",
      "Epoch: 930; train loss=0.000769; validation loss=0.000825\n",
      "Epoch: 931; train loss=0.000754; validation loss=0.000752\n",
      "Epoch: 932; train loss=0.000775; validation loss=0.000789\n",
      "Epoch: 933; train loss=0.000789; validation loss=0.000691\n",
      "Epoch: 934; train loss=0.000763; validation loss=0.000665\n",
      "Epoch: 935; train loss=0.000773; validation loss=0.000704\n",
      "Epoch: 936; train loss=0.000765; validation loss=0.000877\n",
      "Epoch: 937; train loss=0.000784; validation loss=0.000740\n",
      "Epoch: 938; train loss=0.000744; validation loss=0.000769\n",
      "Epoch: 939; train loss=0.000759; validation loss=0.000708\n",
      "Epoch: 940; train loss=0.000774; validation loss=0.000845\n",
      "Epoch: 941; train loss=0.000727; validation loss=0.000811\n",
      "Epoch: 942; train loss=0.000807; validation loss=0.000551\n",
      "Epoch: 943; train loss=0.000732; validation loss=0.000741\n",
      "Epoch: 944; train loss=0.000749; validation loss=0.001021\n",
      "Epoch: 945; train loss=0.000795; validation loss=0.000794\n",
      "Epoch: 946; train loss=0.000752; validation loss=0.000959\n",
      "Epoch: 947; train loss=0.000783; validation loss=0.000688\n",
      "Epoch: 948; train loss=0.000749; validation loss=0.000607\n",
      "Epoch: 949; train loss=0.000769; validation loss=0.001100\n",
      "Epoch: 950; train loss=0.000774; validation loss=0.000603\n",
      "Epoch: 951; train loss=0.000768; validation loss=0.000695\n",
      "Epoch: 952; train loss=0.000769; validation loss=0.000840\n",
      "Epoch: 953; train loss=0.000716; validation loss=0.000579\n",
      "Epoch: 954; train loss=0.000763; validation loss=0.000719\n",
      "Epoch: 955; train loss=0.000806; validation loss=0.000577\n",
      "Epoch: 956; train loss=0.000752; validation loss=0.000481\n",
      "Epoch: 957; train loss=0.000769; validation loss=0.000992\n",
      "Epoch: 958; train loss=0.000737; validation loss=0.000563\n",
      "Epoch: 959; train loss=0.000769; validation loss=0.000643\n",
      "Epoch: 960; train loss=0.000758; validation loss=0.001069\n",
      "Epoch: 961; train loss=0.000731; validation loss=0.000775\n",
      "Epoch: 962; train loss=0.000753; validation loss=0.000717\n",
      "Epoch: 963; train loss=0.000760; validation loss=0.000634\n",
      "Epoch: 964; train loss=0.000742; validation loss=0.000747\n",
      "Epoch: 965; train loss=0.000730; validation loss=0.000609\n",
      "Epoch: 966; train loss=0.000785; validation loss=0.000618\n",
      "Epoch: 967; train loss=0.000738; validation loss=0.000688\n",
      "Epoch: 968; train loss=0.000733; validation loss=0.000706\n",
      "Epoch: 969; train loss=0.000751; validation loss=0.000761\n",
      "Epoch: 970; train loss=0.000805; validation loss=0.000617\n",
      "Epoch: 971; train loss=0.000729; validation loss=0.000579\n",
      "Epoch: 972; train loss=0.000758; validation loss=0.000549\n",
      "Epoch: 973; train loss=0.000703; validation loss=0.000556\n",
      "Epoch: 974; train loss=0.000754; validation loss=0.000969\n",
      "Epoch: 975; train loss=0.000695; validation loss=0.000540\n",
      "Epoch: 976; train loss=0.000733; validation loss=0.000737\n",
      "Epoch: 977; train loss=0.000745; validation loss=0.000606\n",
      "Epoch: 978; train loss=0.000784; validation loss=0.000520\n",
      "Epoch: 979; train loss=0.000689; validation loss=0.000692\n",
      "Epoch: 980; train loss=0.000842; validation loss=0.000609\n",
      "Epoch: 981; train loss=0.000727; validation loss=0.000564\n",
      "Epoch: 982; train loss=0.000690; validation loss=0.000726\n",
      "Epoch: 983; train loss=0.000782; validation loss=0.000685\n",
      "Epoch: 984; train loss=0.000720; validation loss=0.000606\n",
      "Epoch: 985; train loss=0.000715; validation loss=0.000567\n",
      "Epoch: 986; train loss=0.000752; validation loss=0.000845\n",
      "Epoch: 987; train loss=0.000731; validation loss=0.000688\n",
      "Epoch: 988; train loss=0.000724; validation loss=0.001291\n",
      "Epoch: 989; train loss=0.000747; validation loss=0.000579\n",
      "Epoch: 990; train loss=0.000710; validation loss=0.000640\n",
      "Epoch: 991; train loss=0.000729; validation loss=0.000585\n",
      "Epoch: 992; train loss=0.000696; validation loss=0.000775\n",
      "Epoch: 993; train loss=0.000715; validation loss=0.000768\n",
      "Epoch: 994; train loss=0.000727; validation loss=0.000739\n",
      "Epoch: 995; train loss=0.000772; validation loss=0.000639\n",
      "Epoch: 996; train loss=0.000724; validation loss=0.000580\n",
      "Epoch: 997; train loss=0.000735; validation loss=0.000534\n",
      "Epoch: 998; train loss=0.000736; validation loss=0.000755\n",
      "Epoch: 999; train loss=0.000737; validation loss=0.000677\n",
      "Epoch: 1000; train loss=0.000704; validation loss=0.000615\n",
      "Epoch: 1001; train loss=0.000709; validation loss=0.000692\n",
      "Epoch: 1002; train loss=0.000742; validation loss=0.000937\n",
      "Epoch: 1003; train loss=0.000734; validation loss=0.000741\n",
      "Epoch: 1004; train loss=0.000742; validation loss=0.000921\n",
      "Epoch: 1005; train loss=0.000739; validation loss=0.000671\n",
      "Epoch: 1006; train loss=0.000676; validation loss=0.000704\n",
      "Epoch: 1007; train loss=0.000691; validation loss=0.000606\n",
      "Epoch: 1008; train loss=0.000763; validation loss=0.000826\n",
      "Epoch: 1009; train loss=0.000697; validation loss=0.000529\n",
      "Epoch: 1010; train loss=0.000716; validation loss=0.000571\n",
      "Epoch: 1011; train loss=0.000723; validation loss=0.000751\n",
      "Epoch: 1012; train loss=0.000722; validation loss=0.000734\n",
      "Epoch: 1013; train loss=0.000777; validation loss=0.000783\n",
      "Epoch: 1014; train loss=0.000715; validation loss=0.000508\n",
      "Epoch: 1015; train loss=0.000690; validation loss=0.000879\n",
      "Epoch: 1016; train loss=0.000730; validation loss=0.000695\n",
      "Epoch: 1017; train loss=0.000697; validation loss=0.000989\n",
      "Epoch: 1018; train loss=0.000695; validation loss=0.000622\n",
      "Epoch: 1019; train loss=0.000736; validation loss=0.000551\n",
      "Epoch: 1020; train loss=0.000687; validation loss=0.000909\n",
      "Epoch: 1021; train loss=0.000733; validation loss=0.000642\n",
      "Epoch: 1022; train loss=0.000741; validation loss=0.000554\n",
      "Epoch: 1023; train loss=0.000677; validation loss=0.000635\n",
      "Epoch: 1024; train loss=0.000689; validation loss=0.000690\n",
      "Epoch: 1025; train loss=0.000688; validation loss=0.000634\n",
      "Epoch: 1026; train loss=0.000726; validation loss=0.000763\n",
      "Epoch: 1027; train loss=0.000700; validation loss=0.000813\n",
      "Epoch: 1028; train loss=0.000720; validation loss=0.000856\n",
      "Epoch: 1029; train loss=0.000707; validation loss=0.000669\n",
      "Epoch: 1030; train loss=0.000714; validation loss=0.000826\n",
      "Epoch: 1031; train loss=0.000715; validation loss=0.000529\n",
      "Epoch: 1032; train loss=0.000701; validation loss=0.000711\n",
      "Epoch: 1033; train loss=0.000745; validation loss=0.000835\n",
      "Epoch: 1034; train loss=0.000667; validation loss=0.000550\n",
      "Epoch: 1035; train loss=0.000732; validation loss=0.000865\n",
      "Epoch: 1036; train loss=0.000707; validation loss=0.000661\n",
      "Epoch: 1037; train loss=0.000693; validation loss=0.000614\n",
      "Epoch: 1038; train loss=0.000677; validation loss=0.000641\n",
      "Epoch: 1039; train loss=0.000696; validation loss=0.000703\n",
      "Epoch: 1040; train loss=0.000774; validation loss=0.000761\n",
      "Epoch: 1041; train loss=0.000709; validation loss=0.000715\n",
      "Epoch: 1042; train loss=0.000698; validation loss=0.000675\n",
      "Epoch: 1043; train loss=0.000689; validation loss=0.000778\n",
      "Epoch: 1044; train loss=0.000709; validation loss=0.000536\n",
      "Epoch: 1045; train loss=0.000692; validation loss=0.000594\n",
      "Epoch: 1046; train loss=0.000754; validation loss=0.000777\n",
      "Epoch: 1047; train loss=0.000679; validation loss=0.000542\n",
      "Epoch: 1048; train loss=0.000673; validation loss=0.000821\n",
      "Epoch: 1049; train loss=0.000762; validation loss=0.000767\n",
      "Epoch: 1050; train loss=0.000673; validation loss=0.000667\n",
      "Epoch: 1051; train loss=0.000711; validation loss=0.000535\n",
      "Epoch: 1052; train loss=0.000716; validation loss=0.000636\n",
      "Epoch: 1053; train loss=0.000687; validation loss=0.000666\n",
      "Epoch: 1054; train loss=0.000715; validation loss=0.000678\n",
      "Epoch: 1055; train loss=0.000692; validation loss=0.000796\n",
      "Epoch: 1056; train loss=0.000692; validation loss=0.000570\n",
      "Epoch: 1057; train loss=0.000679; validation loss=0.001061\n",
      "Epoch: 1058; train loss=0.000663; validation loss=0.000724\n",
      "Epoch: 1059; train loss=0.000722; validation loss=0.000594\n",
      "Epoch: 1060; train loss=0.000695; validation loss=0.000934\n",
      "Epoch: 1061; train loss=0.000707; validation loss=0.000882\n",
      "Epoch: 1062; train loss=0.000668; validation loss=0.000730\n",
      "Epoch: 1063; train loss=0.000714; validation loss=0.000809\n",
      "Epoch: 1064; train loss=0.000699; validation loss=0.000669\n",
      "Epoch: 1065; train loss=0.000689; validation loss=0.000713\n",
      "Epoch: 1066; train loss=0.000696; validation loss=0.000700\n",
      "Epoch: 1067; train loss=0.000697; validation loss=0.000764\n",
      "Epoch: 1068; train loss=0.000724; validation loss=0.000856\n",
      "Epoch: 1069; train loss=0.000695; validation loss=0.000541\n",
      "Epoch: 1070; train loss=0.000673; validation loss=0.000891\n",
      "Epoch: 1071; train loss=0.000716; validation loss=0.000644\n",
      "Epoch: 1072; train loss=0.000711; validation loss=0.000805\n",
      "Epoch: 1073; train loss=0.000644; validation loss=0.000929\n",
      "Epoch: 1074; train loss=0.000715; validation loss=0.000561\n",
      "Epoch: 1075; train loss=0.000676; validation loss=0.000477\n",
      "Epoch: 1076; train loss=0.000696; validation loss=0.000708\n",
      "Epoch: 1077; train loss=0.000675; validation loss=0.000697\n",
      "Epoch: 1078; train loss=0.000686; validation loss=0.000845\n",
      "Epoch: 1079; train loss=0.000679; validation loss=0.000734\n",
      "Epoch: 1080; train loss=0.000714; validation loss=0.000745\n",
      "Epoch: 1081; train loss=0.000707; validation loss=0.000617\n",
      "Epoch: 1082; train loss=0.000684; validation loss=0.000557\n",
      "Epoch: 1083; train loss=0.000715; validation loss=0.000746\n",
      "Epoch: 1084; train loss=0.000690; validation loss=0.000749\n",
      "Epoch: 1085; train loss=0.000671; validation loss=0.000594\n",
      "Epoch: 1086; train loss=0.000703; validation loss=0.000566\n",
      "Epoch: 1087; train loss=0.000663; validation loss=0.000681\n",
      "Epoch: 1088; train loss=0.000679; validation loss=0.000641\n",
      "Epoch: 1089; train loss=0.000691; validation loss=0.000558\n",
      "Epoch: 1090; train loss=0.000709; validation loss=0.000651\n",
      "Epoch: 1091; train loss=0.000677; validation loss=0.000567\n",
      "Epoch: 1092; train loss=0.000731; validation loss=0.000866\n",
      "Epoch: 1093; train loss=0.000687; validation loss=0.000627\n",
      "Epoch: 1094; train loss=0.000662; validation loss=0.000597\n",
      "Epoch: 1095; train loss=0.000699; validation loss=0.000501\n",
      "Epoch: 1096; train loss=0.000706; validation loss=0.000546\n",
      "Epoch: 1097; train loss=0.000685; validation loss=0.000984\n",
      "Epoch: 1098; train loss=0.000644; validation loss=0.000723\n",
      "Epoch: 1099; train loss=0.000676; validation loss=0.000608\n",
      "Epoch: 1100; train loss=0.000711; validation loss=0.000554\n",
      "Epoch: 1101; train loss=0.000711; validation loss=0.000648\n",
      "Epoch: 1102; train loss=0.000683; validation loss=0.000577\n",
      "Epoch: 1103; train loss=0.000667; validation loss=0.000730\n",
      "Epoch: 1104; train loss=0.000679; validation loss=0.000617\n",
      "Epoch: 1105; train loss=0.000677; validation loss=0.000877\n",
      "Epoch: 1106; train loss=0.000736; validation loss=0.000549\n",
      "Epoch: 1107; train loss=0.000643; validation loss=0.000556\n",
      "Epoch: 1108; train loss=0.000662; validation loss=0.000656\n",
      "Epoch: 1109; train loss=0.000680; validation loss=0.000844\n",
      "Epoch: 1110; train loss=0.000677; validation loss=0.000631\n",
      "Epoch: 1111; train loss=0.000711; validation loss=0.000718\n",
      "Epoch: 1112; train loss=0.000662; validation loss=0.000520\n",
      "Epoch: 1113; train loss=0.000708; validation loss=0.000605\n",
      "Epoch: 1114; train loss=0.000677; validation loss=0.000562\n",
      "Epoch: 1115; train loss=0.000700; validation loss=0.000993\n",
      "Epoch: 1116; train loss=0.000683; validation loss=0.000612\n",
      "Epoch: 1117; train loss=0.000649; validation loss=0.000665\n",
      "Epoch: 1118; train loss=0.000696; validation loss=0.000708\n",
      "Epoch: 1119; train loss=0.000656; validation loss=0.000594\n",
      "Epoch: 1120; train loss=0.000720; validation loss=0.000543\n",
      "Epoch: 1121; train loss=0.000675; validation loss=0.000606\n",
      "Epoch: 1122; train loss=0.000698; validation loss=0.000689\n",
      "Epoch: 1123; train loss=0.000699; validation loss=0.000483\n",
      "Epoch: 1124; train loss=0.000632; validation loss=0.000769\n",
      "Epoch: 1125; train loss=0.000691; validation loss=0.000441\n",
      "Epoch: 1126; train loss=0.000642; validation loss=0.000619\n",
      "Epoch: 1127; train loss=0.000697; validation loss=0.000577\n",
      "Epoch: 1128; train loss=0.000647; validation loss=0.000670\n",
      "Epoch: 1129; train loss=0.000717; validation loss=0.001180\n",
      "Epoch: 1130; train loss=0.000724; validation loss=0.000594\n",
      "Epoch: 1131; train loss=0.000651; validation loss=0.000567\n",
      "Epoch: 1132; train loss=0.000666; validation loss=0.000762\n",
      "Epoch: 1133; train loss=0.000720; validation loss=0.000408\n",
      "Epoch: 1134; train loss=0.000641; validation loss=0.000818\n",
      "Epoch: 1135; train loss=0.000659; validation loss=0.000597\n",
      "Epoch: 1136; train loss=0.000642; validation loss=0.000738\n",
      "Epoch: 1137; train loss=0.000693; validation loss=0.000543\n",
      "Epoch: 1138; train loss=0.000690; validation loss=0.000791\n",
      "Epoch: 1139; train loss=0.000643; validation loss=0.000800\n",
      "Epoch: 1140; train loss=0.000746; validation loss=0.000933\n",
      "Epoch: 1141; train loss=0.000643; validation loss=0.000541\n",
      "Epoch: 1142; train loss=0.000633; validation loss=0.000519\n",
      "Epoch: 1143; train loss=0.000676; validation loss=0.000511\n",
      "Epoch: 1144; train loss=0.000677; validation loss=0.000773\n",
      "Epoch: 1145; train loss=0.000649; validation loss=0.000739\n",
      "Epoch: 1146; train loss=0.000703; validation loss=0.001293\n",
      "Epoch: 1147; train loss=0.000705; validation loss=0.000699\n",
      "Epoch: 1148; train loss=0.000642; validation loss=0.000562\n",
      "Epoch: 1149; train loss=0.000669; validation loss=0.000717\n",
      "Epoch: 1150; train loss=0.000660; validation loss=0.000531\n",
      "Epoch: 1151; train loss=0.000665; validation loss=0.000608\n",
      "Epoch: 1152; train loss=0.000682; validation loss=0.000930\n",
      "Epoch: 1153; train loss=0.000705; validation loss=0.000502\n",
      "Epoch: 1154; train loss=0.000632; validation loss=0.000695\n",
      "Epoch: 1155; train loss=0.000672; validation loss=0.000762\n",
      "Epoch: 1156; train loss=0.000697; validation loss=0.000546\n",
      "Epoch: 1157; train loss=0.000658; validation loss=0.000428\n",
      "Epoch: 1158; train loss=0.000643; validation loss=0.000702\n",
      "Epoch: 1159; train loss=0.000669; validation loss=0.000588\n",
      "Epoch: 1160; train loss=0.000698; validation loss=0.000603\n",
      "Epoch: 1161; train loss=0.000654; validation loss=0.000571\n",
      "Epoch: 1162; train loss=0.000673; validation loss=0.000676\n",
      "Epoch: 1163; train loss=0.000657; validation loss=0.000760\n",
      "Epoch: 1164; train loss=0.000712; validation loss=0.000458\n",
      "Epoch: 1165; train loss=0.000679; validation loss=0.000529\n",
      "Epoch: 1166; train loss=0.000687; validation loss=0.000783\n",
      "Epoch: 1167; train loss=0.000659; validation loss=0.000557\n",
      "Epoch: 1168; train loss=0.000675; validation loss=0.000678\n",
      "Epoch: 1169; train loss=0.000658; validation loss=0.000597\n",
      "Epoch: 1170; train loss=0.000652; validation loss=0.000564\n",
      "Epoch: 1171; train loss=0.000661; validation loss=0.000606\n",
      "Epoch: 1172; train loss=0.000674; validation loss=0.000490\n",
      "Epoch: 1173; train loss=0.000662; validation loss=0.000429\n",
      "Epoch: 1174; train loss=0.000645; validation loss=0.000756\n",
      "Epoch: 1175; train loss=0.000636; validation loss=0.000969\n",
      "Epoch: 1176; train loss=0.000732; validation loss=0.000542\n",
      "Epoch: 1177; train loss=0.000645; validation loss=0.000630\n",
      "Epoch: 1178; train loss=0.000682; validation loss=0.000628\n",
      "Epoch: 1179; train loss=0.000673; validation loss=0.000590\n",
      "Epoch: 1180; train loss=0.000664; validation loss=0.000512\n",
      "Epoch: 1181; train loss=0.000695; validation loss=0.000579\n",
      "Epoch: 1182; train loss=0.000631; validation loss=0.000594\n",
      "Epoch: 1183; train loss=0.000679; validation loss=0.000773\n",
      "Epoch: 1184; train loss=0.000650; validation loss=0.000642\n",
      "Epoch: 1185; train loss=0.000670; validation loss=0.000699\n",
      "Epoch: 1186; train loss=0.000649; validation loss=0.000513\n",
      "Epoch: 1187; train loss=0.000621; validation loss=0.000696\n",
      "Epoch: 1188; train loss=0.000679; validation loss=0.000806\n",
      "Epoch: 1189; train loss=0.000665; validation loss=0.000662\n",
      "Epoch: 1190; train loss=0.000649; validation loss=0.001085\n",
      "Epoch: 1191; train loss=0.000686; validation loss=0.000496\n",
      "Epoch: 1192; train loss=0.000668; validation loss=0.000638\n",
      "Epoch: 1193; train loss=0.000667; validation loss=0.001006\n",
      "Epoch: 1194; train loss=0.000712; validation loss=0.000714\n",
      "Epoch: 1195; train loss=0.000638; validation loss=0.000588\n",
      "Epoch: 1196; train loss=0.000676; validation loss=0.000803\n",
      "Epoch: 1197; train loss=0.000604; validation loss=0.000582\n",
      "Epoch: 1198; train loss=0.000627; validation loss=0.000786\n",
      "Epoch: 1199; train loss=0.000683; validation loss=0.000569\n",
      "Epoch: 1200; train loss=0.000612; validation loss=0.000705\n",
      "Epoch: 1201; train loss=0.000702; validation loss=0.000732\n",
      "Epoch: 1202; train loss=0.000638; validation loss=0.000852\n",
      "Epoch: 1203; train loss=0.000676; validation loss=0.000595\n",
      "Epoch: 1204; train loss=0.000682; validation loss=0.000428\n",
      "Epoch: 1205; train loss=0.000646; validation loss=0.000742\n",
      "Epoch: 1206; train loss=0.000656; validation loss=0.000717\n",
      "Epoch: 1207; train loss=0.000640; validation loss=0.000590\n",
      "Epoch: 1208; train loss=0.000663; validation loss=0.000498\n",
      "Epoch: 1209; train loss=0.000612; validation loss=0.000827\n",
      "Epoch: 1210; train loss=0.000684; validation loss=0.000667\n",
      "Epoch: 1211; train loss=0.000646; validation loss=0.000865\n",
      "Epoch: 1212; train loss=0.000658; validation loss=0.000661\n",
      "Epoch: 1213; train loss=0.000653; validation loss=0.000515\n",
      "Epoch: 1214; train loss=0.000651; validation loss=0.000706\n",
      "Epoch: 1215; train loss=0.000671; validation loss=0.000605\n",
      "Epoch: 1216; train loss=0.000658; validation loss=0.000539\n",
      "Epoch: 1217; train loss=0.000624; validation loss=0.001049\n",
      "Epoch: 1218; train loss=0.000629; validation loss=0.000764\n",
      "Epoch: 1219; train loss=0.000702; validation loss=0.000792\n",
      "Epoch: 1220; train loss=0.000638; validation loss=0.000612\n",
      "Epoch: 1221; train loss=0.000664; validation loss=0.000584\n",
      "Epoch: 1222; train loss=0.000620; validation loss=0.000424\n",
      "Epoch: 1223; train loss=0.000617; validation loss=0.000591\n",
      "Epoch: 1224; train loss=0.000706; validation loss=0.000535\n",
      "Epoch: 1225; train loss=0.000673; validation loss=0.000614\n",
      "Epoch: 1226; train loss=0.000668; validation loss=0.000672\n",
      "Epoch: 1227; train loss=0.000628; validation loss=0.000932\n",
      "Epoch: 1228; train loss=0.000698; validation loss=0.000669\n",
      "Epoch: 1229; train loss=0.000721; validation loss=0.000819\n",
      "Epoch: 1230; train loss=0.000615; validation loss=0.000846\n",
      "Epoch: 1231; train loss=0.000667; validation loss=0.000737\n",
      "Epoch: 1232; train loss=0.000589; validation loss=0.000618\n",
      "Epoch: 1233; train loss=0.000700; validation loss=0.000425\n",
      "Epoch: 1234; train loss=0.000655; validation loss=0.000833\n",
      "Epoch: 1235; train loss=0.000699; validation loss=0.000625\n",
      "Epoch: 1236; train loss=0.000651; validation loss=0.000435\n",
      "Epoch: 1237; train loss=0.000638; validation loss=0.000515\n",
      "Epoch: 1238; train loss=0.000644; validation loss=0.000542\n",
      "Epoch: 1239; train loss=0.000642; validation loss=0.000909\n",
      "Epoch: 1240; train loss=0.000711; validation loss=0.000696\n",
      "Epoch: 1241; train loss=0.000642; validation loss=0.000570\n",
      "Epoch: 1242; train loss=0.000624; validation loss=0.000534\n",
      "Epoch: 1243; train loss=0.000636; validation loss=0.000735\n",
      "Epoch: 1244; train loss=0.000694; validation loss=0.000723\n",
      "Epoch: 1245; train loss=0.000622; validation loss=0.000570\n",
      "Epoch: 1246; train loss=0.000655; validation loss=0.000615\n",
      "Epoch: 1247; train loss=0.000637; validation loss=0.000554\n",
      "Epoch: 1248; train loss=0.000625; validation loss=0.000467\n",
      "Epoch: 1249; train loss=0.000652; validation loss=0.000406\n",
      "Epoch: 1250; train loss=0.000649; validation loss=0.000523\n",
      "Epoch: 1251; train loss=0.000680; validation loss=0.000621\n",
      "Epoch: 1252; train loss=0.000654; validation loss=0.000574\n",
      "Epoch: 1253; train loss=0.000623; validation loss=0.000703\n",
      "Epoch: 1254; train loss=0.000653; validation loss=0.000830\n",
      "Epoch: 1255; train loss=0.000675; validation loss=0.000725\n",
      "Epoch: 1256; train loss=0.000637; validation loss=0.000478\n",
      "Epoch: 1257; train loss=0.000624; validation loss=0.000617\n",
      "Epoch: 1258; train loss=0.000667; validation loss=0.001029\n",
      "Epoch: 1259; train loss=0.000644; validation loss=0.001099\n",
      "Epoch: 1260; train loss=0.000710; validation loss=0.000829\n",
      "Epoch: 1261; train loss=0.000623; validation loss=0.000825\n",
      "Epoch: 1262; train loss=0.000673; validation loss=0.000770\n",
      "Epoch: 1263; train loss=0.000619; validation loss=0.000526\n",
      "Epoch: 1264; train loss=0.000631; validation loss=0.000666\n",
      "Epoch: 1265; train loss=0.000651; validation loss=0.001074\n",
      "Epoch: 1266; train loss=0.000638; validation loss=0.000713\n",
      "Epoch: 1267; train loss=0.000686; validation loss=0.000888\n",
      "Epoch: 1268; train loss=0.000613; validation loss=0.000894\n",
      "Epoch: 1269; train loss=0.000682; validation loss=0.000737\n",
      "Epoch: 1270; train loss=0.000663; validation loss=0.000601\n",
      "Epoch: 1271; train loss=0.000660; validation loss=0.000887\n",
      "Epoch: 1272; train loss=0.000646; validation loss=0.000666\n",
      "Epoch: 1273; train loss=0.000646; validation loss=0.000997\n",
      "Epoch: 1274; train loss=0.000659; validation loss=0.000559\n",
      "Epoch: 1275; train loss=0.000611; validation loss=0.000411\n",
      "Epoch: 1276; train loss=0.000680; validation loss=0.000459\n",
      "Epoch: 1277; train loss=0.000621; validation loss=0.001080\n",
      "Epoch: 1278; train loss=0.000636; validation loss=0.000432\n",
      "Epoch: 1279; train loss=0.000647; validation loss=0.000415\n",
      "Epoch: 1280; train loss=0.000625; validation loss=0.000581\n",
      "Epoch: 1281; train loss=0.000664; validation loss=0.000596\n",
      "Epoch: 1282; train loss=0.000635; validation loss=0.000541\n",
      "Epoch: 1283; train loss=0.000652; validation loss=0.000528\n",
      "Epoch: 1284; train loss=0.000626; validation loss=0.000626\n",
      "Epoch: 1285; train loss=0.000642; validation loss=0.000516\n",
      "Epoch: 1286; train loss=0.000706; validation loss=0.000787\n",
      "Epoch: 1287; train loss=0.000606; validation loss=0.000514\n",
      "Epoch: 1288; train loss=0.000655; validation loss=0.000801\n",
      "Epoch: 1289; train loss=0.000644; validation loss=0.000755\n",
      "Epoch: 1290; train loss=0.000638; validation loss=0.000457\n",
      "Epoch: 1291; train loss=0.000666; validation loss=0.000764\n",
      "Epoch: 1292; train loss=0.000699; validation loss=0.000721\n",
      "Epoch: 1293; train loss=0.000610; validation loss=0.000517\n",
      "Epoch: 1294; train loss=0.000629; validation loss=0.000575\n",
      "Epoch: 1295; train loss=0.000657; validation loss=0.000522\n",
      "Epoch: 1296; train loss=0.000646; validation loss=0.000709\n",
      "Epoch: 1297; train loss=0.000633; validation loss=0.000540\n",
      "Epoch: 1298; train loss=0.000671; validation loss=0.000715\n",
      "Epoch: 1299; train loss=0.000624; validation loss=0.000514\n",
      "Epoch: 1300; train loss=0.000657; validation loss=0.000707\n",
      "Epoch: 1301; train loss=0.000657; validation loss=0.000581\n",
      "Epoch: 1302; train loss=0.000628; validation loss=0.000607\n",
      "Epoch: 1303; train loss=0.000635; validation loss=0.000555\n",
      "Epoch: 1304; train loss=0.000654; validation loss=0.000504\n",
      "Epoch: 1305; train loss=0.000645; validation loss=0.000656\n",
      "Epoch: 1306; train loss=0.000637; validation loss=0.000617\n",
      "Epoch: 1307; train loss=0.000618; validation loss=0.000500\n",
      "Epoch: 1308; train loss=0.000609; validation loss=0.000842\n",
      "Epoch: 1309; train loss=0.000642; validation loss=0.000744\n",
      "Epoch: 1310; train loss=0.000667; validation loss=0.000711\n",
      "Epoch: 1311; train loss=0.000606; validation loss=0.000606\n",
      "Epoch: 1312; train loss=0.000649; validation loss=0.000774\n",
      "Epoch: 1313; train loss=0.000643; validation loss=0.000673\n",
      "Epoch: 1314; train loss=0.000652; validation loss=0.000625\n",
      "Epoch: 1315; train loss=0.000690; validation loss=0.000538\n",
      "Epoch: 1316; train loss=0.000626; validation loss=0.000713\n",
      "Epoch: 1317; train loss=0.000632; validation loss=0.000503\n",
      "Epoch: 1318; train loss=0.000628; validation loss=0.000770\n",
      "Epoch: 1319; train loss=0.000656; validation loss=0.000613\n",
      "Epoch: 1320; train loss=0.000633; validation loss=0.000567\n",
      "Epoch: 1321; train loss=0.000691; validation loss=0.000452\n",
      "Epoch: 1322; train loss=0.000662; validation loss=0.000792\n",
      "Epoch: 1323; train loss=0.000648; validation loss=0.000608\n",
      "Epoch: 1324; train loss=0.000641; validation loss=0.000813\n",
      "Epoch: 1325; train loss=0.000607; validation loss=0.000681\n",
      "Epoch: 1326; train loss=0.000644; validation loss=0.000804\n",
      "Epoch: 1327; train loss=0.000640; validation loss=0.000425\n",
      "Epoch: 1328; train loss=0.000633; validation loss=0.000514\n",
      "Epoch: 1329; train loss=0.000656; validation loss=0.000728\n",
      "Epoch: 1330; train loss=0.000641; validation loss=0.000766\n",
      "Epoch: 1331; train loss=0.000674; validation loss=0.000863\n",
      "Epoch: 1332; train loss=0.000627; validation loss=0.000544\n",
      "Epoch: 1333; train loss=0.000656; validation loss=0.000685\n",
      "Epoch: 1334; train loss=0.000629; validation loss=0.000771\n",
      "Epoch: 1335; train loss=0.000626; validation loss=0.000464\n",
      "Epoch: 1336; train loss=0.000644; validation loss=0.000682\n",
      "Epoch: 1337; train loss=0.000627; validation loss=0.000620\n",
      "Epoch: 1338; train loss=0.000606; validation loss=0.000601\n",
      "Epoch: 1339; train loss=0.000643; validation loss=0.000614\n",
      "Epoch: 1340; train loss=0.000675; validation loss=0.000552\n",
      "Epoch: 1341; train loss=0.000600; validation loss=0.000533\n",
      "Epoch: 1342; train loss=0.000652; validation loss=0.000652\n",
      "Epoch: 1343; train loss=0.000658; validation loss=0.000762\n",
      "Epoch: 1344; train loss=0.000616; validation loss=0.000686\n",
      "Epoch: 1345; train loss=0.000610; validation loss=0.000525\n",
      "Epoch: 1346; train loss=0.000607; validation loss=0.000497\n",
      "Epoch: 1347; train loss=0.000626; validation loss=0.000660\n",
      "Epoch: 1348; train loss=0.000639; validation loss=0.000837\n",
      "Epoch: 1349; train loss=0.000654; validation loss=0.000411\n",
      "Epoch: 1350; train loss=0.000638; validation loss=0.000727\n",
      "Epoch: 1351; train loss=0.000660; validation loss=0.000648\n",
      "Epoch: 1352; train loss=0.000605; validation loss=0.000487\n",
      "Epoch: 1353; train loss=0.000633; validation loss=0.000681\n",
      "Epoch: 1354; train loss=0.000616; validation loss=0.000467\n",
      "Epoch: 1355; train loss=0.000629; validation loss=0.000578\n",
      "Epoch: 1356; train loss=0.000663; validation loss=0.000606\n",
      "Epoch: 1357; train loss=0.000673; validation loss=0.000739\n",
      "Epoch: 1358; train loss=0.000646; validation loss=0.000841\n",
      "Epoch: 1359; train loss=0.000683; validation loss=0.000540\n",
      "Epoch: 1360; train loss=0.000617; validation loss=0.000733\n",
      "Epoch: 1361; train loss=0.000629; validation loss=0.000827\n",
      "Epoch: 1362; train loss=0.000618; validation loss=0.000639\n",
      "Epoch: 1363; train loss=0.000627; validation loss=0.000699\n",
      "Epoch: 1364; train loss=0.000630; validation loss=0.000695\n",
      "Epoch: 1365; train loss=0.000634; validation loss=0.000842\n",
      "Epoch: 1366; train loss=0.000665; validation loss=0.000420\n",
      "Epoch: 1367; train loss=0.000627; validation loss=0.000659\n",
      "Epoch: 1368; train loss=0.000637; validation loss=0.000704\n",
      "Epoch: 1369; train loss=0.000639; validation loss=0.000465\n",
      "Epoch: 1370; train loss=0.000671; validation loss=0.000683\n",
      "Epoch: 1371; train loss=0.000575; validation loss=0.000548\n",
      "Epoch: 1372; train loss=0.000673; validation loss=0.001001\n",
      "Epoch: 1373; train loss=0.000635; validation loss=0.000813\n",
      "Epoch: 1374; train loss=0.000640; validation loss=0.000686\n",
      "Epoch: 1375; train loss=0.000635; validation loss=0.000495\n",
      "Epoch: 1376; train loss=0.000668; validation loss=0.000730\n",
      "Epoch: 1377; train loss=0.000669; validation loss=0.000581\n",
      "Epoch: 1378; train loss=0.000601; validation loss=0.000592\n",
      "Epoch: 1379; train loss=0.000626; validation loss=0.000487\n",
      "Epoch: 1380; train loss=0.000645; validation loss=0.000930\n",
      "Epoch: 1381; train loss=0.000620; validation loss=0.000473\n",
      "Epoch: 1382; train loss=0.000591; validation loss=0.000504\n",
      "Epoch: 1383; train loss=0.000642; validation loss=0.000613\n",
      "Epoch: 1384; train loss=0.000641; validation loss=0.000695\n",
      "Epoch: 1385; train loss=0.000626; validation loss=0.000611\n",
      "Epoch: 1386; train loss=0.000631; validation loss=0.000565\n",
      "Epoch: 1387; train loss=0.000649; validation loss=0.000479\n",
      "Epoch: 1388; train loss=0.000602; validation loss=0.000645\n",
      "Epoch: 1389; train loss=0.000651; validation loss=0.000649\n",
      "Epoch: 1390; train loss=0.000601; validation loss=0.001100\n",
      "Epoch: 1391; train loss=0.000635; validation loss=0.000578\n",
      "Epoch: 1392; train loss=0.000630; validation loss=0.000759\n",
      "Epoch: 1393; train loss=0.000610; validation loss=0.001096\n",
      "Epoch: 1394; train loss=0.000635; validation loss=0.000685\n",
      "Epoch: 1395; train loss=0.000646; validation loss=0.000493\n",
      "Epoch: 1396; train loss=0.000631; validation loss=0.000711\n",
      "Epoch: 1397; train loss=0.000627; validation loss=0.000507\n",
      "Epoch: 1398; train loss=0.000656; validation loss=0.000497\n",
      "Epoch: 1399; train loss=0.000582; validation loss=0.000460\n",
      "Epoch: 1400; train loss=0.000595; validation loss=0.001415\n",
      "Epoch: 1401; train loss=0.000671; validation loss=0.000852\n",
      "Epoch: 1402; train loss=0.000628; validation loss=0.000623\n",
      "Epoch: 1403; train loss=0.000600; validation loss=0.000687\n",
      "Epoch: 1404; train loss=0.000653; validation loss=0.000783\n",
      "Epoch: 1405; train loss=0.000603; validation loss=0.000615\n",
      "Epoch: 1406; train loss=0.000641; validation loss=0.000695\n",
      "Epoch: 1407; train loss=0.000638; validation loss=0.000592\n",
      "Epoch: 1408; train loss=0.000638; validation loss=0.000604\n",
      "Epoch: 1409; train loss=0.000661; validation loss=0.000687\n",
      "Epoch: 1410; train loss=0.000628; validation loss=0.000496\n",
      "Epoch: 1411; train loss=0.000622; validation loss=0.000445\n",
      "Epoch: 1412; train loss=0.000638; validation loss=0.000744\n",
      "Epoch: 1413; train loss=0.000624; validation loss=0.000561\n",
      "Epoch: 1414; train loss=0.000615; validation loss=0.000587\n",
      "Epoch: 1415; train loss=0.000621; validation loss=0.000887\n",
      "Epoch: 1416; train loss=0.000639; validation loss=0.000841\n",
      "Epoch: 1417; train loss=0.000636; validation loss=0.000623\n",
      "Epoch: 1418; train loss=0.000600; validation loss=0.000589\n",
      "Epoch: 1419; train loss=0.000602; validation loss=0.000445\n",
      "Epoch: 1420; train loss=0.000581; validation loss=0.000450\n",
      "Epoch: 1421; train loss=0.000693; validation loss=0.000662\n",
      "Epoch: 1422; train loss=0.000648; validation loss=0.000483\n",
      "Epoch: 1423; train loss=0.000648; validation loss=0.000498\n",
      "Epoch: 1424; train loss=0.000612; validation loss=0.000594\n",
      "Epoch: 1425; train loss=0.000657; validation loss=0.000575\n",
      "Epoch: 1426; train loss=0.000611; validation loss=0.000569\n",
      "Epoch: 1427; train loss=0.000597; validation loss=0.000477\n",
      "Epoch: 1428; train loss=0.000674; validation loss=0.000977\n",
      "Epoch: 1429; train loss=0.000600; validation loss=0.000468\n",
      "Epoch: 1430; train loss=0.000616; validation loss=0.000758\n",
      "Epoch: 1431; train loss=0.000605; validation loss=0.000525\n",
      "Epoch: 1432; train loss=0.000667; validation loss=0.000627\n",
      "Epoch: 1433; train loss=0.000630; validation loss=0.000617\n",
      "Epoch: 1434; train loss=0.000649; validation loss=0.000619\n",
      "Epoch: 1435; train loss=0.000620; validation loss=0.000443\n",
      "Epoch: 1436; train loss=0.000626; validation loss=0.000763\n",
      "Epoch: 1437; train loss=0.000591; validation loss=0.000549\n",
      "Epoch: 1438; train loss=0.000598; validation loss=0.000619\n",
      "Epoch: 1439; train loss=0.000643; validation loss=0.000456\n",
      "Epoch: 1440; train loss=0.000662; validation loss=0.000766\n",
      "Epoch: 1441; train loss=0.000639; validation loss=0.000610\n",
      "Epoch: 1442; train loss=0.000641; validation loss=0.000506\n",
      "Epoch: 1443; train loss=0.000630; validation loss=0.000502\n",
      "Epoch: 1444; train loss=0.000614; validation loss=0.000634\n",
      "Epoch: 1445; train loss=0.000606; validation loss=0.000545\n",
      "Epoch: 1446; train loss=0.000631; validation loss=0.000592\n",
      "Epoch: 1447; train loss=0.000586; validation loss=0.000516\n",
      "Epoch: 1448; train loss=0.000616; validation loss=0.000668\n",
      "Epoch: 1449; train loss=0.000647; validation loss=0.000440\n",
      "Epoch: 1450; train loss=0.000641; validation loss=0.000799\n",
      "Epoch: 1451; train loss=0.000661; validation loss=0.000461\n",
      "Epoch: 1452; train loss=0.000614; validation loss=0.000480\n",
      "Epoch: 1453; train loss=0.000585; validation loss=0.000615\n",
      "Epoch: 1454; train loss=0.000645; validation loss=0.000543\n",
      "Epoch: 1455; train loss=0.000635; validation loss=0.000612\n",
      "Epoch: 1456; train loss=0.000606; validation loss=0.000562\n",
      "Epoch: 1457; train loss=0.000621; validation loss=0.000628\n",
      "Epoch: 1458; train loss=0.000602; validation loss=0.000609\n",
      "Epoch: 1459; train loss=0.000629; validation loss=0.001053\n",
      "Epoch: 1460; train loss=0.000642; validation loss=0.000934\n",
      "Epoch: 1461; train loss=0.000607; validation loss=0.000411\n",
      "Epoch: 1462; train loss=0.000676; validation loss=0.000491\n",
      "Epoch: 1463; train loss=0.000594; validation loss=0.000586\n",
      "Epoch: 1464; train loss=0.000625; validation loss=0.000686\n",
      "Epoch: 1465; train loss=0.000654; validation loss=0.000565\n",
      "Epoch: 1466; train loss=0.000603; validation loss=0.000774\n",
      "Epoch: 1467; train loss=0.000643; validation loss=0.000592\n",
      "Epoch: 1468; train loss=0.000601; validation loss=0.000634\n",
      "Epoch: 1469; train loss=0.000627; validation loss=0.000467\n",
      "Epoch: 1470; train loss=0.000623; validation loss=0.000602\n",
      "Epoch: 1471; train loss=0.000619; validation loss=0.000661\n",
      "Epoch: 1472; train loss=0.000617; validation loss=0.000541\n",
      "Epoch: 1473; train loss=0.000592; validation loss=0.000582\n",
      "Epoch: 1474; train loss=0.000642; validation loss=0.000392\n",
      "Epoch: 1475; train loss=0.000607; validation loss=0.000849\n",
      "Epoch: 1476; train loss=0.000622; validation loss=0.000454\n",
      "Epoch: 1477; train loss=0.000635; validation loss=0.000616\n",
      "Epoch: 1478; train loss=0.000602; validation loss=0.000648\n",
      "Epoch: 1479; train loss=0.000648; validation loss=0.000634\n",
      "Epoch: 1480; train loss=0.000638; validation loss=0.000533\n",
      "Epoch: 1481; train loss=0.000583; validation loss=0.000696\n",
      "Epoch: 1482; train loss=0.000604; validation loss=0.000507\n",
      "Epoch: 1483; train loss=0.000598; validation loss=0.000526\n",
      "Epoch: 1484; train loss=0.000631; validation loss=0.000619\n",
      "Epoch: 1485; train loss=0.000602; validation loss=0.000555\n",
      "Epoch: 1486; train loss=0.000638; validation loss=0.000447\n",
      "Epoch: 1487; train loss=0.000612; validation loss=0.000840\n",
      "Epoch: 1488; train loss=0.000678; validation loss=0.000515\n",
      "Epoch: 1489; train loss=0.000616; validation loss=0.000472\n",
      "Epoch: 1490; train loss=0.000658; validation loss=0.000680\n",
      "Epoch: 1491; train loss=0.000622; validation loss=0.000621\n",
      "Epoch: 1492; train loss=0.000596; validation loss=0.001076\n",
      "Epoch: 1493; train loss=0.000658; validation loss=0.000601\n",
      "Epoch: 1494; train loss=0.000577; validation loss=0.000628\n",
      "Epoch: 1495; train loss=0.000590; validation loss=0.000422\n",
      "Epoch: 1496; train loss=0.000628; validation loss=0.000995\n",
      "Epoch: 1497; train loss=0.000579; validation loss=0.000717\n",
      "Epoch: 1498; train loss=0.000636; validation loss=0.000700\n",
      "Epoch: 1499; train loss=0.000631; validation loss=0.000612\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "hovertemplate": "epoch=%{x}<br>loss=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "showlegend": false,
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000,
          1001,
          1002,
          1003,
          1004,
          1005,
          1006,
          1007,
          1008,
          1009,
          1010,
          1011,
          1012,
          1013,
          1014,
          1015,
          1016,
          1017,
          1018,
          1019,
          1020,
          1021,
          1022,
          1023,
          1024,
          1025,
          1026,
          1027,
          1028,
          1029,
          1030,
          1031,
          1032,
          1033,
          1034,
          1035,
          1036,
          1037,
          1038,
          1039,
          1040,
          1041,
          1042,
          1043,
          1044,
          1045,
          1046,
          1047,
          1048,
          1049,
          1050,
          1051,
          1052,
          1053,
          1054,
          1055,
          1056,
          1057,
          1058,
          1059,
          1060,
          1061,
          1062,
          1063,
          1064,
          1065,
          1066,
          1067,
          1068,
          1069,
          1070,
          1071,
          1072,
          1073,
          1074,
          1075,
          1076,
          1077,
          1078,
          1079,
          1080,
          1081,
          1082,
          1083,
          1084,
          1085,
          1086,
          1087,
          1088,
          1089,
          1090,
          1091,
          1092,
          1093,
          1094,
          1095,
          1096,
          1097,
          1098,
          1099,
          1100,
          1101,
          1102,
          1103,
          1104,
          1105,
          1106,
          1107,
          1108,
          1109,
          1110,
          1111,
          1112,
          1113,
          1114,
          1115,
          1116,
          1117,
          1118,
          1119,
          1120,
          1121,
          1122,
          1123,
          1124,
          1125,
          1126,
          1127,
          1128,
          1129,
          1130,
          1131,
          1132,
          1133,
          1134,
          1135,
          1136,
          1137,
          1138,
          1139,
          1140,
          1141,
          1142,
          1143,
          1144,
          1145,
          1146,
          1147,
          1148,
          1149,
          1150,
          1151,
          1152,
          1153,
          1154,
          1155,
          1156,
          1157,
          1158,
          1159,
          1160,
          1161,
          1162,
          1163,
          1164,
          1165,
          1166,
          1167,
          1168,
          1169,
          1170,
          1171,
          1172,
          1173,
          1174,
          1175,
          1176,
          1177,
          1178,
          1179,
          1180,
          1181,
          1182,
          1183,
          1184,
          1185,
          1186,
          1187,
          1188,
          1189,
          1190,
          1191,
          1192,
          1193,
          1194,
          1195,
          1196,
          1197,
          1198,
          1199,
          1200,
          1201,
          1202,
          1203,
          1204,
          1205,
          1206,
          1207,
          1208,
          1209,
          1210,
          1211,
          1212,
          1213,
          1214,
          1215,
          1216,
          1217,
          1218,
          1219,
          1220,
          1221,
          1222,
          1223,
          1224,
          1225,
          1226,
          1227,
          1228,
          1229,
          1230,
          1231,
          1232,
          1233,
          1234,
          1235,
          1236,
          1237,
          1238,
          1239,
          1240,
          1241,
          1242,
          1243,
          1244,
          1245,
          1246,
          1247,
          1248,
          1249,
          1250,
          1251,
          1252,
          1253,
          1254,
          1255,
          1256,
          1257,
          1258,
          1259,
          1260,
          1261,
          1262,
          1263,
          1264,
          1265,
          1266,
          1267,
          1268,
          1269,
          1270,
          1271,
          1272,
          1273,
          1274,
          1275,
          1276,
          1277,
          1278,
          1279,
          1280,
          1281,
          1282,
          1283,
          1284,
          1285,
          1286,
          1287,
          1288,
          1289,
          1290,
          1291,
          1292,
          1293,
          1294,
          1295,
          1296,
          1297,
          1298,
          1299,
          1300,
          1301,
          1302,
          1303,
          1304,
          1305,
          1306,
          1307,
          1308,
          1309,
          1310,
          1311,
          1312,
          1313,
          1314,
          1315,
          1316,
          1317,
          1318,
          1319,
          1320,
          1321,
          1322,
          1323,
          1324,
          1325,
          1326,
          1327,
          1328,
          1329,
          1330,
          1331,
          1332,
          1333,
          1334,
          1335,
          1336,
          1337,
          1338,
          1339,
          1340,
          1341,
          1342,
          1343,
          1344,
          1345,
          1346,
          1347,
          1348,
          1349,
          1350,
          1351,
          1352,
          1353,
          1354,
          1355,
          1356,
          1357,
          1358,
          1359,
          1360,
          1361,
          1362,
          1363,
          1364,
          1365,
          1366,
          1367,
          1368,
          1369,
          1370,
          1371,
          1372,
          1373,
          1374,
          1375,
          1376,
          1377,
          1378,
          1379,
          1380,
          1381,
          1382,
          1383,
          1384,
          1385,
          1386,
          1387,
          1388,
          1389,
          1390,
          1391,
          1392,
          1393,
          1394,
          1395,
          1396,
          1397,
          1398,
          1399,
          1400,
          1401,
          1402,
          1403,
          1404,
          1405,
          1406,
          1407,
          1408,
          1409,
          1410,
          1411,
          1412,
          1413,
          1414,
          1415,
          1416,
          1417,
          1418,
          1419,
          1420,
          1421,
          1422,
          1423,
          1424,
          1425,
          1426,
          1427,
          1428,
          1429,
          1430,
          1431,
          1432,
          1433,
          1434,
          1435,
          1436,
          1437,
          1438,
          1439,
          1440,
          1441,
          1442,
          1443,
          1444,
          1445,
          1446,
          1447,
          1448,
          1449,
          1450,
          1451,
          1452,
          1453,
          1454,
          1455,
          1456,
          1457,
          1458,
          1459,
          1460,
          1461,
          1462,
          1463,
          1464,
          1465,
          1466,
          1467,
          1468,
          1469,
          1470,
          1471,
          1472,
          1473,
          1474,
          1475,
          1476,
          1477,
          1478,
          1479,
          1480,
          1481,
          1482,
          1483,
          1484,
          1485,
          1486,
          1487,
          1488,
          1489,
          1490,
          1491,
          1492,
          1493,
          1494,
          1495,
          1496,
          1497,
          1498,
          1499
         ],
         "xaxis": "x",
         "y": [
          0.24837253451239502,
          0.056940154351105304,
          0.04929833314566905,
          0.037637448234908256,
          0.020478817678098223,
          0.01568327195025684,
          0.014397265835562934,
          0.013252091170507692,
          0.012286655594728465,
          0.011650429424055739,
          0.010885081178676089,
          0.010172047077108566,
          0.00941834900757372,
          0.009226538634671412,
          0.0087177799391112,
          0.008375327434251479,
          0.008170904774798487,
          0.007663850334390944,
          0.007303168157967138,
          0.007207525992907575,
          0.00715413697758202,
          0.006646480455666565,
          0.0065362419521905685,
          0.006513304999985691,
          0.0061017648694391925,
          0.006165464754711805,
          0.005903140504128862,
          0.005702716707329482,
          0.0056190913620621724,
          0.005357194369472338,
          0.0054091772848719995,
          0.005247772807217191,
          0.005031369174903638,
          0.004983276469167883,
          0.0050712384050992845,
          0.004761843291359568,
          0.004721378401456574,
          0.004681831937445051,
          0.004616577575371946,
          0.004598846675073155,
          0.004440069066886357,
          0.0043005790130040905,
          0.004397688207718734,
          0.004172555701211724,
          0.004158781812749848,
          0.004298668053109015,
          0.004078175759940567,
          0.003927427046596375,
          0.004036260143582978,
          0.0037951521989434455,
          0.004073697348452197,
          0.0036091231086613795,
          0.0037884943474272873,
          0.0037270147152316945,
          0.0036911890725183903,
          0.003517361374659547,
          0.0036395488697833264,
          0.003649267818513624,
          0.0034290468617959174,
          0.003484606167944137,
          0.003427778922843739,
          0.0033860535572077383,
          0.0032411479206915284,
          0.0032220279875989953,
          0.003358337799574735,
          0.0033046363881565587,
          0.0030066231967807175,
          0.003132661495052179,
          0.0031711712147618125,
          0.003071207514389972,
          0.0030781220112768857,
          0.0029421101767452946,
          0.0030105176302565057,
          0.002773721545116821,
          0.002917231828989899,
          0.0029903167276783644,
          0.0028351905165336783,
          0.0027402981388887034,
          0.0028145569438436063,
          0.0028940237616497766,
          0.0027175598836248903,
          0.002762997267370093,
          0.0025915982267977746,
          0.002678328824529494,
          0.0026647520648423397,
          0.002640843794589011,
          0.0026336037076389544,
          0.0026117831244458086,
          0.002492174426283557,
          0.0025509160934061048,
          0.0024928258992035044,
          0.002582078035392847,
          0.002492996180273898,
          0.002492929716112566,
          0.0025447278223994702,
          0.002422094959187107,
          0.0024651903691403883,
          0.002420099574732128,
          0.0023468122177221448,
          0.0024017462564746885,
          0.0023238395243283224,
          0.0023137623395330406,
          0.0023324220043587957,
          0.002339924603646713,
          0.002278480375751817,
          0.002394296168220489,
          0.0022887811823034676,
          0.002260185170646833,
          0.0023088268975000404,
          0.002194906517372335,
          0.0022464907841601906,
          0.0021948915471202628,
          0.0022407280138229775,
          0.0021109650590073934,
          0.002157647639150148,
          0.00218064269762648,
          0.002174527488960081,
          0.002167039929576829,
          0.002109817156750165,
          0.0021157067921237327,
          0.0022205575549047087,
          0.0020592391042407285,
          0.0021273004950223035,
          0.0020982692032475003,
          0.0020004125176878384,
          0.0019930578574180982,
          0.0021302324398988085,
          0.002054249660243405,
          0.002018132292950892,
          0.0020961632931872356,
          0.0019507264330549518,
          0.002069284411880836,
          0.0019844033137756986,
          0.0019776320976089457,
          0.002032216588334058,
          0.0019712473280712136,
          0.0019529243499777573,
          0.001930294594636459,
          0.0019682870197039104,
          0.001938384113495156,
          0.002008363047465278,
          0.001931097060756531,
          0.002031275688106614,
          0.001842301051734539,
          0.0019036520778598091,
          0.0018716545521918644,
          0.001976846959396963,
          0.0019198034556337663,
          0.0017794472035087996,
          0.0019210603029722183,
          0.0018985505648062928,
          0.0018009050576234251,
          0.0018049545016811557,
          0.0018801515451795337,
          0.0018685078689327467,
          0.0018000788132876912,
          0.0018174403659669083,
          0.0018023114624198422,
          0.0017840023131746759,
          0.0017583373515834117,
          0.0018479602304101888,
          0.0017813677649295679,
          0.0018031864659579873,
          0.001742608102366544,
          0.0017595794300444252,
          0.0017795928031266795,
          0.001737886192434354,
          0.001780162829556362,
          0.0018112194440434311,
          0.0017157836650937472,
          0.0017136109992019176,
          0.0017467092122181586,
          0.001797102120411734,
          0.0017275384547800023,
          0.0017460618055491867,
          0.0016654426327752639,
          0.001712834214245669,
          0.0017119942864052618,
          0.0016666460308764216,
          0.0017484430113045635,
          0.001680194331160033,
          0.0016354842076922876,
          0.0017096740885978099,
          0.0016989346448415205,
          0.0017372213077391032,
          0.0016611929375125573,
          0.0016536002562171246,
          0.0016661019498972161,
          0.0016457399984471167,
          0.0016612447480883435,
          0.0015921906024089535,
          0.0016173357736606901,
          0.0016616735381576422,
          0.0016139377799139001,
          0.001596020063075301,
          0.0016897581512079235,
          0.001609681953959149,
          0.001635177232144205,
          0.0016553761121290045,
          0.0015575179676564615,
          0.0016172344840454124,
          0.0016173420058826233,
          0.0016100366465888907,
          0.0016068566157465714,
          0.0015722344982223215,
          0.0015771086470968796,
          0.0015725897390853761,
          0.0015612075591754208,
          0.0015613057604845976,
          0.001571027352362287,
          0.001626619869737523,
          0.0015660251361015731,
          0.0015900775033866018,
          0.0015632445561397368,
          0.0015984048336110694,
          0.001528005085495695,
          0.0015357686738922869,
          0.0015266815868045672,
          0.001533492448075761,
          0.0015704793881105913,
          0.0015232138203982763,
          0.0015274072269570932,
          0.0015356464014333574,
          0.0015238451939109888,
          0.0015406244743640105,
          0.0014789208406930739,
          0.0014984767977541495,
          0.0015700503945602295,
          0.0015432967158962396,
          0.0014158810892752377,
          0.0014854758661644774,
          0.0015252821198838736,
          0.0014747964892035353,
          0.001492394800455196,
          0.0014702067779269253,
          0.0014609475065397932,
          0.0014754911649868844,
          0.0015096590648920908,
          0.0014474087191714182,
          0.0015513622752459332,
          0.0014662277616281849,
          0.0014412485900592278,
          0.0014667216899318326,
          0.0014738717480968185,
          0.0014012202168887861,
          0.0014845841527445774,
          0.0014402158467792226,
          0.0013857707129881253,
          0.0014750595159314132,
          0.0014665762414151423,
          0.0014690632893410664,
          0.0014678812133590944,
          0.0013940025868615534,
          0.0015205618959376352,
          0.0014636442552526246,
          0.001433467483473773,
          0.0014046298926112,
          0.0014084770877264773,
          0.0013867561564701008,
          0.0015213468202768371,
          0.0014139439131833154,
          0.0013950486511297624,
          0.0014335272484880268,
          0.0014401409658182085,
          0.0013778441777566293,
          0.0014319964570096674,
          0.0013975734357352496,
          0.0013767660451396869,
          0.0014431279148278472,
          0.0013876384891180907,
          0.001458412021554701,
          0.0013777809923226003,
          0.001408647663837391,
          0.0013924990894398747,
          0.0014060093077299589,
          0.0013711953096696152,
          0.001376511972702015,
          0.0014279543961970129,
          0.0013570198778004642,
          0.0014182266778401374,
          0.0013804518789293377,
          0.0013048482296423283,
          0.0013778996416530488,
          0.0013944304710258567,
          0.001365610164257645,
          0.001375968963825071,
          0.001416620692876881,
          0.001369174146172068,
          0.0013868440471592935,
          0.001445835006599673,
          0.0013147404780263132,
          0.0013049029154940065,
          0.0013221930989105843,
          0.0013285335281833476,
          0.0013585979044796906,
          0.001319916062610307,
          0.0013404121375007979,
          0.0013709061743132096,
          0.0013480423914551717,
          0.0013576871405138811,
          0.0013155640634164368,
          0.0013711073675133352,
          0.0013135684346156679,
          0.0013424395756999343,
          0.0013233837917328007,
          0.0013582802623952992,
          0.0013499858966647717,
          0.001321571889901882,
          0.0013381011280780535,
          0.0012879437831285509,
          0.0013963119560780747,
          0.0013057511638702804,
          0.0012702101015006119,
          0.0012986870058890841,
          0.0013678176815827142,
          0.0012834732129633993,
          0.001388845510698801,
          0.0012434066611143285,
          0.0013589361901322,
          0.0013133800906338139,
          0.0012652662699110806,
          0.001236093349980058,
          0.0012990397984494507,
          0.0012621601674322656,
          0.001305308566648913,
          0.0013043808808243542,
          0.0012802721756854205,
          0.0013309341996618344,
          0.0012811345285011412,
          0.0012694447141520418,
          0.0012633128870931309,
          0.0012725179737480975,
          0.0013099339838668848,
          0.0012756693233798772,
          0.0012777851215104233,
          0.0012538627135360656,
          0.0013257232293839352,
          0.0012582271558988674,
          0.0012958315686986694,
          0.0012520919629064836,
          0.0012483299363419116,
          0.0012558701707795037,
          0.0012444001316363655,
          0.0013122011469823137,
          0.0012874067751173968,
          0.0013027659762567595,
          0.0012394657324262602,
          0.0012221397676581542,
          0.0012738624275482257,
          0.0012862029281361714,
          0.0012405972209656824,
          0.001262383935515251,
          0.0012037721400057046,
          0.0012711770866241472,
          0.001253692570155929,
          0.0012292153566690392,
          0.0012122481536604374,
          0.0012837588758010134,
          0.0012113977012570513,
          0.0012799024888605274,
          0.0012133893093759299,
          0.0011670372373170576,
          0.001194176162647553,
          0.0013008564865790685,
          0.0011955008388326175,
          0.0012454497945282622,
          0.0012467856602057976,
          0.001251564646786836,
          0.0012303021707936034,
          0.0011683797341040072,
          0.0012372899530916075,
          0.0011649997146582216,
          0.0012852836089782794,
          0.0012395078146693144,
          0.001205527202020634,
          0.0012047444370522449,
          0.00117684594317327,
          0.0012123932732230971,
          0.0011747730252011685,
          0.001222623284233215,
          0.0012193608078914632,
          0.0012566216057728172,
          0.001184526733313749,
          0.0011732103788957844,
          0.0012150699941472873,
          0.0012182852878786885,
          0.0012601610946197139,
          0.0012413021549891425,
          0.0011836226712333756,
          0.001243371435017544,
          0.0011938507862465481,
          0.00117924622447085,
          0.0012403169596445296,
          0.001170188762484606,
          0.0011597356136351267,
          0.001215110069173933,
          0.0011824979065564675,
          0.001203624620588229,
          0.00114615706362356,
          0.0012380794069557861,
          0.0011610425810696977,
          0.0011825269599028373,
          0.0012038402176216083,
          0.0012134816296751397,
          0.0012748680801121844,
          0.0011222289121188493,
          0.0011677470832526127,
          0.001182795900922264,
          0.001199925420943432,
          0.0011752104458025016,
          0.0011517868802205303,
          0.0011607103813827192,
          0.0011890366835243308,
          0.001203663613542182,
          0.0011504940497346304,
          0.001196190653258173,
          0.0011562390318387542,
          0.0011600966641001978,
          0.001153988565264362,
          0.001123387274412108,
          0.0011341352006886717,
          0.0011551898477382204,
          0.0011578569137036298,
          0.001191105882384993,
          0.0011566295261821733,
          0.0011224392595093145,
          0.0011801824045414723,
          0.00115049476304178,
          0.001159640990236417,
          0.001138262297066133,
          0.0011852788862483565,
          0.0011578265320429909,
          0.001151525431910285,
          0.0011401042421247285,
          0.0011298019726579814,
          0.0011921573831363884,
          0.0011257915257670624,
          0.0011739902312342702,
          0.0011455269165441566,
          0.0011241099660552194,
          0.001147221360370782,
          0.0011040106840826014,
          0.0011556210116830412,
          0.0011036742732223163,
          0.0011332383638711823,
          0.0011597777099912566,
          0.0011389089593932312,
          0.0011265967058105477,
          0.001110001400675382,
          0.0011592662845630382,
          0.0010943057524451516,
          0.0011289750447157497,
          0.0011497690045079317,
          0.0011102623779178384,
          0.001124646424779846,
          0.001133700909819881,
          0.0011170437908169686,
          0.0011243459203227708,
          0.0011004604634703042,
          0.0011523599109097874,
          0.0010982673083414045,
          0.001144419621818882,
          0.0010766055050448699,
          0.0010980100752768951,
          0.0011411846754538846,
          0.0011215922743586465,
          0.0010994956349090093,
          0.0011349399666081715,
          0.0011060010163372986,
          0.001140173006576988,
          0.0010770289714653741,
          0.0011482367565039775,
          0.0010834106124642073,
          0.001109381595812401,
          0.0010850904996010315,
          0.0012155424620095636,
          0.0010783392443086848,
          0.0010793262586251476,
          0.001093522857229222,
          0.001091829891764841,
          0.0011408277361067316,
          0.0010861495841997793,
          0.0011033490858382271,
          0.0010690607815959565,
          0.0011221275466019051,
          0.0010912850909485551,
          0.0010530176726692279,
          0.0010737916371117789,
          0.0011402403153462249,
          0.0010704233445085595,
          0.001062734980842231,
          0.0011030923652679482,
          0.001078509160405108,
          0.0010462030026931384,
          0.0010591593019263223,
          0.0011205108998066985,
          0.0010343400852904129,
          0.0011285209402119554,
          0.001036178737157558,
          0.0010505552142150746,
          0.0011205653257250103,
          0.0010713420795536272,
          0.001074297834172018,
          0.0011147311714503677,
          0.00108386472574479,
          0.0010766647646565381,
          0.0010009221563399943,
          0.0011022094776460718,
          0.0010968638450329711,
          0.0010649918407101783,
          0.001058521284806049,
          0.0010490081555561688,
          0.0010410228267955775,
          0.0011004125408713668,
          0.0010405624037062519,
          0.001123690290154105,
          0.0010388799502364886,
          0.001076970150061199,
          0.0010505146006446902,
          0.0010377258703840584,
          0.0010574681397057862,
          0.0010821899151726118,
          0.001084019098078677,
          0.0010479387149087797,
          0.0010456257963590144,
          0.0010568159031350305,
          0.001042499515201011,
          0.001077960421970458,
          0.0010580375511985635,
          0.0010743750869723395,
          0.0010509962495191716,
          0.0010586878176962798,
          0.0010773929226239167,
          0.0010401725505598887,
          0.0010536079022828917,
          0.0010342378490458414,
          0.001029313710182276,
          0.0010339359570838357,
          0.0011059842139130864,
          0.0010026460370937513,
          0.0010598375583747211,
          0.0010842022354589872,
          9.90787046075101E-4,
          0.001049681401371156,
          0.0010601756189201608,
          0.001025006339974607,
          0.0010319223942148608,
          0.00108066763577475,
          0.001042144732977813,
          0.001034445575406422,
          0.001056105351545685,
          0.0010162480685953163,
          0.0010195659711986188,
          0.0010362867191793404,
          0.0010346366526908382,
          0.001011641404355019,
          0.0010298821117826686,
          0.0010554828530512255,
          0.001055126780148627,
          0.0010507887052945046,
          0.0010993122418784054,
          0.0010294678185805814,
          9.878148786516903E-4,
          0.0010333649065082644,
          0.0010536061342866288,
          0.0010274944220870661,
          0.001059063792212409,
          0.001033934489323952,
          0.0010031990062914996,
          0.0010433866738889983,
          9.891116841801806E-4,
          0.0010403640032802068,
          0.0010087119208410634,
          9.995638791682924E-4,
          0.0010740923656929234,
          0.001019481287337278,
          0.0010281365868366975,
          0.0010191821179350454,
          9.8610126617869E-4,
          0.0010013975028484493,
          0.0010346213241351546,
          9.97804578456048E-4,
          0.001022042453064908,
          0.0010185583298144,
          9.88190027798635E-4,
          0.0010324529583079446,
          9.797241529494757E-4,
          0.0010159943407694657,
          0.0010574139528671915,
          0.001010064217860196,
          9.69098171511883E-4,
          0.0010191378319457363,
          0.0010035881226089197,
          9.953181649866067E-4,
          9.618771372141656E-4,
          0.0010358849992532961,
          9.790387087326331E-4,
          0.0010364894280957217,
          9.882470012324512E-4,
          0.0010010999294174261,
          9.974568477855374E-4,
          9.862175103882496E-4,
          0.001007311513399721,
          9.706495711001353E-4,
          0.0010419860042674316,
          9.712487466485028E-4,
          0.0010084236522100694,
          0.0010553404123048254,
          9.892522568047154E-4,
          9.619483930806981E-4,
          0.0010226982326496199,
          9.921976899199044E-4,
          9.8036946765337E-4,
          9.937402963597862E-4,
          9.84954539940898E-4,
          9.977404642973738E-4,
          9.758989398274458E-4,
          9.694627692739831E-4,
          9.696599465667914E-4,
          0.0010200698749893609,
          9.787653116323952E-4,
          9.883275005317083E-4,
          9.520990342638748E-4,
          0.0010106167633145984,
          0.0010477380779463981,
          0.0010157878978562117,
          9.502602819902699E-4,
          0.0010154346206064804,
          0.0010076946669777202,
          9.936138648265664E-4,
          9.476619241652456E-4,
          0.0010205421693520833,
          0.0010022145342946825,
          9.980997539280416E-4,
          9.967957980553334E-4,
          9.269070231880368E-4,
          9.848976223274563E-4,
          9.996520736045794E-4,
          9.26470245890189E-4,
          0.001013043434308579,
          9.765466300217914E-4,
          9.706759070825906E-4,
          9.578544515481644E-4,
          9.969606126610311E-4,
          9.848053040644614E-4,
          9.696533568838186E-4,
          9.868864211016778E-4,
          9.96060366306984E-4,
          9.579887165405998E-4,
          9.68825157079621E-4,
          9.794250963816354E-4,
          9.637084448753898E-4,
          9.27434256525016E-4,
          9.814787727546966E-4,
          9.855491601254238E-4,
          0.0010015840770786829,
          9.548939740345943E-4,
          9.522530263872869E-4,
          9.447447761114737E-4,
          9.609798975771943E-4,
          0.0010101929868979265,
          9.331438836891011E-4,
          9.835632597978157E-4,
          9.273676653460018E-4,
          9.385054277068519E-4,
          9.913296670882106E-4,
          9.946261702663748E-4,
          9.619016877872099E-4,
          9.352763261914532E-4,
          9.891845863615808E-4,
          9.424331228235293E-4,
          9.477663167614144E-4,
          9.37360146900794E-4,
          9.841621811001757E-4,
          9.564527983645784E-4,
          9.186086021599656E-4,
          0.0010081685299280722,
          8.94889546265046E-4,
          9.867051651839512E-4,
          9.277024879586513E-4,
          9.633582942687712E-4,
          9.508219478619301E-4,
          9.606525926700197E-4,
          9.380397209206729E-4,
          9.317972997273121E-4,
          9.393447069074864E-4,
          9.884894137417919E-4,
          9.121302483250602E-4,
          9.723053413776925E-4,
          9.57544865853415E-4,
          9.45106818072781E-4,
          9.236993567666446E-4,
          9.481343484946512E-4,
          9.134693383840244E-4,
          9.268031912531133E-4,
          9.396999439087542E-4,
          9.653690644338799E-4,
          9.311796288877788E-4,
          9.591389714686292E-4,
          8.957914104269518E-4,
          9.630217224772934E-4,
          9.250985945780527E-4,
          9.422175355499388E-4,
          9.39788017506218E-4,
          9.412659195659567E-4,
          9.493500779835626E-4,
          9.353517872630759E-4,
          9.092390611689129E-4,
          9.370534486290117E-4,
          9.437845578216088E-4,
          9.316969307620344E-4,
          9.363814098681845E-4,
          8.910652242327925E-4,
          9.384459449541143E-4,
          9.565025338267209E-4,
          8.887732680943156E-4,
          9.448785046665998E-4,
          9.314886487956385E-4,
          8.986255462114015E-4,
          9.687034160025705E-4,
          8.722390487747418E-4,
          9.436729513372736E-4,
          9.100265622327713E-4,
          9.499385777273327E-4,
          9.317382882530065E-4,
          9.084931802677509E-4,
          9.093736330680863E-4,
          9.0309417656588E-4,
          9.334282143506591E-4,
          9.280100402470556E-4,
          9.657798210817274E-4,
          8.645969474198358E-4,
          9.430988352752512E-4,
          9.229595020786377E-4,
          8.684918102561143E-4,
          9.4770194912909E-4,
          9.154382541515068E-4,
          9.101442221734129E-4,
          8.866034972085982E-4,
          9.523204029835446E-4,
          9.326593293465755E-4,
          8.856502785128333E-4,
          8.825156181198023E-4,
          9.116508451849897E-4,
          9.205270620665105E-4,
          8.900003169019525E-4,
          8.699490327277953E-4,
          9.481792587593683E-4,
          9.486337970471542E-4,
          8.709122238212251E-4,
          9.239082316928672E-4,
          9.135687916845182E-4,
          9.100163749091112E-4,
          8.989462510438858E-4,
          8.977316543926115E-4,
          8.99877042657908E-4,
          9.336200814758201E-4,
          9.13915569266019E-4,
          8.930931817369471E-4,
          8.72944346157243E-4,
          9.12538454227545E-4,
          8.606751671564216E-4,
          8.977505079171743E-4,
          8.834641688981906E-4,
          9.379567720548702E-4,
          9.231524722003552E-4,
          8.805403009139055E-4,
          8.870843289991834E-4,
          9.055015092055044E-4,
          9.424140279021775E-4,
          8.721093350737182E-4,
          8.634725726429773E-4,
          8.856140662561001E-4,
          9.274801403111064E-4,
          8.690814096963683E-4,
          9.028732339768425E-4,
          8.911146225960446E-4,
          8.934209515330516E-4,
          8.793147192342236E-4,
          9.403125079212748E-4,
          8.718399915858807E-4,
          8.647408293148973E-4,
          9.219058353562847E-4,
          9.078006901855798E-4,
          8.956007388408045E-4,
          9.129347237679698E-4,
          8.667267787223064E-4,
          9.124636128674001E-4,
          8.820415495117437E-4,
          8.711587277182633E-4,
          8.471900177613997E-4,
          8.849202755240968E-4,
          9.209042147085053E-4,
          8.741013619507268E-4,
          9.462830878230232E-4,
          8.80832633478803E-4,
          8.576206313991027E-4,
          8.626231137720421E-4,
          8.952372411262599E-4,
          8.622837903520679E-4,
          8.751044862379013E-4,
          8.889358790239726E-4,
          9.039163715020721E-4,
          8.650195754112943E-4,
          8.852106823211826E-4,
          8.397445389360584E-4,
          9.474907566392199E-4,
          8.767589224436162E-4,
          8.405292928651361E-4,
          8.525239245149344E-4,
          8.307035600393562E-4,
          9.30381891350245E-4,
          8.468222355698117E-4,
          8.881228155988988E-4,
          8.532048832311715E-4,
          8.43177494844051E-4,
          8.757558688622494E-4,
          8.74761927623495E-4,
          8.757579492419662E-4,
          9.068655584145684E-4,
          8.659809000680024E-4,
          8.592595151357074E-4,
          8.384952971411799E-4,
          8.424411902616454E-4,
          8.857126518481819E-4,
          8.110363979091412E-4,
          8.30190042575846E-4,
          9.048576758830697E-4,
          8.773842031800102E-4,
          8.6367279885166E-4,
          8.490245823132771E-4,
          8.443913686390297E-4,
          8.764834220035831E-4,
          8.24195017984229E-4,
          8.339792726908566E-4,
          8.435009510943889E-4,
          9.015682090210883E-4,
          8.404329499882501E-4,
          8.728752965646806E-4,
          8.216016787970473E-4,
          8.51969596178836E-4,
          8.13162644490357E-4,
          8.719456792849513E-4,
          8.7032413623544E-4,
          8.825241849674597E-4,
          8.17936433457283E-4,
          8.147774008355486E-4,
          8.189274031563299E-4,
          8.833193525209106E-4,
          8.205472354342391E-4,
          8.642034546446294E-4,
          8.292664972187859E-4,
          8.169081413430871E-4,
          8.78881065700702E-4,
          8.174574474604133E-4,
          8.494935344047485E-4,
          8.196840266358956E-4,
          7.981812214620402E-4,
          8.896555659862233E-4,
          8.276624026353301E-4,
          8.553810695279502E-4,
          8.079203054790843E-4,
          8.606223849550483E-4,
          8.490697657116504E-4,
          8.078466208294411E-4,
          8.31134190144797E-4,
          8.368446560889994E-4,
          8.187871933291218E-4,
          8.436011085039582E-4,
          8.535377929252275E-4,
          8.057657576169463E-4,
          8.269032185101844E-4,
          8.687047123941576E-4,
          8.163042903644121E-4,
          8.255612441176825E-4,
          8.20586081570075E-4,
          8.337563719652117E-4,
          8.201508318547011E-4,
          8.06592354217861E-4,
          8.267016740980928E-4,
          7.865212731197054E-4,
          8.197192175553121E-4,
          8.329145852010135E-4,
          8.191332532501857E-4,
          7.812995232604624E-4,
          8.640893928712824E-4,
          8.414353712195636E-4,
          7.616832393302444E-4,
          8.367825532893777E-4,
          7.797247487675304E-4,
          8.559585584746618E-4,
          7.819901209968323E-4,
          8.519715575453016E-4,
          8.148265552742966E-4,
          8.037991747198305E-4,
          7.621163225129462E-4,
          8.270152880578775E-4,
          8.329357145117108E-4,
          8.112354782905398E-4,
          7.676088061735294E-4,
          8.056948731138862E-4,
          8.176929264473173E-4,
          7.708131987124061E-4,
          8.180877061805657E-4,
          8.402512355710956E-4,
          7.655651902468747E-4,
          8.32638060544877E-4,
          7.798662140967708E-4,
          8.028464515264336E-4,
          8.21324137859024E-4,
          7.910455944436738E-4,
          7.583824965419793E-4,
          8.389232277522477E-4,
          7.836094362165811E-4,
          7.987058758275051E-4,
          7.720429636903143E-4,
          7.905594592962292E-4,
          7.633101360100592E-4,
          7.670006746498125E-4,
          8.200204183276748E-4,
          7.57221255602542E-4,
          7.690987816536564E-4,
          7.731273495934823E-4,
          7.74990332403318E-4,
          7.709900991313173E-4,
          7.972935127853826E-4,
          7.342089289704964E-4,
          7.929820794161675E-4,
          7.704097936429821E-4,
          7.932069631342846E-4,
          7.691035515924217E-4,
          7.544561965133774E-4,
          7.746854465734551E-4,
          7.88647085565858E-4,
          7.626942913042352E-4,
          7.730292162517551E-4,
          7.648040861465976E-4,
          7.842010327623831E-4,
          7.438692621649686E-4,
          7.587566486808647E-4,
          7.738964678494954E-4,
          7.272703051485629E-4,
          8.067227682363875E-4,
          7.322804329116953E-4,
          7.489198420406852E-4,
          7.947329616435861E-4,
          7.519509658201702E-4,
          7.830317847939619E-4,
          7.488028266322794E-4,
          7.687293285721929E-4,
          7.738238955349116E-4,
          7.680186038343652E-4,
          7.691692768534886E-4,
          7.163306086425826E-4,
          7.62745205067779E-4,
          8.058568484636318E-4,
          7.516896450542143E-4,
          7.692194417112286E-4,
          7.373475079187074E-4,
          7.689519424021774E-4,
          7.577473318077337E-4,
          7.313870053499065E-4,
          7.526457525772324E-4,
          7.60412903015858E-4,
          7.417248844239856E-4,
          7.303706149470097E-4,
          7.845953844692131E-4,
          7.384873488010778E-4,
          7.333597140942797E-4,
          7.508803958809666E-4,
          8.046121269254412E-4,
          7.294933824205661E-4,
          7.582786930087433E-4,
          7.028207325068189E-4,
          7.53943135899259E-4,
          6.947330714133765E-4,
          7.325350709607211E-4,
          7.454899047159863E-4,
          7.836387327853118E-4,
          6.894352372603174E-4,
          8.424335229294813E-4,
          7.268093543285021E-4,
          6.899779775675354E-4,
          7.823285435321342E-4,
          7.198898170022036E-4,
          7.154906131506901E-4,
          7.519350867492087E-4,
          7.306676051428877E-4,
          7.241679600830919E-4,
          7.468416932079968E-4,
          7.09754247746382E-4,
          7.289124935917642E-4,
          6.958130685361473E-4,
          7.152500271261305E-4,
          7.26927843219258E-4,
          7.723584909197639E-4,
          7.235836556793018E-4,
          7.345872577021417E-4,
          7.362937591860433E-4,
          7.373493846769324E-4,
          7.042897361669402E-4,
          7.091115776643796E-4,
          7.417730176307383E-4,
          7.339781486899429E-4,
          7.41973505984538E-4,
          7.391394146106378E-4,
          6.764186207071369E-4,
          6.91234323084332E-4,
          7.62649531263029E-4,
          6.967053795500183E-4,
          7.160090737014479E-4,
          7.225834602064288E-4,
          7.22459805754392E-4,
          7.77471638659568E-4,
          7.152600916800739E-4,
          6.903895857745042E-4,
          7.304287105458884E-4,
          6.971170612011527E-4,
          6.947271423768229E-4,
          7.359475895902311E-4,
          6.874017081104345E-4,
          7.32828502625281E-4,
          7.411740985050218E-4,
          6.766365732198898E-4,
          6.893288628302123E-4,
          6.876799886508657E-4,
          7.257381806164684E-4,
          7.004002974210228E-4,
          7.195322928049763E-4,
          7.0717002167417E-4,
          7.138958344611242E-4,
          7.152682679957531E-4,
          7.011967382407259E-4,
          7.45350936804342E-4,
          6.670210147765212E-4,
          7.322203785091733E-4,
          7.07192374609604E-4,
          6.930468549131246E-4,
          6.7666274089865E-4,
          6.960668117740384E-4,
          7.740997502412333E-4,
          7.091655845788113E-4,
          6.979704796324233E-4,
          6.888052996653003E-4,
          7.087928465560789E-4,
          6.923208875268186E-4,
          7.539641270984135E-4,
          6.790953145286043E-4,
          6.729700370251894E-4,
          7.619060164084939E-4,
          6.734263752216408E-4,
          7.114062620148813E-4,
          7.164456344934785E-4,
          6.871698690332311E-4,
          7.146033337643085E-4,
          6.919289657616352E-4,
          6.920221737101202E-4,
          6.788673890564721E-4,
          6.63243736224968E-4,
          7.223466926114465E-4,
          6.954459637370908E-4,
          7.069295859433355E-4,
          6.68375738893621E-4,
          7.14041104071759E-4,
          6.9921805703225E-4,
          6.894162056722709E-4,
          6.959448106583001E-4,
          6.973102219547151E-4,
          7.238630802916594E-4,
          6.946623766293751E-4,
          6.729563046864653E-4,
          7.155539835643122E-4,
          7.111621847243101E-4,
          6.444843361882742E-4,
          7.147532784190721E-4,
          6.757809266779994E-4,
          6.955085083602425E-4,
          6.746269274315942E-4,
          6.860322750087005E-4,
          6.789242737745109E-4,
          7.137300743846688E-4,
          7.074248490560759E-4,
          6.83766536366035E-4,
          7.152518392169783E-4,
          6.902180797453022E-4,
          6.705061576089881E-4,
          7.034694292583695E-4,
          6.63206326603649E-4,
          6.792934161576636E-4,
          6.913579749033322E-4,
          7.085993005717184E-4,
          6.77007789733686E-4,
          7.30705683450164E-4,
          6.867336652458469E-4,
          6.617397042968736E-4,
          6.991784777888294E-4,
          7.05724031139509E-4,
          6.847769590794021E-4,
          6.437951082628292E-4,
          6.763137287468131E-4,
          7.105435744524496E-4,
          7.111010051024033E-4,
          6.833485001094293E-4,
          6.66708002377816E-4,
          6.787999716305946E-4,
          6.774592486676952E-4,
          7.359455511284558E-4,
          6.426897915097041E-4,
          6.624845818355814E-4,
          6.79750020115269E-4,
          6.768861857851781E-4,
          7.108569571263055E-4,
          6.620288903129021E-4,
          7.084191286575781E-4,
          6.766041912589518E-4,
          6.999991290634712E-4,
          6.828093927606954E-4,
          6.493554810490077E-4,
          6.964563741629541E-4,
          6.557007202475845E-4,
          7.203777721396055E-4,
          6.754650490791553E-4,
          6.981540700354455E-4,
          6.988599404720173E-4,
          6.316123506466019E-4,
          6.913064015114768E-4,
          6.419683404129776E-4,
          6.968601567044953E-4,
          6.469961247573729E-4,
          7.170349417017847E-4,
          7.239681566698618E-4,
          6.509354447654423E-4,
          6.657710807387851E-4,
          7.202347420845226E-4,
          6.405548921034113E-4,
          6.586313941749094E-4,
          6.421331108187688E-4,
          6.928626285089052E-4,
          6.895349394354241E-4,
          6.427549705034587E-4,
          7.458427801994501E-4,
          6.430337958367018E-4,
          6.32503042518542E-4,
          6.76270615055582E-4,
          6.77247077706343E-4,
          6.48889835524812E-4,
          7.033032279552058E-4,
          7.049332419747377E-4,
          6.415263990634564E-4,
          6.690437790900648E-4,
          6.598117551724207E-4,
          6.651824201691438E-4,
          6.815980915477291E-4,
          7.048127017729883E-4,
          6.321063791811736E-4,
          6.71829727356995E-4,
          6.970063313775538E-4,
          6.579485295264025E-4,
          6.430096534545341E-4,
          6.692855760656787E-4,
          6.977291926233249E-4,
          6.54301579156385E-4,
          6.727786367900661E-4,
          6.572871913207162E-4,
          7.119263610516117E-4,
          6.793508151603977E-4,
          6.873849062128296E-4,
          6.592453030020614E-4,
          6.747598065691354E-4,
          6.582863645785937E-4,
          6.523419263412046E-4,
          6.609336166983567E-4,
          6.737105022265999E-4,
          6.622627226338666E-4,
          6.450144873861228E-4,
          6.358571431250733E-4,
          7.321583430801796E-4,
          6.452144893303074E-4,
          6.816129556357685E-4,
          6.731723738408482E-4,
          6.644870626399758E-4,
          6.951081075503932E-4,
          6.310796144388086E-4,
          6.792696748045133E-4,
          6.496128760628173E-4,
          6.700543210624332E-4,
          6.49384938478717E-4,
          6.214983352171808E-4,
          6.785079591025107E-4,
          6.653352075905749E-4,
          6.490245300883807E-4,
          6.862490328952257E-4,
          6.68109117825128E-4,
          6.670198181842929E-4,
          7.118580421442401E-4,
          6.376128362261986E-4,
          6.755248791118578E-4,
          6.042741480537896E-4,
          6.266459038360909E-4,
          6.825683636136412E-4,
          6.119446368776802E-4,
          7.015230856704963E-4,
          6.384703013537602E-4,
          6.758781688246287E-4,
          6.819780689815286E-4,
          6.458232508167912E-4,
          6.557203180789138E-4,
          6.403311892495175E-4,
          6.62803730789226E-4,
          6.117939164601401E-4,
          6.837892808164475E-4,
          6.463601888944951E-4,
          6.5766598027204E-4,
          6.530977797102457E-4,
          6.50689599162644E-4,
          6.711321000801231E-4,
          6.579173127718975E-4,
          6.235103494393896E-4,
          6.29379120420842E-4,
          7.022749716151996E-4,
          6.377990223117402E-4,
          6.639109911445968E-4,
          6.198182375076484E-4,
          6.174029488497345E-4,
          7.059187403643016E-4,
          6.732601288759989E-4,
          6.682338862271533E-4,
          6.275169384051834E-4,
          6.978024713289491E-4,
          7.211322396186453E-4,
          6.147133312072937E-4,
          6.66606459464424E-4,
          5.893051096707789E-4,
          6.997323258239573E-4,
          6.553794541921404E-4,
          6.985411604945587E-4,
          6.508366283789318E-4,
          6.383186726439385E-4,
          6.437703390424314E-4,
          6.423383422894685E-4,
          7.105682870801156E-4,
          6.423427645620902E-4,
          6.239307156173609E-4,
          6.360168687030853E-4,
          6.935844456679238E-4,
          6.218135415672452E-4,
          6.550672887184121E-4,
          6.370494546679346E-4,
          6.254509925733875E-4,
          6.52436064418621E-4,
          6.488112039612416E-4,
          6.803653624377228E-4,
          6.541652908333576E-4,
          6.234088776530911E-4,
          6.532637333675469E-4,
          6.748711358122775E-4,
          6.374033027950931E-4,
          6.237388034146144E-4,
          6.674778239354401E-4,
          6.438027266907282E-4,
          7.097580887849664E-4,
          6.230928429497341E-4,
          6.733724749627421E-4,
          6.189424459894376E-4,
          6.308139023296332E-4,
          6.51309589215861E-4,
          6.384392471453771E-4,
          6.85602492600594E-4,
          6.130307436633105E-4,
          6.821256144485123E-4,
          6.634608965799037E-4,
          6.602204394449825E-4,
          6.462064856327441E-4,
          6.463932582183962E-4,
          6.590900391922192E-4,
          6.110954346751459E-4,
          6.80259225086227E-4,
          6.211082344600622E-4,
          6.357654717464935E-4,
          6.471133458234855E-4,
          6.248934985199141E-4,
          6.643145052568405E-4,
          6.350812764666454E-4,
          6.520445613413532E-4,
          6.264819260445099E-4,
          6.419329545786436E-4,
          7.057546866710542E-4,
          6.055224495386622E-4,
          6.554384214665395E-4,
          6.435531152137617E-4,
          6.376078810269829E-4,
          6.661453172050538E-4,
          6.991086422173089E-4,
          6.103634765690173E-4,
          6.288823601986373E-4,
          6.568065880425949E-4,
          6.457245451933507E-4,
          6.334350573711223E-4,
          6.710775486888438E-4,
          6.243508942178097E-4,
          6.574978219205907E-4,
          6.570532080389905E-4,
          6.276624770068302E-4,
          6.347697881748057E-4,
          6.540094917798494E-4,
          6.446716269555157E-4,
          6.37120748169336E-4,
          6.183814225435837E-4,
          6.088492712548028E-4,
          6.415074976176289E-4,
          6.673127490453045E-4,
          6.057214464352492E-4,
          6.485506219902291E-4,
          6.432986617581503E-4,
          6.522948144717688E-4,
          6.903297708729851E-4,
          6.259835803832419E-4,
          6.322705401267758E-4,
          6.278814716052278E-4,
          6.557537029108058E-4,
          6.325462004447871E-4,
          6.910636953659023E-4,
          6.615629901916273E-4,
          6.477191223944363E-4,
          6.405832004408713E-4,
          6.068338869213699E-4,
          6.435205610873418E-4,
          6.400336816795147E-4,
          6.327600542324471E-4,
          6.558977789835346E-4,
          6.408680616768439E-4,
          6.742246310811926E-4,
          6.267055613171327E-4,
          6.560707844041661E-4,
          6.292495255224267E-4,
          6.259637812123858E-4,
          6.440376721191096E-4,
          6.271419722016169E-4,
          6.061202444982085E-4,
          6.429547283124961E-4,
          6.753228096371748E-4,
          6.004138413995878E-4,
          6.518895501274822E-4,
          6.577591663487683E-4,
          6.156061776754737E-4,
          6.103339308799234E-4,
          6.070502025279721E-4,
          6.263593051119722E-4,
          6.393131057339169E-4,
          6.535334114265596E-4,
          6.382092411530994E-4,
          6.598850964741002E-4,
          6.054505435929637E-4,
          6.329063691936918E-4,
          6.160427512816155E-4,
          6.289515704415353E-4,
          6.630805687767098E-4,
          6.732799429673953E-4,
          6.45679367166372E-4,
          6.830715893799231E-4,
          6.166803063917456E-4,
          6.285143779664873E-4,
          6.182240337328323E-4,
          6.270596711330152E-4,
          6.299550068313065E-4,
          6.337968604633556E-4,
          6.653287278281006E-4,
          6.272998971688202E-4,
          6.372244023918472E-4,
          6.39194077491958E-4,
          6.709984109152234E-4,
          5.752628283525747E-4,
          6.733575138736368E-4,
          6.351774902896342E-4,
          6.396684262199963E-4,
          6.34875352507338E-4,
          6.680780522771341E-4,
          6.690471595930063E-4,
          6.007391246964209E-4,
          6.257237131236654E-4,
          6.451352331051502E-4,
          6.196094042887244E-4,
          5.909004411926949E-4,
          6.417086833048235E-4,
          6.412135835105623E-4,
          6.259809717812898E-4,
          6.30917441119823E-4,
          6.491558777114468E-4,
          6.015483096235772E-4,
          6.514736787535124E-4,
          6.010365970890556E-4,
          6.352086285094363E-4,
          6.296393386115274E-4,
          6.10450430599348E-4,
          6.348213004099993E-4,
          6.455680807539576E-4,
          6.305585632258543E-4,
          6.270865795376124E-4,
          6.561427721495328E-4,
          5.820008782294676E-4,
          5.950130397199447E-4,
          6.708201077548771E-4,
          6.281115206739831E-4,
          6.000139685662237E-4,
          6.534678972648082E-4,
          6.026866393536216E-4,
          6.405419470075028E-4,
          6.379983783194029E-4,
          6.38375504771461E-4,
          6.609658059210206E-4,
          6.280681507356366E-4,
          6.217459848361815E-4,
          6.384457531328952E-4,
          6.243451452107406E-4,
          6.145645863395094E-4,
          6.208128294926047E-4,
          6.389213494989635E-4,
          6.358808217066328E-4,
          6.004661084736941E-4,
          6.019475825810053E-4,
          5.810252120898109E-4,
          6.928478482567488E-4,
          6.483134419915117E-4,
          6.476734108791493E-4,
          6.120889178006511E-4,
          6.569126502647816E-4,
          6.114008707043223E-4,
          5.974471003133961E-4,
          6.740761240292678E-4,
          6.002169618154432E-4,
          6.156942985973807E-4,
          6.046438868372703E-4,
          6.666328526013256E-4,
          6.304827596137325E-4,
          6.490298163129491E-4,
          6.200240581817094E-4,
          6.260236627472827E-4,
          5.914885605855612E-4,
          5.977913379976447E-4,
          6.434340606063303E-4,
          6.617150146292862E-4,
          6.393660151285082E-4,
          6.414867484471924E-4,
          6.304202911731044E-4,
          6.136956149125213E-4,
          6.064430046790089E-4,
          6.308953334780722E-4,
          5.862900601931374E-4,
          6.159186535666554E-4,
          6.470572200167892E-4,
          6.41131101885869E-4,
          6.607346743231794E-4,
          6.13792443391558E-4,
          5.852310603781659E-4,
          6.454759496471994E-4,
          6.34517668081061E-4,
          6.059489748454726E-4,
          6.206642517699794E-4,
          6.015174559472563E-4,
          6.285291575165005E-4,
          6.418402638638547E-4,
          6.074805566560773E-4,
          6.764876935406351E-4,
          5.937803397839833E-4,
          6.247114909229187E-4,
          6.543270152020611E-4,
          6.030035375174252E-4,
          6.427508040215591E-4,
          6.008164631230902E-4,
          6.273431920129648E-4,
          6.234831646010639E-4,
          6.185504597675199E-4,
          6.174560247926632E-4,
          5.918288229112553E-4,
          6.424837358283559E-4,
          6.067064308911894E-4,
          6.216697655202522E-4,
          6.3521671793491E-4,
          6.017631064947083E-4,
          6.48344373359964E-4,
          6.378633186063281E-4,
          5.829150668981252E-4,
          6.035004357809585E-4,
          5.975542792941436E-4,
          6.312003397956868E-4,
          6.022197994489483E-4,
          6.379504878084041E-4,
          6.122994098325897E-4,
          6.78192973927515E-4,
          6.155677096436836E-4,
          6.578778068673212E-4,
          6.221439804900348E-4,
          5.96357913015453E-4,
          6.577403569538977E-4,
          5.76754733918693E-4,
          5.900816799818894E-4,
          6.279941445044652E-4,
          5.789942638423357E-4,
          6.363717894942193E-4,
          6.305063172511473E-4
         ],
         "yaxis": "y",
         "type": "scattergl"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmapgl": [
           {
            "type": "heatmapgl",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "type": "scattergl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "bgcolor": "#E5ECF6",
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "#E5ECF6",
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "white",
           "landcolor": "#E5ECF6",
           "subunitcolor": "white",
           "showland": true,
           "showlakes": true,
           "lakecolor": "white"
          },
          "title": {
           "x": 0.05
          },
          "mapbox": {
           "style": "light"
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0.0,
          1.0
         ],
         "title": {
          "text": "epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.0,
          1.0
         ],
         "title": {
          "text": "loss"
         }
        },
        "legend": {
         "tracegroupgap": 0
        },
        "title": {
         "text": "train loss"
        }
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      },
      "text/html": "<div>                            <div id=\"0e356ee4-4ec0-428e-b837-023d24eb65b0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0e356ee4-4ec0-428e-b837-023d24eb65b0\")) {                    Plotly.newPlot(                        \"0e356ee4-4ec0-428e-b837-023d24eb65b0\",                        [{\"hovertemplate\":\"epoch=%{x}<br>loss=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499],\"xaxis\":\"x\",\"y\":[0.24837253451239502,0.056940154351105304,0.04929833314566905,0.037637448234908256,0.020478817678098223,0.01568327195025684,0.014397265835562934,0.013252091170507692,0.012286655594728465,0.011650429424055739,0.010885081178676089,0.010172047077108566,0.00941834900757372,0.009226538634671412,0.0087177799391112,0.008375327434251479,0.008170904774798487,0.007663850334390944,0.007303168157967138,0.007207525992907575,0.00715413697758202,0.006646480455666565,0.0065362419521905685,0.006513304999985691,0.0061017648694391925,0.006165464754711805,0.005903140504128862,0.005702716707329482,0.0056190913620621724,0.005357194369472338,0.0054091772848719995,0.005247772807217191,0.005031369174903638,0.004983276469167883,0.0050712384050992845,0.004761843291359568,0.004721378401456574,0.004681831937445051,0.004616577575371946,0.004598846675073155,0.004440069066886357,0.0043005790130040905,0.004397688207718734,0.004172555701211724,0.004158781812749848,0.004298668053109015,0.004078175759940567,0.003927427046596375,0.004036260143582978,0.0037951521989434455,0.004073697348452197,0.0036091231086613795,0.0037884943474272873,0.0037270147152316945,0.0036911890725183903,0.003517361374659547,0.0036395488697833264,0.003649267818513624,0.0034290468617959174,0.003484606167944137,0.003427778922843739,0.0033860535572077383,0.0032411479206915284,0.0032220279875989953,0.003358337799574735,0.0033046363881565587,0.0030066231967807175,0.003132661495052179,0.0031711712147618125,0.003071207514389972,0.0030781220112768857,0.0029421101767452946,0.0030105176302565057,0.002773721545116821,0.002917231828989899,0.0029903167276783644,0.0028351905165336783,0.0027402981388887034,0.0028145569438436063,0.0028940237616497766,0.0027175598836248903,0.002762997267370093,0.0025915982267977746,0.002678328824529494,0.0026647520648423397,0.002640843794589011,0.0026336037076389544,0.0026117831244458086,0.002492174426283557,0.0025509160934061048,0.0024928258992035044,0.002582078035392847,0.002492996180273898,0.002492929716112566,0.0025447278223994702,0.002422094959187107,0.0024651903691403883,0.002420099574732128,0.0023468122177221448,0.0024017462564746885,0.0023238395243283224,0.0023137623395330406,0.0023324220043587957,0.002339924603646713,0.002278480375751817,0.002394296168220489,0.0022887811823034676,0.002260185170646833,0.0023088268975000404,0.002194906517372335,0.0022464907841601906,0.0021948915471202628,0.0022407280138229775,0.0021109650590073934,0.002157647639150148,0.00218064269762648,0.002174527488960081,0.002167039929576829,0.002109817156750165,0.0021157067921237327,0.0022205575549047087,0.0020592391042407285,0.0021273004950223035,0.0020982692032475003,0.0020004125176878384,0.0019930578574180982,0.0021302324398988085,0.002054249660243405,0.002018132292950892,0.0020961632931872356,0.0019507264330549518,0.002069284411880836,0.0019844033137756986,0.0019776320976089457,0.002032216588334058,0.0019712473280712136,0.0019529243499777573,0.001930294594636459,0.0019682870197039104,0.001938384113495156,0.002008363047465278,0.001931097060756531,0.002031275688106614,0.001842301051734539,0.0019036520778598091,0.0018716545521918644,0.001976846959396963,0.0019198034556337663,0.0017794472035087996,0.0019210603029722183,0.0018985505648062928,0.0018009050576234251,0.0018049545016811557,0.0018801515451795337,0.0018685078689327467,0.0018000788132876912,0.0018174403659669083,0.0018023114624198422,0.0017840023131746759,0.0017583373515834117,0.0018479602304101888,0.0017813677649295679,0.0018031864659579873,0.001742608102366544,0.0017595794300444252,0.0017795928031266795,0.001737886192434354,0.001780162829556362,0.0018112194440434311,0.0017157836650937472,0.0017136109992019176,0.0017467092122181586,0.001797102120411734,0.0017275384547800023,0.0017460618055491867,0.0016654426327752639,0.001712834214245669,0.0017119942864052618,0.0016666460308764216,0.0017484430113045635,0.001680194331160033,0.0016354842076922876,0.0017096740885978099,0.0016989346448415205,0.0017372213077391032,0.0016611929375125573,0.0016536002562171246,0.0016661019498972161,0.0016457399984471167,0.0016612447480883435,0.0015921906024089535,0.0016173357736606901,0.0016616735381576422,0.0016139377799139001,0.001596020063075301,0.0016897581512079235,0.001609681953959149,0.001635177232144205,0.0016553761121290045,0.0015575179676564615,0.0016172344840454124,0.0016173420058826233,0.0016100366465888907,0.0016068566157465714,0.0015722344982223215,0.0015771086470968796,0.0015725897390853761,0.0015612075591754208,0.0015613057604845976,0.001571027352362287,0.001626619869737523,0.0015660251361015731,0.0015900775033866018,0.0015632445561397368,0.0015984048336110694,0.001528005085495695,0.0015357686738922869,0.0015266815868045672,0.001533492448075761,0.0015704793881105913,0.0015232138203982763,0.0015274072269570932,0.0015356464014333574,0.0015238451939109888,0.0015406244743640105,0.0014789208406930739,0.0014984767977541495,0.0015700503945602295,0.0015432967158962396,0.0014158810892752377,0.0014854758661644774,0.0015252821198838736,0.0014747964892035353,0.001492394800455196,0.0014702067779269253,0.0014609475065397932,0.0014754911649868844,0.0015096590648920908,0.0014474087191714182,0.0015513622752459332,0.0014662277616281849,0.0014412485900592278,0.0014667216899318326,0.0014738717480968185,0.0014012202168887861,0.0014845841527445774,0.0014402158467792226,0.0013857707129881253,0.0014750595159314132,0.0014665762414151423,0.0014690632893410664,0.0014678812133590944,0.0013940025868615534,0.0015205618959376352,0.0014636442552526246,0.001433467483473773,0.0014046298926112,0.0014084770877264773,0.0013867561564701008,0.0015213468202768371,0.0014139439131833154,0.0013950486511297624,0.0014335272484880268,0.0014401409658182085,0.0013778441777566293,0.0014319964570096674,0.0013975734357352496,0.0013767660451396869,0.0014431279148278472,0.0013876384891180907,0.001458412021554701,0.0013777809923226003,0.001408647663837391,0.0013924990894398747,0.0014060093077299589,0.0013711953096696152,0.001376511972702015,0.0014279543961970129,0.0013570198778004642,0.0014182266778401374,0.0013804518789293377,0.0013048482296423283,0.0013778996416530488,0.0013944304710258567,0.001365610164257645,0.001375968963825071,0.001416620692876881,0.001369174146172068,0.0013868440471592935,0.001445835006599673,0.0013147404780263132,0.0013049029154940065,0.0013221930989105843,0.0013285335281833476,0.0013585979044796906,0.001319916062610307,0.0013404121375007979,0.0013709061743132096,0.0013480423914551717,0.0013576871405138811,0.0013155640634164368,0.0013711073675133352,0.0013135684346156679,0.0013424395756999343,0.0013233837917328007,0.0013582802623952992,0.0013499858966647717,0.001321571889901882,0.0013381011280780535,0.0012879437831285509,0.0013963119560780747,0.0013057511638702804,0.0012702101015006119,0.0012986870058890841,0.0013678176815827142,0.0012834732129633993,0.001388845510698801,0.0012434066611143285,0.0013589361901322,0.0013133800906338139,0.0012652662699110806,0.001236093349980058,0.0012990397984494507,0.0012621601674322656,0.001305308566648913,0.0013043808808243542,0.0012802721756854205,0.0013309341996618344,0.0012811345285011412,0.0012694447141520418,0.0012633128870931309,0.0012725179737480975,0.0013099339838668848,0.0012756693233798772,0.0012777851215104233,0.0012538627135360656,0.0013257232293839352,0.0012582271558988674,0.0012958315686986694,0.0012520919629064836,0.0012483299363419116,0.0012558701707795037,0.0012444001316363655,0.0013122011469823137,0.0012874067751173968,0.0013027659762567595,0.0012394657324262602,0.0012221397676581542,0.0012738624275482257,0.0012862029281361714,0.0012405972209656824,0.001262383935515251,0.0012037721400057046,0.0012711770866241472,0.001253692570155929,0.0012292153566690392,0.0012122481536604374,0.0012837588758010134,0.0012113977012570513,0.0012799024888605274,0.0012133893093759299,0.0011670372373170576,0.001194176162647553,0.0013008564865790685,0.0011955008388326175,0.0012454497945282622,0.0012467856602057976,0.001251564646786836,0.0012303021707936034,0.0011683797341040072,0.0012372899530916075,0.0011649997146582216,0.0012852836089782794,0.0012395078146693144,0.001205527202020634,0.0012047444370522449,0.00117684594317327,0.0012123932732230971,0.0011747730252011685,0.001222623284233215,0.0012193608078914632,0.0012566216057728172,0.001184526733313749,0.0011732103788957844,0.0012150699941472873,0.0012182852878786885,0.0012601610946197139,0.0012413021549891425,0.0011836226712333756,0.001243371435017544,0.0011938507862465481,0.00117924622447085,0.0012403169596445296,0.001170188762484606,0.0011597356136351267,0.001215110069173933,0.0011824979065564675,0.001203624620588229,0.00114615706362356,0.0012380794069557861,0.0011610425810696977,0.0011825269599028373,0.0012038402176216083,0.0012134816296751397,0.0012748680801121844,0.0011222289121188493,0.0011677470832526127,0.001182795900922264,0.001199925420943432,0.0011752104458025016,0.0011517868802205303,0.0011607103813827192,0.0011890366835243308,0.001203663613542182,0.0011504940497346304,0.001196190653258173,0.0011562390318387542,0.0011600966641001978,0.001153988565264362,0.001123387274412108,0.0011341352006886717,0.0011551898477382204,0.0011578569137036298,0.001191105882384993,0.0011566295261821733,0.0011224392595093145,0.0011801824045414723,0.00115049476304178,0.001159640990236417,0.001138262297066133,0.0011852788862483565,0.0011578265320429909,0.001151525431910285,0.0011401042421247285,0.0011298019726579814,0.0011921573831363884,0.0011257915257670624,0.0011739902312342702,0.0011455269165441566,0.0011241099660552194,0.001147221360370782,0.0011040106840826014,0.0011556210116830412,0.0011036742732223163,0.0011332383638711823,0.0011597777099912566,0.0011389089593932312,0.0011265967058105477,0.001110001400675382,0.0011592662845630382,0.0010943057524451516,0.0011289750447157497,0.0011497690045079317,0.0011102623779178384,0.001124646424779846,0.001133700909819881,0.0011170437908169686,0.0011243459203227708,0.0011004604634703042,0.0011523599109097874,0.0010982673083414045,0.001144419621818882,0.0010766055050448699,0.0010980100752768951,0.0011411846754538846,0.0011215922743586465,0.0010994956349090093,0.0011349399666081715,0.0011060010163372986,0.001140173006576988,0.0010770289714653741,0.0011482367565039775,0.0010834106124642073,0.001109381595812401,0.0010850904996010315,0.0012155424620095636,0.0010783392443086848,0.0010793262586251476,0.001093522857229222,0.001091829891764841,0.0011408277361067316,0.0010861495841997793,0.0011033490858382271,0.0010690607815959565,0.0011221275466019051,0.0010912850909485551,0.0010530176726692279,0.0010737916371117789,0.0011402403153462249,0.0010704233445085595,0.001062734980842231,0.0011030923652679482,0.001078509160405108,0.0010462030026931384,0.0010591593019263223,0.0011205108998066985,0.0010343400852904129,0.0011285209402119554,0.001036178737157558,0.0010505552142150746,0.0011205653257250103,0.0010713420795536272,0.001074297834172018,0.0011147311714503677,0.00108386472574479,0.0010766647646565381,0.0010009221563399943,0.0011022094776460718,0.0010968638450329711,0.0010649918407101783,0.001058521284806049,0.0010490081555561688,0.0010410228267955775,0.0011004125408713668,0.0010405624037062519,0.001123690290154105,0.0010388799502364886,0.001076970150061199,0.0010505146006446902,0.0010377258703840584,0.0010574681397057862,0.0010821899151726118,0.001084019098078677,0.0010479387149087797,0.0010456257963590144,0.0010568159031350305,0.001042499515201011,0.001077960421970458,0.0010580375511985635,0.0010743750869723395,0.0010509962495191716,0.0010586878176962798,0.0010773929226239167,0.0010401725505598887,0.0010536079022828917,0.0010342378490458414,0.001029313710182276,0.0010339359570838357,0.0011059842139130864,0.0010026460370937513,0.0010598375583747211,0.0010842022354589872,0.000990787046075101,0.001049681401371156,0.0010601756189201608,0.001025006339974607,0.0010319223942148608,0.00108066763577475,0.001042144732977813,0.001034445575406422,0.001056105351545685,0.0010162480685953163,0.0010195659711986188,0.0010362867191793404,0.0010346366526908382,0.001011641404355019,0.0010298821117826686,0.0010554828530512255,0.001055126780148627,0.0010507887052945046,0.0010993122418784054,0.0010294678185805814,0.0009878148786516903,0.0010333649065082644,0.0010536061342866288,0.0010274944220870661,0.001059063792212409,0.001033934489323952,0.0010031990062914996,0.0010433866738889983,0.0009891116841801806,0.0010403640032802068,0.0010087119208410634,0.0009995638791682924,0.0010740923656929234,0.001019481287337278,0.0010281365868366975,0.0010191821179350454,0.00098610126617869,0.0010013975028484493,0.0010346213241351546,0.000997804578456048,0.001022042453064908,0.0010185583298144,0.000988190027798635,0.0010324529583079446,0.0009797241529494757,0.0010159943407694657,0.0010574139528671915,0.001010064217860196,0.000969098171511883,0.0010191378319457363,0.0010035881226089197,0.0009953181649866067,0.0009618771372141656,0.0010358849992532961,0.0009790387087326331,0.0010364894280957217,0.0009882470012324512,0.0010010999294174261,0.0009974568477855374,0.0009862175103882496,0.001007311513399721,0.0009706495711001353,0.0010419860042674316,0.0009712487466485028,0.0010084236522100694,0.0010553404123048254,0.0009892522568047154,0.0009619483930806981,0.0010226982326496199,0.0009921976899199044,0.00098036946765337,0.0009937402963597862,0.000984954539940898,0.0009977404642973738,0.0009758989398274458,0.0009694627692739831,0.0009696599465667914,0.0010200698749893609,0.0009787653116323952,0.0009883275005317083,0.0009520990342638748,0.0010106167633145984,0.0010477380779463981,0.0010157878978562117,0.0009502602819902699,0.0010154346206064804,0.0010076946669777202,0.0009936138648265664,0.0009476619241652456,0.0010205421693520833,0.0010022145342946825,0.0009980997539280416,0.0009967957980553334,0.0009269070231880368,0.0009848976223274563,0.0009996520736045794,0.000926470245890189,0.001013043434308579,0.0009765466300217914,0.0009706759070825906,0.0009578544515481644,0.0009969606126610311,0.0009848053040644614,0.0009696533568838186,0.0009868864211016778,0.000996060366306984,0.0009579887165405998,0.000968825157079621,0.0009794250963816354,0.0009637084448753898,0.000927434256525016,0.0009814787727546966,0.0009855491601254238,0.0010015840770786829,0.0009548939740345943,0.0009522530263872869,0.0009447447761114737,0.0009609798975771943,0.0010101929868979265,0.0009331438836891011,0.0009835632597978157,0.0009273676653460018,0.0009385054277068519,0.0009913296670882106,0.0009946261702663748,0.0009619016877872099,0.0009352763261914532,0.0009891845863615808,0.0009424331228235293,0.0009477663167614144,0.000937360146900794,0.0009841621811001757,0.0009564527983645784,0.0009186086021599656,0.0010081685299280722,0.000894889546265046,0.0009867051651839512,0.0009277024879586513,0.0009633582942687712,0.0009508219478619301,0.0009606525926700197,0.0009380397209206729,0.0009317972997273121,0.0009393447069074864,0.0009884894137417919,0.0009121302483250602,0.0009723053413776925,0.000957544865853415,0.000945106818072781,0.0009236993567666446,0.0009481343484946512,0.0009134693383840244,0.0009268031912531133,0.0009396999439087542,0.0009653690644338799,0.0009311796288877788,0.0009591389714686292,0.0008957914104269518,0.0009630217224772934,0.0009250985945780527,0.0009422175355499388,0.000939788017506218,0.0009412659195659567,0.0009493500779835626,0.0009353517872630759,0.0009092390611689129,0.0009370534486290117,0.0009437845578216088,0.0009316969307620344,0.0009363814098681845,0.0008910652242327925,0.0009384459449541143,0.0009565025338267209,0.0008887732680943156,0.0009448785046665998,0.0009314886487956385,0.0008986255462114015,0.0009687034160025705,0.0008722390487747418,0.0009436729513372736,0.0009100265622327713,0.0009499385777273327,0.0009317382882530065,0.0009084931802677509,0.0009093736330680863,0.00090309417656588,0.0009334282143506591,0.0009280100402470556,0.0009657798210817274,0.0008645969474198358,0.0009430988352752512,0.0009229595020786377,0.0008684918102561143,0.00094770194912909,0.0009154382541515068,0.0009101442221734129,0.0008866034972085982,0.0009523204029835446,0.0009326593293465755,0.0008856502785128333,0.0008825156181198023,0.0009116508451849897,0.0009205270620665105,0.0008900003169019525,0.0008699490327277953,0.0009481792587593683,0.0009486337970471542,0.0008709122238212251,0.0009239082316928672,0.0009135687916845182,0.0009100163749091112,0.0008989462510438858,0.0008977316543926115,0.000899877042657908,0.0009336200814758201,0.000913915569266019,0.0008930931817369471,0.000872944346157243,0.000912538454227545,0.0008606751671564216,0.0008977505079171743,0.0008834641688981906,0.0009379567720548702,0.0009231524722003552,0.0008805403009139055,0.0008870843289991834,0.0009055015092055044,0.0009424140279021775,0.0008721093350737182,0.0008634725726429773,0.0008856140662561001,0.0009274801403111064,0.0008690814096963683,0.0009028732339768425,0.0008911146225960446,0.0008934209515330516,0.0008793147192342236,0.0009403125079212748,0.0008718399915858807,0.0008647408293148973,0.0009219058353562847,0.0009078006901855798,0.0008956007388408045,0.0009129347237679698,0.0008667267787223064,0.0009124636128674001,0.0008820415495117437,0.0008711587277182633,0.0008471900177613997,0.0008849202755240968,0.0009209042147085053,0.0008741013619507268,0.0009462830878230232,0.000880832633478803,0.0008576206313991027,0.0008626231137720421,0.0008952372411262599,0.0008622837903520679,0.0008751044862379013,0.0008889358790239726,0.0009039163715020721,0.0008650195754112943,0.0008852106823211826,0.0008397445389360584,0.0009474907566392199,0.0008767589224436162,0.0008405292928651361,0.0008525239245149344,0.0008307035600393562,0.000930381891350245,0.0008468222355698117,0.0008881228155988988,0.0008532048832311715,0.000843177494844051,0.0008757558688622494,0.000874761927623495,0.0008757579492419662,0.0009068655584145684,0.0008659809000680024,0.0008592595151357074,0.0008384952971411799,0.0008424411902616454,0.0008857126518481819,0.0008110363979091412,0.000830190042575846,0.0009048576758830697,0.0008773842031800102,0.00086367279885166,0.0008490245823132771,0.0008443913686390297,0.0008764834220035831,0.000824195017984229,0.0008339792726908566,0.0008435009510943889,0.0009015682090210883,0.0008404329499882501,0.0008728752965646806,0.0008216016787970473,0.000851969596178836,0.000813162644490357,0.0008719456792849513,0.00087032413623544,0.0008825241849674597,0.000817936433457283,0.0008147774008355486,0.0008189274031563299,0.0008833193525209106,0.0008205472354342391,0.0008642034546446294,0.0008292664972187859,0.0008169081413430871,0.000878881065700702,0.0008174574474604133,0.0008494935344047485,0.0008196840266358956,0.0007981812214620402,0.0008896555659862233,0.0008276624026353301,0.0008553810695279502,0.0008079203054790843,0.0008606223849550483,0.0008490697657116504,0.0008078466208294411,0.000831134190144797,0.0008368446560889994,0.0008187871933291218,0.0008436011085039582,0.0008535377929252275,0.0008057657576169463,0.0008269032185101844,0.0008687047123941576,0.0008163042903644121,0.0008255612441176825,0.000820586081570075,0.0008337563719652117,0.0008201508318547011,0.000806592354217861,0.0008267016740980928,0.0007865212731197054,0.0008197192175553121,0.0008329145852010135,0.0008191332532501857,0.0007812995232604624,0.0008640893928712824,0.0008414353712195636,0.0007616832393302444,0.0008367825532893777,0.0007797247487675304,0.0008559585584746618,0.0007819901209968323,0.0008519715575453016,0.0008148265552742966,0.0008037991747198305,0.0007621163225129462,0.0008270152880578775,0.0008329357145117108,0.0008112354782905398,0.0007676088061735294,0.0008056948731138862,0.0008176929264473173,0.0007708131987124061,0.0008180877061805657,0.0008402512355710956,0.0007655651902468747,0.000832638060544877,0.0007798662140967708,0.0008028464515264336,0.000821324137859024,0.0007910455944436738,0.0007583824965419793,0.0008389232277522477,0.0007836094362165811,0.0007987058758275051,0.0007720429636903143,0.0007905594592962292,0.0007633101360100592,0.0007670006746498125,0.0008200204183276748,0.000757221255602542,0.0007690987816536564,0.0007731273495934823,0.000774990332403318,0.0007709900991313173,0.0007972935127853826,0.0007342089289704964,0.0007929820794161675,0.0007704097936429821,0.0007932069631342846,0.0007691035515924217,0.0007544561965133774,0.0007746854465734551,0.000788647085565858,0.0007626942913042352,0.0007730292162517551,0.0007648040861465976,0.0007842010327623831,0.0007438692621649686,0.0007587566486808647,0.0007738964678494954,0.0007272703051485629,0.0008067227682363875,0.0007322804329116953,0.0007489198420406852,0.0007947329616435861,0.0007519509658201702,0.0007830317847939619,0.0007488028266322794,0.0007687293285721929,0.0007738238955349116,0.0007680186038343652,0.0007691692768534886,0.0007163306086425826,0.000762745205067779,0.0008058568484636318,0.0007516896450542143,0.0007692194417112286,0.0007373475079187074,0.0007689519424021774,0.0007577473318077337,0.0007313870053499065,0.0007526457525772324,0.000760412903015858,0.0007417248844239856,0.0007303706149470097,0.0007845953844692131,0.0007384873488010778,0.0007333597140942797,0.0007508803958809666,0.0008046121269254412,0.0007294933824205661,0.0007582786930087433,0.0007028207325068189,0.000753943135899259,0.0006947330714133765,0.0007325350709607211,0.0007454899047159863,0.0007836387327853118,0.0006894352372603174,0.0008424335229294813,0.0007268093543285021,0.0006899779775675354,0.0007823285435321342,0.0007198898170022036,0.0007154906131506901,0.0007519350867492087,0.0007306676051428877,0.0007241679600830919,0.0007468416932079968,0.000709754247746382,0.0007289124935917642,0.0006958130685361473,0.0007152500271261305,0.000726927843219258,0.0007723584909197639,0.0007235836556793018,0.0007345872577021417,0.0007362937591860433,0.0007373493846769324,0.0007042897361669402,0.0007091115776643796,0.0007417730176307383,0.0007339781486899429,0.000741973505984538,0.0007391394146106378,0.0006764186207071369,0.000691234323084332,0.000762649531263029,0.0006967053795500183,0.0007160090737014479,0.0007225834602064288,0.000722459805754392,0.000777471638659568,0.0007152600916800739,0.0006903895857745042,0.0007304287105458884,0.0006971170612011527,0.0006947271423768229,0.0007359475895902311,0.0006874017081104345,0.000732828502625281,0.0007411740985050218,0.0006766365732198898,0.0006893288628302123,0.0006876799886508657,0.0007257381806164684,0.0007004002974210228,0.0007195322928049763,0.00070717002167417,0.0007138958344611242,0.0007152682679957531,0.0007011967382407259,0.000745350936804342,0.0006670210147765212,0.0007322203785091733,0.000707192374609604,0.0006930468549131246,0.00067666274089865,0.0006960668117740384,0.0007740997502412333,0.0007091655845788113,0.0006979704796324233,0.0006888052996653003,0.0007087928465560789,0.0006923208875268186,0.0007539641270984135,0.0006790953145286043,0.0006729700370251894,0.0007619060164084939,0.0006734263752216408,0.0007114062620148813,0.0007164456344934785,0.0006871698690332311,0.0007146033337643085,0.0006919289657616352,0.0006920221737101202,0.0006788673890564721,0.000663243736224968,0.0007223466926114465,0.0006954459637370908,0.0007069295859433355,0.000668375738893621,0.000714041104071759,0.00069921805703225,0.0006894162056722709,0.0006959448106583001,0.0006973102219547151,0.0007238630802916594,0.0006946623766293751,0.0006729563046864653,0.0007155539835643122,0.0007111621847243101,0.0006444843361882742,0.0007147532784190721,0.0006757809266779994,0.0006955085083602425,0.0006746269274315942,0.0006860322750087005,0.0006789242737745109,0.0007137300743846688,0.0007074248490560759,0.000683766536366035,0.0007152518392169783,0.0006902180797453022,0.0006705061576089881,0.0007034694292583695,0.000663206326603649,0.0006792934161576636,0.0006913579749033322,0.0007085993005717184,0.000677007789733686,0.000730705683450164,0.0006867336652458469,0.0006617397042968736,0.0006991784777888294,0.000705724031139509,0.0006847769590794021,0.0006437951082628292,0.0006763137287468131,0.0007105435744524496,0.0007111010051024033,0.0006833485001094293,0.000666708002377816,0.0006787999716305946,0.0006774592486676952,0.0007359455511284558,0.0006426897915097041,0.0006624845818355814,0.000679750020115269,0.0006768861857851781,0.0007108569571263055,0.0006620288903129021,0.0007084191286575781,0.0006766041912589518,0.0006999991290634712,0.0006828093927606954,0.0006493554810490077,0.0006964563741629541,0.0006557007202475845,0.0007203777721396055,0.0006754650490791553,0.0006981540700354455,0.0006988599404720173,0.0006316123506466019,0.0006913064015114768,0.0006419683404129776,0.0006968601567044953,0.0006469961247573729,0.0007170349417017847,0.0007239681566698618,0.0006509354447654423,0.0006657710807387851,0.0007202347420845226,0.0006405548921034113,0.0006586313941749094,0.0006421331108187688,0.0006928626285089052,0.0006895349394354241,0.0006427549705034587,0.0007458427801994501,0.0006430337958367018,0.000632503042518542,0.000676270615055582,0.000677247077706343,0.000648889835524812,0.0007033032279552058,0.0007049332419747377,0.0006415263990634564,0.0006690437790900648,0.0006598117551724207,0.0006651824201691438,0.0006815980915477291,0.0007048127017729883,0.0006321063791811736,0.000671829727356995,0.0006970063313775538,0.0006579485295264025,0.0006430096534545341,0.0006692855760656787,0.0006977291926233249,0.000654301579156385,0.0006727786367900661,0.0006572871913207162,0.0007119263610516117,0.0006793508151603977,0.0006873849062128296,0.0006592453030020614,0.0006747598065691354,0.0006582863645785937,0.0006523419263412046,0.0006609336166983567,0.0006737105022265999,0.0006622627226338666,0.0006450144873861228,0.0006358571431250733,0.0007321583430801796,0.0006452144893303074,0.0006816129556357685,0.0006731723738408482,0.0006644870626399758,0.0006951081075503932,0.0006310796144388086,0.0006792696748045133,0.0006496128760628173,0.0006700543210624332,0.000649384938478717,0.0006214983352171808,0.0006785079591025107,0.0006653352075905749,0.0006490245300883807,0.0006862490328952257,0.000668109117825128,0.0006670198181842929,0.0007118580421442401,0.0006376128362261986,0.0006755248791118578,0.0006042741480537896,0.0006266459038360909,0.0006825683636136412,0.0006119446368776802,0.0007015230856704963,0.0006384703013537602,0.0006758781688246287,0.0006819780689815286,0.0006458232508167912,0.0006557203180789138,0.0006403311892495175,0.000662803730789226,0.0006117939164601401,0.0006837892808164475,0.0006463601888944951,0.00065766598027204,0.0006530977797102457,0.000650689599162644,0.0006711321000801231,0.0006579173127718975,0.0006235103494393896,0.000629379120420842,0.0007022749716151996,0.0006377990223117402,0.0006639109911445968,0.0006198182375076484,0.0006174029488497345,0.0007059187403643016,0.0006732601288759989,0.0006682338862271533,0.0006275169384051834,0.0006978024713289491,0.0007211322396186453,0.0006147133312072937,0.000666606459464424,0.0005893051096707789,0.0006997323258239573,0.0006553794541921404,0.0006985411604945587,0.0006508366283789318,0.0006383186726439385,0.0006437703390424314,0.0006423383422894685,0.0007105682870801156,0.0006423427645620902,0.0006239307156173609,0.0006360168687030853,0.0006935844456679238,0.0006218135415672452,0.0006550672887184121,0.0006370494546679346,0.0006254509925733875,0.000652436064418621,0.0006488112039612416,0.0006803653624377228,0.0006541652908333576,0.0006234088776530911,0.0006532637333675469,0.0006748711358122775,0.0006374033027950931,0.0006237388034146144,0.0006674778239354401,0.0006438027266907282,0.0007097580887849664,0.0006230928429497341,0.0006733724749627421,0.0006189424459894376,0.0006308139023296332,0.000651309589215861,0.0006384392471453771,0.000685602492600594,0.0006130307436633105,0.0006821256144485123,0.0006634608965799037,0.0006602204394449825,0.0006462064856327441,0.0006463932582183962,0.0006590900391922192,0.0006110954346751459,0.000680259225086227,0.0006211082344600622,0.0006357654717464935,0.0006471133458234855,0.0006248934985199141,0.0006643145052568405,0.0006350812764666454,0.0006520445613413532,0.0006264819260445099,0.0006419329545786436,0.0007057546866710542,0.0006055224495386622,0.0006554384214665395,0.0006435531152137617,0.0006376078810269829,0.0006661453172050538,0.0006991086422173089,0.0006103634765690173,0.0006288823601986373,0.0006568065880425949,0.0006457245451933507,0.0006334350573711223,0.0006710775486888438,0.0006243508942178097,0.0006574978219205907,0.0006570532080389905,0.0006276624770068302,0.0006347697881748057,0.0006540094917798494,0.0006446716269555157,0.000637120748169336,0.0006183814225435837,0.0006088492712548028,0.0006415074976176289,0.0006673127490453045,0.0006057214464352492,0.0006485506219902291,0.0006432986617581503,0.0006522948144717688,0.0006903297708729851,0.0006259835803832419,0.0006322705401267758,0.0006278814716052278,0.0006557537029108058,0.0006325462004447871,0.0006910636953659023,0.0006615629901916273,0.0006477191223944363,0.0006405832004408713,0.0006068338869213699,0.0006435205610873418,0.0006400336816795147,0.0006327600542324471,0.0006558977789835346,0.0006408680616768439,0.0006742246310811926,0.0006267055613171327,0.0006560707844041661,0.0006292495255224267,0.0006259637812123858,0.0006440376721191096,0.0006271419722016169,0.0006061202444982085,0.0006429547283124961,0.0006753228096371748,0.0006004138413995878,0.0006518895501274822,0.0006577591663487683,0.0006156061776754737,0.0006103339308799234,0.0006070502025279721,0.0006263593051119722,0.0006393131057339169,0.0006535334114265596,0.0006382092411530994,0.0006598850964741002,0.0006054505435929637,0.0006329063691936918,0.0006160427512816155,0.0006289515704415353,0.0006630805687767098,0.0006732799429673953,0.000645679367166372,0.0006830715893799231,0.0006166803063917456,0.0006285143779664873,0.0006182240337328323,0.0006270596711330152,0.0006299550068313065,0.0006337968604633556,0.0006653287278281006,0.0006272998971688202,0.0006372244023918472,0.000639194077491958,0.0006709984109152234,0.0005752628283525747,0.0006733575138736368,0.0006351774902896342,0.0006396684262199963,0.000634875352507338,0.0006680780522771341,0.0006690471595930063,0.0006007391246964209,0.0006257237131236654,0.0006451352331051502,0.0006196094042887244,0.0005909004411926949,0.0006417086833048235,0.0006412135835105623,0.0006259809717812898,0.000630917441119823,0.0006491558777114468,0.0006015483096235772,0.0006514736787535124,0.0006010365970890556,0.0006352086285094363,0.0006296393386115274,0.000610450430599348,0.0006348213004099993,0.0006455680807539576,0.0006305585632258543,0.0006270865795376124,0.0006561427721495328,0.0005820008782294676,0.0005950130397199447,0.0006708201077548771,0.0006281115206739831,0.0006000139685662237,0.0006534678972648082,0.0006026866393536216,0.0006405419470075028,0.0006379983783194029,0.000638375504771461,0.0006609658059210206,0.0006280681507356366,0.0006217459848361815,0.0006384457531328952,0.0006243451452107406,0.0006145645863395094,0.0006208128294926047,0.0006389213494989635,0.0006358808217066328,0.0006004661084736941,0.0006019475825810053,0.0005810252120898109,0.0006928478482567488,0.0006483134419915117,0.0006476734108791493,0.0006120889178006511,0.0006569126502647816,0.0006114008707043223,0.0005974471003133961,0.0006740761240292678,0.0006002169618154432,0.0006156942985973807,0.0006046438868372703,0.0006666328526013256,0.0006304827596137325,0.0006490298163129491,0.0006200240581817094,0.0006260236627472827,0.0005914885605855612,0.0005977913379976447,0.0006434340606063303,0.0006617150146292862,0.0006393660151285082,0.0006414867484471924,0.0006304202911731044,0.0006136956149125213,0.0006064430046790089,0.0006308953334780722,0.0005862900601931374,0.0006159186535666554,0.0006470572200167892,0.000641131101885869,0.0006607346743231794,0.000613792443391558,0.0005852310603781659,0.0006454759496471994,0.000634517668081061,0.0006059489748454726,0.0006206642517699794,0.0006015174559472563,0.0006285291575165005,0.0006418402638638547,0.0006074805566560773,0.0006764876935406351,0.0005937803397839833,0.0006247114909229187,0.0006543270152020611,0.0006030035375174252,0.0006427508040215591,0.0006008164631230902,0.0006273431920129648,0.0006234831646010639,0.0006185504597675199,0.0006174560247926632,0.0005918288229112553,0.0006424837358283559,0.0006067064308911894,0.0006216697655202522,0.00063521671793491,0.0006017631064947083,0.000648344373359964,0.0006378633186063281,0.0005829150668981252,0.0006035004357809585,0.0005975542792941436,0.0006312003397956868,0.0006022197994489483,0.0006379504878084041,0.0006122994098325897,0.000678192973927515,0.0006155677096436836,0.0006578778068673212,0.0006221439804900348,0.000596357913015453,0.0006577403569538977,0.000576754733918693,0.0005900816799818894,0.0006279941445044652,0.0005789942638423357,0.0006363717894942193,0.0006305063172511473],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"loss\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"train loss\"}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('0e356ee4-4ec0-428e-b837-023d24eb65b0');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_validation = True\n",
    "train_loss_threshold = 0.0003\n",
    "\n",
    "train_loss_list, validation_loss_list = train_model(epoch_count, model, optimizer, loss_function, train_loader, test_loader, True, train_loss_threshold)\n",
    "plot_loss(train_loss_list, \"train loss\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss=0.0006121573153833514\n"
     ]
    }
   ],
   "source": [
    "test_loss = test_loop(test_loader, model, loss_function)\n",
    "print(f\"test loss={test_loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "hovertemplate": "epoch=%{x}<br>loss=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "showlegend": false,
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000,
          1001,
          1002,
          1003,
          1004,
          1005,
          1006,
          1007,
          1008,
          1009,
          1010,
          1011,
          1012,
          1013,
          1014,
          1015,
          1016,
          1017,
          1018,
          1019,
          1020,
          1021,
          1022,
          1023,
          1024,
          1025,
          1026,
          1027,
          1028,
          1029,
          1030,
          1031,
          1032,
          1033,
          1034,
          1035,
          1036,
          1037,
          1038,
          1039,
          1040,
          1041,
          1042,
          1043,
          1044,
          1045,
          1046,
          1047,
          1048,
          1049,
          1050,
          1051,
          1052,
          1053,
          1054,
          1055,
          1056,
          1057,
          1058,
          1059,
          1060,
          1061,
          1062,
          1063,
          1064,
          1065,
          1066,
          1067,
          1068,
          1069,
          1070,
          1071,
          1072,
          1073,
          1074,
          1075,
          1076,
          1077,
          1078,
          1079,
          1080,
          1081,
          1082,
          1083,
          1084,
          1085,
          1086,
          1087,
          1088,
          1089,
          1090,
          1091,
          1092,
          1093,
          1094,
          1095,
          1096,
          1097,
          1098,
          1099,
          1100,
          1101,
          1102,
          1103,
          1104,
          1105,
          1106,
          1107,
          1108,
          1109,
          1110,
          1111,
          1112,
          1113,
          1114,
          1115,
          1116,
          1117,
          1118,
          1119,
          1120,
          1121,
          1122,
          1123,
          1124,
          1125,
          1126,
          1127,
          1128,
          1129,
          1130,
          1131,
          1132,
          1133,
          1134,
          1135,
          1136,
          1137,
          1138,
          1139,
          1140,
          1141,
          1142,
          1143,
          1144,
          1145,
          1146,
          1147,
          1148,
          1149,
          1150,
          1151,
          1152,
          1153,
          1154,
          1155,
          1156,
          1157,
          1158,
          1159,
          1160,
          1161,
          1162,
          1163,
          1164,
          1165,
          1166,
          1167,
          1168,
          1169,
          1170,
          1171,
          1172,
          1173,
          1174,
          1175,
          1176,
          1177,
          1178,
          1179,
          1180,
          1181,
          1182,
          1183,
          1184,
          1185,
          1186,
          1187,
          1188,
          1189,
          1190,
          1191,
          1192,
          1193,
          1194,
          1195,
          1196,
          1197,
          1198,
          1199,
          1200,
          1201,
          1202,
          1203,
          1204,
          1205,
          1206,
          1207,
          1208,
          1209,
          1210,
          1211,
          1212,
          1213,
          1214,
          1215,
          1216,
          1217,
          1218,
          1219,
          1220,
          1221,
          1222,
          1223,
          1224,
          1225,
          1226,
          1227,
          1228,
          1229,
          1230,
          1231,
          1232,
          1233,
          1234,
          1235,
          1236,
          1237,
          1238,
          1239,
          1240,
          1241,
          1242,
          1243,
          1244,
          1245,
          1246,
          1247,
          1248,
          1249,
          1250,
          1251,
          1252,
          1253,
          1254,
          1255,
          1256,
          1257,
          1258,
          1259,
          1260,
          1261,
          1262,
          1263,
          1264,
          1265,
          1266,
          1267,
          1268,
          1269,
          1270,
          1271,
          1272,
          1273,
          1274,
          1275,
          1276,
          1277,
          1278,
          1279,
          1280,
          1281,
          1282,
          1283,
          1284,
          1285,
          1286,
          1287,
          1288,
          1289,
          1290,
          1291,
          1292,
          1293,
          1294,
          1295,
          1296,
          1297,
          1298,
          1299,
          1300,
          1301,
          1302,
          1303,
          1304,
          1305,
          1306,
          1307,
          1308,
          1309,
          1310,
          1311,
          1312,
          1313,
          1314,
          1315,
          1316,
          1317,
          1318,
          1319,
          1320,
          1321,
          1322,
          1323,
          1324,
          1325,
          1326,
          1327,
          1328,
          1329,
          1330,
          1331,
          1332,
          1333,
          1334,
          1335,
          1336,
          1337,
          1338,
          1339,
          1340,
          1341,
          1342,
          1343,
          1344,
          1345,
          1346,
          1347,
          1348,
          1349,
          1350,
          1351,
          1352,
          1353,
          1354,
          1355,
          1356,
          1357,
          1358,
          1359,
          1360,
          1361,
          1362,
          1363,
          1364,
          1365,
          1366,
          1367,
          1368,
          1369,
          1370,
          1371,
          1372,
          1373,
          1374,
          1375,
          1376,
          1377,
          1378,
          1379,
          1380,
          1381,
          1382,
          1383,
          1384,
          1385,
          1386,
          1387,
          1388,
          1389,
          1390,
          1391,
          1392,
          1393,
          1394,
          1395,
          1396,
          1397,
          1398,
          1399,
          1400,
          1401,
          1402,
          1403,
          1404,
          1405,
          1406,
          1407,
          1408,
          1409,
          1410,
          1411,
          1412,
          1413,
          1414,
          1415,
          1416,
          1417,
          1418,
          1419,
          1420,
          1421,
          1422,
          1423,
          1424,
          1425,
          1426,
          1427,
          1428,
          1429,
          1430,
          1431,
          1432,
          1433,
          1434,
          1435,
          1436,
          1437,
          1438,
          1439,
          1440,
          1441,
          1442,
          1443,
          1444,
          1445,
          1446,
          1447,
          1448,
          1449,
          1450,
          1451,
          1452,
          1453,
          1454,
          1455,
          1456,
          1457,
          1458,
          1459,
          1460,
          1461,
          1462,
          1463,
          1464,
          1465,
          1466,
          1467,
          1468,
          1469,
          1470,
          1471,
          1472,
          1473,
          1474,
          1475,
          1476,
          1477,
          1478,
          1479,
          1480,
          1481,
          1482,
          1483,
          1484,
          1485,
          1486,
          1487,
          1488,
          1489,
          1490,
          1491,
          1492,
          1493,
          1494,
          1495,
          1496,
          1497,
          1498,
          1499
         ],
         "xaxis": "x",
         "y": [
          0.08533420987176092,
          0.051239270026261885,
          0.046199522274180074,
          0.025713520721019654,
          0.01702035175573625,
          0.01430731124160916,
          0.01365576161521623,
          0.01290373401873316,
          0.01233755189956825,
          0.011170562864228916,
          0.011374976810360893,
          0.010645861802831962,
          0.011976023466232118,
          0.00827516602441208,
          0.008295854302437117,
          0.007806208099793183,
          0.007232360298525584,
          0.0071746784162948305,
          0.007156291946486225,
          0.007299011951218244,
          0.007518077050754277,
          0.006193089266203009,
          0.006391465714923368,
          0.006971171103532981,
          0.005525834369211552,
          0.006342594647842846,
          0.005271978769189773,
          0.006745926233981684,
          0.005531877258353019,
          0.006085760106615136,
          0.0046501071794021335,
          0.004591815146157162,
          0.004981492207846029,
          0.005058607722245408,
          0.0052044190325135934,
          0.004355952965116568,
          0.004706426539322298,
          0.004055707055546888,
          0.005070503089535102,
          0.004107605302941807,
          0.004812104613101633,
          0.003916825878099025,
          0.004562791732527064,
          0.0038720103114152724,
          0.006402425732191527,
          0.0037412949735717324,
          0.004312603918866914,
          0.003955311648118613,
          0.003495033061278335,
          0.0036068588555424235,
          0.0033711559725192824,
          0.003388757391027018,
          0.0036286563753788726,
          0.004581214483366923,
          0.004185712286088029,
          0.0035603385624015348,
          0.004104974920327744,
          0.0036623219232169097,
          0.0033301596975822546,
          0.0029155961087423514,
          0.003222712247601051,
          0.003196068623448523,
          0.0032003018769613477,
          0.0029922235257442246,
          0.003725138931728774,
          0.0038982763777884624,
          0.00279113263927735,
          0.0027708294644449532,
          0.0036620976242467008,
          0.0031062574001562812,
          0.0029786716796081055,
          0.0030613320688664745,
          0.0028690603062029134,
          0.002594846800451031,
          0.002388926938416834,
          0.0028890403690015414,
          0.003245014358531642,
          0.0024658113886769652,
          0.003185633101024445,
          0.003075268603547403,
          0.0024125570538610724,
          0.0032853104633258218,
          0.0025232035053234674,
          0.002866252835609772,
          0.002994236601071872,
          0.00263412521689021,
          0.003185962765671187,
          0.002180374287960925,
          0.003066724398450696,
          0.0021592802603551176,
          0.002274550100542563,
          0.0026197008758500804,
          0.002118311540859364,
          0.0025814381111517884,
          0.0025141099402471705,
          0.0028457555670050507,
          0.0019312663137222106,
          0.0021221585701915614,
          0.00243799770093952,
          0.002045695802714843,
          0.002088488023688891,
          0.002195699428197708,
          0.0023560502221075335,
          0.0023162787226865883,
          0.0029273470589012075,
          0.0019004200889305158,
          0.0021207786153405487,
          0.0019793436974365514,
          0.002108774890892961,
          0.0022882133894966223,
          0.0023046142285626926,
          0.0021210481795963694,
          0.0028080372532222715,
          0.002229922590384867,
          0.00262791713963922,
          0.001810821702931432,
          0.002234320748817134,
          0.001907976218002189,
          0.0020376180067757836,
          0.002272621384466046,
          0.001975784969667831,
          0.0019749738714197294,
          0.0021305981862588964,
          0.0021658490570209753,
          0.0023512041086351937,
          0.001769034108251668,
          0.001616324558710219,
          0.0022343805346250784,
          0.0023207756869882096,
          0.0016152035556812091,
          0.001928481443397952,
          0.0019016551070328634,
          0.0021399902879637193,
          0.0025323974851550264,
          0.0022244787522528865,
          0.0026048753492984127,
          0.0017567122570275632,
          0.0019351460047463856,
          0.0019024210832254396,
          0.0014905083350303552,
          0.0015459345271706245,
          0.001790607962861992,
          0.001693899103955711,
          0.0015539004695680244,
          0.001792352072360894,
          0.002047742285315743,
          0.0018506440725779224,
          0.001832563887556931,
          0.00166710730631616,
          0.002215934619098232,
          0.001567043453648561,
          0.0015962647801929604,
          0.0019719785091132343,
          0.0015593697836889435,
          0.001767316840005662,
          0.0020697854284008736,
          0.0015209924120304248,
          0.0017217195369146263,
          0.0017419259107718768,
          0.0017151861367197812,
          0.0018318308026168831,
          0.0032131408754568756,
          0.0017628105395876416,
          0.0016873144345839373,
          0.0017394865146874753,
          0.002345953247865683,
          0.0018240718414295424,
          0.0025847671367751246,
          0.0019334580989952168,
          0.0019870984320282895,
          0.0017416971275227124,
          0.0019319546029620458,
          0.0016812564670422188,
          0.0014574141895628712,
          0.0020780823702971044,
          0.0018572733875526263,
          0.00149621382706244,
          0.001723414163361565,
          0.0013540451342287066,
          0.0015461736596110956,
          0.0017263062600454504,
          0.0015425070164740882,
          0.0014454597022562298,
          0.0014722985568655174,
          0.002002681794856267,
          0.001670368495161823,
          0.0014203585337015559,
          0.0015384788462091655,
          0.001614430116154672,
          0.0013829309596638248,
          0.0014924958434604694,
          0.0016609349888435491,
          0.0016553092619085036,
          0.0016125261592626404,
          0.0017115298074570726,
          0.0018277686047420074,
          0.001995017662777806,
          0.0014298239911205313,
          0.0016972682336763886,
          0.0014220042882769715,
          0.0016489597737234546,
          0.0017323896957278837,
          0.0014608110192629478,
          0.001738086379763639,
          0.0015248020354192704,
          0.0015485743734347268,
          0.0014452862005884853,
          0.0019919548675501613,
          0.002019459731272537,
          0.0014843271984430972,
          0.0016160658292545614,
          0.0013566068190495285,
          0.0014602928484523188,
          0.002195404400379303,
          0.001844901787417972,
          0.001290922683305264,
          0.001430271362121939,
          0.0014297827130596917,
          0.001489627375162803,
          0.001561486409791337,
          0.001331801369283976,
          0.0013373020318274,
          0.0026781985855378796,
          0.0014713636839505954,
          0.0014810413252980856,
          0.0013750923824956997,
          0.0016453556590216507,
          0.0016026052586169224,
          0.00188235005329813,
          0.001768366348330622,
          0.0013657318669491646,
          0.001417493105936649,
          0.0013028629270664762,
          0.001613063557567912,
          0.0015845735916433584,
          0.0015427799296324676,
          0.0014672640984448907,
          0.0014452261629833557,
          0.001329553952529566,
          0.0017330546136108342,
          0.0012440997289671573,
          0.0020149770487764367,
          0.0013663777479839124,
          0.0012568542786109984,
          0.001358500210924095,
          0.0012351101002096084,
          0.0012459331980168695,
          0.0016752722966772494,
          0.0012537158144051942,
          0.0015505641339781035,
          0.0018189911216528814,
          0.0019282699916433291,
          0.0012241307530928864,
          0.0015143876459732066,
          0.0016140336408855373,
          0.001209110496408735,
          0.0018680015251202656,
          0.0018643722284109113,
          0.0016323223787234322,
          0.0014561164085596298,
          0.00143706021775502,
          0.0013420803229104768,
          0.0013895938797524262,
          0.0014017368879383743,
          0.0016563162979345476,
          0.0013105405142708692,
          0.001280758813091585,
          0.001425169904721545,
          0.0013235632226844265,
          0.0011901908722219549,
          0.0012010083425256393,
          0.0012869275174380982,
          0.0012972931406366524,
          0.0012704584544153067,
          0.001178746010972124,
          0.001256252563456492,
          0.0014047209056371594,
          0.001394555666562421,
          0.0012703305895157744,
          0.0019446523654735072,
          0.0016573582722915316,
          0.0011516438798424317,
          0.0013520094910061007,
          0.0013580291405754436,
          0.0015026933357925312,
          0.0011777506880933063,
          0.0015265813582639597,
          0.0012953813309425468,
          0.0012133332166239996,
          0.0013968091002885211,
          0.00122211820523129,
          0.0011109806949748877,
          0.001361160448836058,
          0.0012079203815926704,
          0.001274555870868119,
          0.001426795926245892,
          0.001179960367970922,
          0.0013090518958542203,
          0.001706615388602688,
          0.0011333183367773262,
          0.0011309115242296725,
          0.001138552298849145,
          0.0016673164258402342,
          0.001216794513597603,
          0.0015000981701213574,
          0.0011358040190704711,
          0.0023058322009766536,
          0.001517068459639284,
          0.0011271131489807844,
          0.0010664435134601538,
          0.0015276937063370068,
          0.0014869255943124424,
          0.0010082209764017064,
          0.001839440806148825,
          0.0012426731680922755,
          0.001745140703533661,
          0.0011230692328895661,
          0.0014492204299018708,
          0.0011332658470380695,
          0.0016291766107642206,
          0.0014907399688198577,
          0.001771361747916181,
          0.0011810704276326708,
          0.001196894971614578,
          0.001242363048139227,
          0.0010937799510266108,
          0.0015089421018335467,
          0.0012402043542484595,
          0.0011432930562917268,
          0.0011541874797392135,
          0.0011447510970468643,
          0.0012697285937872621,
          0.0013550757600538684,
          0.0012621785611505463,
          0.0015583347484699629,
          9.95356868821709E-4,
          0.0011971707304081556,
          0.0010424603327449536,
          0.0011567316875463415,
          0.00163132284952359,
          0.0011698127945942616,
          0.001490804756562529,
          0.0013156864864704606,
          0.0013004315983022698,
          0.0014224115649913176,
          0.001124107674891757,
          0.0010506123550605092,
          0.0010553574175809332,
          0.001221925001905373,
          0.0017680752868083924,
          0.0016873650840781838,
          0.001662392606121603,
          0.0013175619964937815,
          0.0011687923927158326,
          0.0011615416681226552,
          0.0013918727783491479,
          0.0010442591687269361,
          0.001466186650442692,
          0.001120812670011178,
          0.0010958950951227165,
          0.0014074635979708996,
          0.0010618278812329295,
          0.0014343960007935177,
          0.0013984768786153682,
          0.001771057241405308,
          0.0012251883048663606,
          0.001069765861879961,
          0.0024335148529766987,
          0.0011806411433538547,
          0.0013857041400585199,
          0.001212111873724864,
          0.0011281280335577813,
          0.0010288483891609972,
          0.0013438287132885307,
          0.00102586044522468,
          0.0010894189599843884,
          0.0012145458466865206,
          0.0010111887971648234,
          0.001115268635729673,
          0.0016418949679963375,
          0.0014814578161543507,
          0.0013927498919329491,
          0.00112291278573946,
          0.0012190982129089952,
          0.001480062834570561,
          9.484753961638243E-4,
          0.001055115804611182,
          0.0011497662906937846,
          9.367569020080767E-4,
          9.710300493700262E-4,
          0.001322404740461975,
          0.0012632372839444348,
          9.49787856779438E-4,
          0.0010862313199518877,
          0.0011418669708884123,
          0.001178414446401169,
          0.0011077315247031662,
          0.0013981337088102663,
          0.001134185634849049,
          0.0013499940085627683,
          0.0010273608109610303,
          0.0013918938138783815,
          9.05544729085817E-4,
          0.0011723157750269963,
          0.0013877756941378157,
          0.0010060565943471314,
          9.674178403697573E-4,
          0.001693897854126048,
          0.0010523817031395757,
          0.0012075383787754964,
          9.43178809843068E-4,
          0.0012078165708455059,
          0.0014688173868808519,
          0.0013731620594953301,
          0.0010301287592064297,
          0.0010242872016983148,
          0.0013556052430982837,
          9.972373387590575E-4,
          0.0012767266444835728,
          0.0012253427327338481,
          0.001092854902289515,
          0.001060607612232437,
          0.0011574671397069365,
          0.00112665415312467,
          0.001203263305347371,
          0.0012114098000607003,
          0.0013088193490546657,
          0.0010216487411362526,
          9.997884817800767E-4,
          0.0010742937382101343,
          9.132880131188215E-4,
          0.0013522758558026273,
          0.0010159534277601084,
          0.001077751516890346,
          0.0010982623562187982,
          9.500473668063687E-4,
          0.0010923220731221203,
          9.716593956684673E-4,
          0.0010527019072428681,
          0.0012225682652304262,
          0.0010440526623344258,
          0.0010458431702062717,
          9.786817369448922E-4,
          9.73945231604641E-4,
          0.0012450203007830078,
          0.0010708400288340374,
          0.001327018873187912,
          0.0010798907149753146,
          0.0010696468414382989,
          0.0011185815115066853,
          0.001479610148686497,
          8.572915960050951E-4,
          0.001079606756749772,
          0.001156615940631587,
          0.0012520540697275127,
          0.001236191724447973,
          0.0010155140957925886,
          9.399860233377163E-4,
          0.001292308045909583,
          9.573479959665369E-4,
          8.878100766758487E-4,
          9.710315488713134E-4,
          0.0012974548457697912,
          0.0011258765161063606,
          9.653977639358386E-4,
          0.0013134923235126092,
          0.0010750050870034571,
          9.584931875487497E-4,
          0.0010871151609351502,
          0.0011162722968559168,
          0.0013091111502720023,
          9.249912271095608E-4,
          0.0010608543700399923,
          0.0014723312604146895,
          0.0012796089917112643,
          9.276675138219647E-4,
          0.001011460227335887,
          0.0010846830146476166,
          0.0010635039163818792,
          0.0011358772838760292,
          0.0011991086204044437,
          0.001101494892506881,
          0.0010709375807861118,
          9.647977695044318E-4,
          0.0011477308129379002,
          0.0013939405208076821,
          9.252358246934757E-4,
          0.0010540379635437674,
          0.0010079508359554443,
          0.0012065158958096853,
          0.0010096689874536536,
          0.001042434311140946,
          0.0011256753298286557,
          0.0010659695515314934,
          9.766288891073652E-4,
          0.0010377322480584798,
          9.663626656271099E-4,
          0.0012417774892077267,
          9.219094068060493E-4,
          8.518557993595729E-4,
          0.0012108909444925322,
          0.001250659145370356,
          0.0013676533551384392,
          0.0012520292919034955,
          9.476187590868056E-4,
          9.44847396209972E-4,
          0.0012540002448322104,
          0.0013937400192875163,
          0.0011142580397165475,
          0.0012580813281499687,
          9.461973052801502E-4,
          0.0010018302776832447,
          9.193684081049908E-4,
          0.0012558696626716952,
          0.0013105950813369009,
          8.188491973965795E-4,
          0.0010668199643129065,
          0.001001475058238315,
          0.001025727785223823,
          0.00134384776158206,
          0.0015946450016037508,
          0.0012495929769010105,
          0.0013768002485694216,
          9.568619186691731E-4,
          9.937508730217814E-4,
          0.0010695790957327242,
          9.611734078563959E-4,
          0.001239156034275408,
          0.0014994198906371433,
          0.0012940606321443626,
          9.231966223013117E-4,
          0.001692614585469906,
          0.0014667091318903219,
          0.0013454429265059363,
          9.421612534363325E-4,
          0.0010934823084415952,
          8.600713489603335E-4,
          9.01264362848165E-4,
          0.0011303961748555511,
          0.0010273707672506258,
          9.624380651034749E-4,
          9.079198428204681E-4,
          8.20894482489309E-4,
          0.0012671843951363954,
          0.0010899570639757964,
          0.0010917100001105599,
          9.322530283263016E-4,
          9.143161229341908E-4,
          8.136259190466129E-4,
          0.0010876436838801698,
          0.001324228077127567,
          9.744713932152817E-4,
          9.115878811427863E-4,
          0.0013068666883739068,
          0.0010214286625484694,
          0.0010762582585382998,
          0.0010332827514503151,
          8.128585980281632E-4,
          7.969019874038301E-4,
          9.826319208800312E-4,
          9.684182958235295E-4,
          0.0011710563525452874,
          9.437536364918302E-4,
          0.0011493951468754644,
          0.0014578771867051596,
          0.0012363429839220526,
          0.0010512768708854873,
          8.848397876463014E-4,
          8.27807283161072E-4,
          0.0010133482417055103,
          8.898405917381261E-4,
          0.0012967231712209878,
          9.721059936198165E-4,
          9.665001047058345E-4,
          9.575615198157854E-4,
          0.001057624389329831,
          9.364530022630175E-4,
          9.013335104427415E-4,
          9.552296193831945E-4,
          0.0010690826273868593,
          9.084250992150935E-4,
          0.0013025429840801347,
          0.0013050409615971148,
          8.859595244951818E-4,
          8.253130976442938E-4,
          8.241490472704591E-4,
          0.0010795061129244734,
          0.001124624317260773,
          0.0012248697918918236,
          9.791405411735386E-4,
          0.0013675454914376264,
          9.86813858126583E-4,
          9.304740781087449E-4,
          8.512720571284109E-4,
          7.909014134332956E-4,
          8.505702499768519E-4,
          0.0013090155360137186,
          0.0011074780300128787,
          8.110904535069392E-4,
          9.682403427412671E-4,
          0.0010587979824899622,
          9.183072160636441E-4,
          7.698890629480855E-4,
          9.671004263100769E-4,
          9.669759557674E-4,
          0.0011563202493112493,
          0.0011686466515242132,
          0.0010225033700489701,
          0.0010425867668151583,
          7.39848039281722E-4,
          8.827123694184623E-4,
          8.175239024822486E-4,
          8.105351421210308E-4,
          8.876220837531067E-4,
          7.103635879492471E-4,
          0.00106722150397555,
          8.596550480964898E-4,
          8.552263651417276E-4,
          0.0011418479399263775,
          9.044490969122461E-4,
          9.17902834362905E-4,
          0.001219890604261309,
          0.001152461047383716,
          9.723583828550607E-4,
          9.078509295280772E-4,
          8.597995867112944E-4,
          9.894996297446321E-4,
          0.0010909632677630929,
          9.652108442577209E-4,
          0.0012032653220139151,
          7.692624548622773E-4,
          0.0017365153173895113,
          7.960609115563395E-4,
          0.0010746701941315314,
          0.0013403179257417495,
          7.768853119864872E-4,
          0.0010579267042241677,
          9.887500069616886E-4,
          9.18491525553282E-4,
          0.0011529392952601728,
          8.872773295877962E-4,
          0.0011919372321990726,
          9.788741374629015E-4,
          0.001160444325853788,
          8.52562897522107E-4,
          9.585946734230757E-4,
          8.464504042810374E-4,
          7.954296638621436E-4,
          9.084635264085856E-4,
          9.476068487529528E-4,
          9.374312827235422E-4,
          7.626010689379521E-4,
          7.094244897467597E-4,
          0.0013284589362780699,
          8.653803104587067E-4,
          0.0010078479491731445,
          7.421505129621416E-4,
          9.446182475278803E-4,
          7.40488708278248E-4,
          7.791780952358975E-4,
          8.302675051617258E-4,
          7.943245856970381E-4,
          0.0013028774374515195,
          9.285644933861272E-4,
          8.798681809096022E-4,
          0.0011227044170288097,
          7.976832632184698E-4,
          0.0011433306479763784,
          9.446896599890832E-4,
          7.737009196471569E-4,
          0.0011333638201781622,
          0.0013866238717873988,
          0.0010679460927226654,
          0.0010689219726076915,
          9.788682820338211E-4,
          8.460424065111163E-4,
          0.0010862442610191517,
          0.001032331263845305,
          0.0010930679681621952,
          9.845206329240621E-4,
          0.001410551652707306,
          0.00103686020737043,
          8.658691333264133E-4,
          7.259954456069894E-4,
          0.0013777425311887741,
          0.001007647134214535,
          8.994176249043347E-4,
          0.001198757395705501,
          8.76901711185536E-4,
          0.001329840750831148,
          8.371474865230135E-4,
          9.190922315569929E-4,
          0.0010697442143527643,
          6.939767623775419E-4,
          7.240357579862218E-4,
          8.985416663174904E-4,
          0.0010355960316445908,
          7.231081976539591E-4,
          0.0010360198569931403,
          8.579678684695404E-4,
          8.085463248360693E-4,
          7.90207682758193E-4,
          0.001012360980587729,
          9.010854902156639E-4,
          0.0010665531366346717,
          0.0013263465204208127,
          0.0012389168112533523,
          9.683745490057456E-4,
          7.89934852987193E-4,
          7.398053462515072E-4,
          0.001034630624887408,
          8.03223371425947E-4,
          8.326637198274767E-4,
          0.001103362278473888,
          7.998769021438685E-4,
          0.0010484533062011128,
          0.0010725503811597028,
          9.801165299526719E-4,
          7.511643464598554E-4,
          0.001096990485636392,
          8.486450284855503E-4,
          8.340818191724149E-4,
          8.402684841794224E-4,
          9.082115307290714E-4,
          6.73580982753735E-4,
          8.952006749322199E-4,
          9.467753753709617E-4,
          0.0013522388318061745,
          8.159693009403189E-4,
          0.0010183425832754314,
          8.965079202395183E-4,
          9.840404311668525E-4,
          6.984159792838827E-4,
          7.864744222613072E-4,
          7.690926672030094E-4,
          8.712087795818539E-4,
          9.984701233876744E-4,
          7.46700517523228E-4,
          8.589179927726496E-4,
          7.950326230303709E-4,
          8.722825747263209E-4,
          9.325295650750775E-4,
          8.02971009005468E-4,
          7.802415375919552E-4,
          8.952985522585785E-4,
          9.208333404182739E-4,
          9.764682179777308E-4,
          7.92306417199061E-4,
          7.880069792867125E-4,
          7.202185089032825E-4,
          0.0010658311467942143,
          7.595927848577437E-4,
          0.001014963229608021,
          0.0011708980342477896,
          6.735748890983568E-4,
          9.05867646549033E-4,
          8.008094263142708E-4,
          7.308707168663255E-4,
          0.0011471416147195556,
          9.396780900960642E-4,
          7.081692143973863E-4,
          8.311853466131672E-4,
          8.431447061953355E-4,
          7.275215518828273E-4,
          7.475051934715737E-4,
          6.676670149154438E-4,
          8.414942320577508E-4,
          7.898286536003703E-4,
          7.200570696287296E-4,
          9.521170584040202E-4,
          7.477407033026763E-4,
          9.06113864464183E-4,
          0.0010372407376645866,
          0.0011123538548990122,
          9.241234753123913E-4,
          0.0012929010426683163,
          0.0010553996562316825,
          6.738211581904671E-4,
          8.459569679656893E-4,
          9.251128230767136E-4,
          9.885234828564873E-4,
          9.350905550010711E-4,
          0.001424019002248376,
          7.457043988672033E-4,
          8.430288775282483E-4,
          8.928415436151155E-4,
          8.271803253387844E-4,
          8.874377973176267E-4,
          8.850404995969717E-4,
          7.514314659939179E-4,
          8.282701463930393E-4,
          8.720179826473775E-4,
          7.714317196566779E-4,
          7.641070579267578E-4,
          0.0010411047108217634,
          8.755487547154026E-4,
          0.001037603576426928,
          0.0012675051330824205,
          8.172596504930093E-4,
          9.047332125927814E-4,
          9.588381174815756E-4,
          7.317892633498845E-4,
          9.644920888665561E-4,
          6.868134078104049E-4,
          8.311950736692217E-4,
          7.31348154577165E-4,
          8.475567155983299E-4,
          6.643113272403252E-4,
          7.969114111587301E-4,
          6.909506613574399E-4,
          0.0010469905921556264,
          7.992027557305887E-4,
          7.691109005892858E-4,
          8.694509479539008E-4,
          8.064592487683646E-4,
          0.001112966908121042,
          7.056051482946162E-4,
          9.211246628939499E-4,
          8.925604810571989E-4,
          8.799263120503321E-4,
          8.601931169343944E-4,
          8.234322787879892E-4,
          7.188000148580818E-4,
          7.981106984230239E-4,
          0.0010380570471333864,
          7.20933045220059E-4,
          8.969270392697765E-4,
          9.006789450211911E-4,
          8.407824372237004E-4,
          7.228723442995544E-4,
          9.713862372530897E-4,
          7.805258292035106E-4,
          0.001237657750116954,
          6.135986618216286E-4,
          6.608278011534301E-4,
          7.826389054561118E-4,
          8.500893703292993E-4,
          0.001119479705092989,
          7.666810589000122E-4,
          8.704181048650232E-4,
          7.725324682182412E-4,
          8.741148508459936E-4,
          7.102064934841702E-4,
          0.0014659888359581988,
          6.809265490456516E-4,
          8.956431180665144E-4,
          8.444644102311348E-4,
          8.274227896773288E-4,
          9.211871839714435E-4,
          7.08286860582335E-4,
          0.001016187384623898,
          7.550393488242427E-4,
          6.978037617341982E-4,
          9.895201320851514E-4,
          8.020379316987826E-4,
          7.308765803071346E-4,
          7.810199257506979E-4,
          6.799292184930463E-4,
          9.124045604591394E-4,
          6.857035018430416E-4,
          6.385506788043703E-4,
          7.597543338439271E-4,
          0.0011819843833957369,
          9.74450374363524E-4,
          0.0011037059410820517,
          6.987896896349371E-4,
          0.0012697390564508067,
          8.840203027533932E-4,
          0.0010300836765555288,
          5.861970830154134E-4,
          8.326197413235819E-4,
          9.018572904444247E-4,
          6.588272651620837E-4,
          8.260131346943443E-4,
          8.466982971379806E-4,
          8.931634316529576E-4,
          8.298419821442345E-4,
          9.88897782478356E-4,
          7.051535820905015E-4,
          9.755121211762007E-4,
          8.261125792129216E-4,
          6.35800027063514E-4,
          6.083317470195274E-4,
          8.733383874641731E-4,
          6.58181007249082E-4,
          6.302802011192766E-4,
          6.817916872207432E-4,
          8.161589697858821E-4,
          8.19615773160764E-4,
          7.207797476603241E-4,
          7.909308952865389E-4,
          6.558482626419033E-4,
          8.238594239352669E-4,
          5.869803300423003E-4,
          7.754340215214643E-4,
          7.40603959773866E-4,
          5.713507192656712E-4,
          0.0011458594330424295,
          6.998150056460872E-4,
          7.101466718687037E-4,
          0.0010140140887854746,
          8.781617755865616E-4,
          8.022259851182507E-4,
          8.731707963265813E-4,
          7.59505865123552E-4,
          8.281338704865049E-4,
          8.041218169729403E-4,
          7.876695563435931E-4,
          6.206389789644817E-4,
          9.198135809496756E-4,
          9.678591742884012E-4,
          8.904755135456603E-4,
          8.666892952921413E-4,
          7.199516658556093E-4,
          7.463254195080777E-4,
          6.94695146613116E-4,
          7.201397588432065E-4,
          7.588295756546216E-4,
          0.0010878574953341249,
          7.679473827501466E-4,
          6.314355522273841E-4,
          6.443595438816302E-4,
          7.761417097723362E-4,
          6.307546998337539E-4,
          6.712265809725844E-4,
          6.638869028106813E-4,
          6.400419360228155E-4,
          6.820130892152888E-4,
          6.356423047405217E-4,
          6.486745780135055E-4,
          8.250819337671999E-4,
          7.521122428483926E-4,
          7.888580812402907E-4,
          6.910904647136275E-4,
          6.648433233514491E-4,
          7.042326732915355E-4,
          8.765269601272858E-4,
          7.398587718914692E-4,
          7.691762422857638E-4,
          7.08486762203883E-4,
          8.451154756718159E-4,
          8.105807376860673E-4,
          5.506509180858292E-4,
          7.405524043002679E-4,
          0.0010214814398924329,
          7.935392036262293E-4,
          9.587111597059274E-4,
          6.883523176460831E-4,
          6.074337648447561E-4,
          0.0010995953889914234,
          6.033383683285812E-4,
          6.952410028512286E-4,
          8.399208969687729E-4,
          5.792467184547921E-4,
          7.189675248973595E-4,
          5.770518244675811E-4,
          4.813999098331898E-4,
          9.917007552216542E-4,
          5.627119154381576E-4,
          6.434638192157753E-4,
          0.0010690656189775367,
          7.752974710905966E-4,
          7.169115071948826E-4,
          6.343560400248892E-4,
          7.465954986400902E-4,
          6.090853840055132E-4,
          6.180542314835834E-4,
          6.875332372637173E-4,
          7.058198622943247E-4,
          7.610465381935427E-4,
          6.173352355770558E-4,
          5.793078438564612E-4,
          5.493147658076912E-4,
          5.56272084548745E-4,
          9.690240277971528E-4,
          5.39807737654525E-4,
          7.367098147737574E-4,
          6.057844424340351E-4,
          5.200789153891135E-4,
          6.917971619627218E-4,
          6.093460330059438E-4,
          5.636977514492746E-4,
          7.25544984857918E-4,
          6.847452191476386E-4,
          6.060438994854542E-4,
          5.665769101724845E-4,
          8.446190441145007E-4,
          6.8786531376778E-4,
          0.0012908708971265828,
          5.792366066722597E-4,
          6.400653616632491E-4,
          5.848962815904864E-4,
          7.747459113192378E-4,
          7.683726654157796E-4,
          7.391602515106958E-4,
          6.390545017535934E-4,
          5.798644667132914E-4,
          5.34188806709148E-4,
          7.546177814751236E-4,
          6.765763602661638E-4,
          6.1479062097032E-4,
          6.922570131117416E-4,
          9.366904489703875E-4,
          7.410043663491777E-4,
          9.214610439853408E-4,
          6.711945816380066E-4,
          7.036012365859462E-4,
          6.056242144020442E-4,
          8.262328491572375E-4,
          5.286236127166161E-4,
          5.706555273493731E-4,
          7.506104735879939E-4,
          7.343998973799367E-4,
          7.831997948036833E-4,
          5.081002683878426E-4,
          8.786013016341192E-4,
          6.952234099127268E-4,
          9.8878032317924E-4,
          6.2248406338563E-4,
          5.513098346935376E-4,
          9.091030346854914E-4,
          6.417196951649581E-4,
          5.540231393527219E-4,
          6.351066922332066E-4,
          6.901547289845858E-4,
          6.343102456381795E-4,
          7.631895555839926E-4,
          8.133337893484034E-4,
          8.562632914556693E-4,
          6.691413018211534E-4,
          8.25628048342684E-4,
          5.285771864661266E-4,
          7.109774253396526E-4,
          8.350736885056883E-4,
          5.495053754590996E-4,
          8.654348263477781E-4,
          6.605221327784042E-4,
          6.143947765021847E-4,
          6.408482336104335E-4,
          7.025175116396395E-4,
          7.614356026137143E-4,
          7.145978298477745E-4,
          6.749128005231909E-4,
          7.777607432707852E-4,
          5.363945293650973E-4,
          5.943766723810747E-4,
          7.771608180018518E-4,
          5.417875819669492E-4,
          8.21202574166982E-4,
          7.674081011981379E-4,
          6.671881359109781E-4,
          5.351245240439148E-4,
          6.35634008023281E-4,
          6.662510478348481E-4,
          6.776603881866158E-4,
          7.955093465528315E-4,
          5.699672088422028E-4,
          0.00106111958327316,
          7.240616236067785E-4,
          5.940156071538398E-4,
          9.34093899886239E-4,
          8.815115112013424E-4,
          7.297358249335057E-4,
          8.093785982463885E-4,
          6.693119503324851E-4,
          7.128459963884749E-4,
          7.002969848625153E-4,
          7.644808155306605E-4,
          8.564736699656678E-4,
          5.413966403497132E-4,
          8.911299195501619E-4,
          6.440986095655584E-4,
          8.047113704869231E-4,
          9.294293982400611E-4,
          5.614372440208315E-4,
          4.773628348589278E-4,
          7.083020488577214E-4,
          6.973079215732581E-4,
          8.447732039978413E-4,
          7.337231332569624E-4,
          7.452006697696581E-4,
          6.170431792924411E-4,
          5.57030195349388E-4,
          7.463731403067562E-4,
          7.493399141495001E-4,
          5.935451891888037E-4,
          5.660493005645263E-4,
          6.805485017333452E-4,
          6.414215623929552E-4,
          5.584407254093421E-4,
          6.51161642248083E-4,
          5.666642813430576E-4,
          8.660530834327965E-4,
          6.268504440321409E-4,
          5.97065399509457E-4,
          5.009694515761469E-4,
          5.460903998477426E-4,
          9.84242248082052E-4,
          7.231651476369857E-4,
          6.078363082625411E-4,
          5.543013034634334E-4,
          6.480989158559026E-4,
          5.767715719117773E-4,
          7.295058729529925E-4,
          6.166142351033292E-4,
          8.766247866036935E-4,
          5.494480987937514E-4,
          5.561601791761062E-4,
          6.557203311959721E-4,
          8.435820056363584E-4,
          6.311636063626056E-4,
          7.182495791812982E-4,
          5.200084342504852E-4,
          6.050463683126244E-4,
          5.622511140000221E-4,
          9.934853574684874E-4,
          6.117960966252355E-4,
          6.653380122760395E-4,
          7.08254088034194E-4,
          5.935297705353436E-4,
          5.430046863346413E-4,
          6.056371123040764E-4,
          6.887441470936527E-4,
          4.8258011348694665E-4,
          7.685454528951453E-4,
          4.4123040245037546E-4,
          6.189221490744836E-4,
          5.765655815399911E-4,
          6.698835188237782E-4,
          0.0011800387190796142,
          5.944083465048729E-4,
          5.674013038024599E-4,
          7.616711008359856E-4,
          4.0824565860858776E-4,
          8.179218731650538E-4,
          5.972267900596195E-4,
          7.381006148892319E-4,
          5.434099957608524E-4,
          7.91359554977533E-4,
          7.997788398937332E-4,
          9.327436248926195E-4,
          5.412719933855023E-4,
          5.19108083383625E-4,
          5.113259100111913E-4,
          7.729640855451293E-4,
          7.392110287020862E-4,
          0.001293369557439046,
          6.987753004068509E-4,
          5.624344767976468E-4,
          7.165772895972255E-4,
          5.307479119294564E-4,
          6.078672176750189E-4,
          9.302386433262839E-4,
          5.019595221128429E-4,
          6.945946574632309E-4,
          7.620717219294185E-4,
          5.460336648733512E-4,
          4.276734374736938E-4,
          7.018853649967925E-4,
          5.881767497617709E-4,
          6.033871424243147E-4,
          5.707299169035252E-4,
          6.755389454002817E-4,
          7.603803022994838E-4,
          4.577146526040206E-4,
          5.294401205165751E-4,
          7.825515817018917E-4,
          5.573732778429985E-4,
          6.777743458698159E-4,
          5.968487908176847E-4,
          5.644694386963115E-4,
          6.055792050012335E-4,
          4.90136857581419E-4,
          4.2871630252234305E-4,
          7.555272982500263E-4,
          9.68564302873735E-4,
          5.418310384004471E-4,
          6.297015790367143E-4,
          6.280273229820298E-4,
          5.89681846015103E-4,
          5.121617577152505E-4,
          5.786867342690487E-4,
          5.939640869972495E-4,
          7.733391521673838E-4,
          6.418335553993775E-4,
          6.992672202164265E-4,
          5.12929816466751E-4,
          6.96450816382382E-4,
          8.062947146775033E-4,
          6.61786918703655E-4,
          0.0010847855065661493,
          4.956419309084512E-4,
          6.384946125640608E-4,
          0.001006250554045631,
          7.143690729228612E-4,
          5.882003358002814E-4,
          8.030484847101812E-4,
          5.82236509176306E-4,
          7.855880104941891E-4,
          5.690622679088683E-4,
          7.053444002103583E-4,
          7.315085791417638E-4,
          8.52245895330679E-4,
          5.954979363635308E-4,
          4.280671558906638E-4,
          7.417588782486286E-4,
          7.169416661209459E-4,
          5.89671533121832E-4,
          4.981073661736119E-4,
          8.27048403070978E-4,
          6.667590949271042E-4,
          8.650731108624886E-4,
          6.61226286221913E-4,
          5.145550715629786E-4,
          7.062170275531479E-4,
          6.050486362858393E-4,
          5.386783275426251E-4,
          0.001049054330875417,
          7.640793546772656E-4,
          7.919525883613112E-4,
          6.119141402900261E-4,
          5.84247160220278E-4,
          4.2394221228288405E-4,
          5.914969409010216E-4,
          5.348060297089096E-4,
          6.140708668926584E-4,
          6.718342987103702E-4,
          9.316786398700428E-4,
          6.688646131765432E-4,
          8.187520759522894E-4,
          8.459951752454063E-4,
          7.365213099179078E-4,
          6.180270828419166E-4,
          4.2482773098751923E-4,
          8.334216072807465E-4,
          6.248344782690173E-4,
          4.345215464617764E-4,
          5.151175327626518E-4,
          5.423749324190692E-4,
          9.087010751428669E-4,
          6.955073625791107E-4,
          5.70133349039393E-4,
          5.339052099106687E-4,
          7.352977696795728E-4,
          7.232841446974807E-4,
          5.699457974157432E-4,
          6.15039333639656E-4,
          5.544867991794193E-4,
          4.6650985166890905E-4,
          4.0640036620950495E-4,
          5.232235863137718E-4,
          6.211831334460359E-4,
          5.742884934304303E-4,
          7.026112473928213E-4,
          8.303774249337069E-4,
          7.249788797115174E-4,
          4.777893444635706E-4,
          6.168964016447471E-4,
          0.0010288695074235916,
          0.0010989762576469587,
          8.285372535007473E-4,
          8.254062083191395E-4,
          7.698985682918135E-4,
          5.255571124732515E-4,
          6.661266148982444E-4,
          0.0010738440631009806,
          7.134828475510618E-4,
          8.877890604401656E-4,
          8.937082135019133E-4,
          7.366516295129831E-4,
          6.006735602977131E-4,
          8.869787269033848E-4,
          6.656978301261814E-4,
          9.972163156561783E-4,
          5.590661230701116E-4,
          4.1068149470590746E-4,
          4.593812813295648E-4,
          0.0010798508648007187,
          4.323463663138355E-4,
          4.1451623625373156E-4,
          5.809724537899006E-4,
          5.955635259330817E-4,
          5.412778542102367E-4,
          5.276486386474368E-4,
          6.255112046224139E-4,
          5.162495103065615E-4,
          7.865398416225013E-4,
          5.144152680432863E-4,
          8.008921958095384E-4,
          7.548230023939539E-4,
          4.5737010747942485E-4,
          7.640327152984447E-4,
          7.207179934197116E-4,
          5.174082169391665E-4,
          5.747308593905227E-4,
          5.218761059418948E-4,
          7.087555686155795E-4,
          5.398445141049144E-4,
          7.153490242375626E-4,
          5.136176313795516E-4,
          7.0748938897656E-4,
          5.808144536724817E-4,
          6.074025043877616E-4,
          5.546915407025706E-4,
          5.043524529508922E-4,
          6.563393953400193E-4,
          6.173606221289426E-4,
          5.004447397613752E-4,
          8.419579260569234E-4,
          7.438306607439423E-4,
          7.106809992293482E-4,
          6.061428181730273E-4,
          7.740855426265952E-4,
          6.73275970359427E-4,
          6.252104830810424E-4,
          5.376995456132912E-4,
          7.129389805107095E-4,
          5.030306083120123E-4,
          7.702452004717118E-4,
          6.130741359116614E-4,
          5.665314328213212E-4,
          4.5178672154904916E-4,
          7.916731350163124E-4,
          6.080898565823589E-4,
          8.126944980421889E-4,
          6.807766803422566E-4,
          8.043007041573566E-4,
          4.250318538907685E-4,
          5.143596189033785E-4,
          7.275610649108029E-4,
          7.659755885899276E-4,
          8.627498841888972E-4,
          5.44122172214792E-4,
          6.845315626961064E-4,
          7.71078141635085E-4,
          4.6360502475702593E-4,
          6.822938275434537E-4,
          6.200405747794514E-4,
          6.01131621397655E-4,
          6.140547575954913E-4,
          5.518784198787043E-4,
          5.32745643161771E-4,
          6.522762561687843E-4,
          7.624200978865743E-4,
          6.863838419765548E-4,
          5.2461608556973E-4,
          4.970581578797128E-4,
          6.603721479866968E-4,
          8.371696320854211E-4,
          4.112349484335589E-4,
          7.270765443413592E-4,
          6.484229145754715E-4,
          4.8747049453942985E-4,
          6.813760357974306E-4,
          4.672304349604816E-4,
          5.777697317600459E-4,
          6.060630318203815E-4,
          7.388908684180443E-4,
          8.409133225449183E-4,
          5.401082031475903E-4,
          7.325662396458406E-4,
          8.273171687700127E-4,
          6.388655387576711E-4,
          6.993801193704222E-4,
          6.954426297740069E-4,
          8.423236912257677E-4,
          4.2029460517655577E-4,
          6.587871283638093E-4,
          7.041001473645041E-4,
          4.6464513041918806E-4,
          6.833899647829363E-4,
          5.475538526073078E-4,
          0.0010010961315979176,
          8.132769837399965E-4,
          6.857102068423638E-4,
          4.948369549290445E-4,
          7.299137158839953E-4,
          5.809163770852925E-4,
          5.922107671170359E-4,
          4.8693666464173015E-4,
          9.302616989556596E-4,
          4.7323462630823526E-4,
          5.035066605660688E-4,
          6.128622229103774E-4,
          6.946359232612205E-4,
          6.107123535299109E-4,
          5.648115141646874E-4,
          4.7935897780692184E-4,
          6.449438904260359E-4,
          6.491965386987758E-4,
          0.0010999274378631976,
          5.779947166323264E-4,
          7.587463243111047E-4,
          0.0010960652781362656,
          6.852845044602546E-4,
          4.93108805692807E-4,
          7.108587361584428E-4,
          5.069136777513378E-4,
          4.968999070278892E-4,
          4.5963802166921455E-4,
          0.001414854513753331,
          8.524645440701626E-4,
          6.232489403363401E-4,
          6.865773585774109E-4,
          7.829119186793464E-4,
          6.149985295788417E-4,
          6.950314726034347E-4,
          5.919830051180122E-4,
          6.042665609333852E-4,
          6.869785846381061E-4,
          4.959077603907032E-4,
          4.4495453505405337E-4,
          7.438277882939791E-4,
          5.610177160654049E-4,
          5.871428703572705E-4,
          8.872695292707198E-4,
          8.409249727428482E-4,
          6.234250101718653E-4,
          5.885631428427178E-4,
          4.4484877557653325E-4,
          4.5014507502835413E-4,
          6.615422112446048E-4,
          4.826062887853399E-4,
          4.975902627214391E-4,
          5.939897588647776E-4,
          5.748109322033424E-4,
          5.687002644918629E-4,
          4.771100905733026E-4,
          9.769222678177143E-4,
          4.676466627377399E-4,
          7.582127113023438E-4,
          5.251902833795489E-4,
          6.267704810944564E-4,
          6.170386641111037E-4,
          6.186261014774798E-4,
          4.430745663402571E-4,
          7.628417478055495E-4,
          5.49260861753078E-4,
          6.192891787884108E-4,
          4.5631154418433755E-4,
          7.656380560986824E-4,
          6.098260724030205E-4,
          5.056940989040383E-4,
          5.024804795334859E-4,
          6.341113727879867E-4,
          5.4521579442551E-4,
          5.917615604487488E-4,
          5.162444743628645E-4,
          6.676129005938308E-4,
          4.4004598683468327E-4,
          7.98996483640264E-4,
          4.6132677208548514E-4,
          4.80441547838024E-4,
          6.146500236354768E-4,
          5.425737764924408E-4,
          6.122530522701341E-4,
          5.619764448015354E-4,
          6.278492457997263E-4,
          6.085883345640673E-4,
          0.0010530864976848779,
          9.343445531924496E-4,
          4.114266202112744E-4,
          4.905873046778509E-4,
          5.861305030981037E-4,
          6.862805550983384E-4,
          5.653304773189253E-4,
          7.736340549047199E-4,
          5.919702591118141E-4,
          6.335847187012937E-4,
          4.6721266723549244E-4,
          6.015279356146943E-4,
          6.608355651724707E-4,
          5.41435574080659E-4,
          5.822604516549873E-4,
          3.9158096110900823E-4,
          8.493744978469304E-4,
          4.5434868579934443E-4,
          6.161695799144153E-4,
          6.484661595974368E-4,
          6.33596819845091E-4,
          5.33340332684306E-4,
          6.958786439048545E-4,
          5.071727430455785E-4,
          5.259216009159154E-4,
          6.190688505290034E-4,
          5.553731103911682E-4,
          4.473330679165168E-4,
          8.404523654503413E-4,
          5.147168089065366E-4,
          4.7226543139321E-4,
          6.797080893877873E-4,
          6.212161394788391E-4,
          0.0010758985136112387,
          6.006549985940683E-4,
          6.279499766095071E-4,
          4.215109254576245E-4,
          9.951697833498604E-4,
          7.168147464418846E-4,
          7.00491473335103E-4,
          6.121167621386938E-4
         ],
         "yaxis": "y",
         "type": "scattergl"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmapgl": [
           {
            "type": "heatmapgl",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "type": "scattergl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "bgcolor": "#E5ECF6",
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "#E5ECF6",
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "white",
           "landcolor": "#E5ECF6",
           "subunitcolor": "white",
           "showland": true,
           "showlakes": true,
           "lakecolor": "white"
          },
          "title": {
           "x": 0.05
          },
          "mapbox": {
           "style": "light"
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0.0,
          1.0
         ],
         "title": {
          "text": "epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.0,
          1.0
         ],
         "title": {
          "text": "loss"
         }
        },
        "legend": {
         "tracegroupgap": 0
        },
        "title": {
         "text": "test loss"
        }
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      },
      "text/html": "<div>                            <div id=\"857e79ca-c4e2-4fb6-9565-7400cc4c6a8d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"857e79ca-c4e2-4fb6-9565-7400cc4c6a8d\")) {                    Plotly.newPlot(                        \"857e79ca-c4e2-4fb6-9565-7400cc4c6a8d\",                        [{\"hovertemplate\":\"epoch=%{x}<br>loss=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"showlegend\":false,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499],\"xaxis\":\"x\",\"y\":[0.08533420987176092,0.051239270026261885,0.046199522274180074,0.025713520721019654,0.01702035175573625,0.01430731124160916,0.01365576161521623,0.01290373401873316,0.01233755189956825,0.011170562864228916,0.011374976810360893,0.010645861802831962,0.011976023466232118,0.00827516602441208,0.008295854302437117,0.007806208099793183,0.007232360298525584,0.0071746784162948305,0.007156291946486225,0.007299011951218244,0.007518077050754277,0.006193089266203009,0.006391465714923368,0.006971171103532981,0.005525834369211552,0.006342594647842846,0.005271978769189773,0.006745926233981684,0.005531877258353019,0.006085760106615136,0.0046501071794021335,0.004591815146157162,0.004981492207846029,0.005058607722245408,0.0052044190325135934,0.004355952965116568,0.004706426539322298,0.004055707055546888,0.005070503089535102,0.004107605302941807,0.004812104613101633,0.003916825878099025,0.004562791732527064,0.0038720103114152724,0.006402425732191527,0.0037412949735717324,0.004312603918866914,0.003955311648118613,0.003495033061278335,0.0036068588555424235,0.0033711559725192824,0.003388757391027018,0.0036286563753788726,0.004581214483366923,0.004185712286088029,0.0035603385624015348,0.004104974920327744,0.0036623219232169097,0.0033301596975822546,0.0029155961087423514,0.003222712247601051,0.003196068623448523,0.0032003018769613477,0.0029922235257442246,0.003725138931728774,0.0038982763777884624,0.00279113263927735,0.0027708294644449532,0.0036620976242467008,0.0031062574001562812,0.0029786716796081055,0.0030613320688664745,0.0028690603062029134,0.002594846800451031,0.002388926938416834,0.0028890403690015414,0.003245014358531642,0.0024658113886769652,0.003185633101024445,0.003075268603547403,0.0024125570538610724,0.0032853104633258218,0.0025232035053234674,0.002866252835609772,0.002994236601071872,0.00263412521689021,0.003185962765671187,0.002180374287960925,0.003066724398450696,0.0021592802603551176,0.002274550100542563,0.0026197008758500804,0.002118311540859364,0.0025814381111517884,0.0025141099402471705,0.0028457555670050507,0.0019312663137222106,0.0021221585701915614,0.00243799770093952,0.002045695802714843,0.002088488023688891,0.002195699428197708,0.0023560502221075335,0.0023162787226865883,0.0029273470589012075,0.0019004200889305158,0.0021207786153405487,0.0019793436974365514,0.002108774890892961,0.0022882133894966223,0.0023046142285626926,0.0021210481795963694,0.0028080372532222715,0.002229922590384867,0.00262791713963922,0.001810821702931432,0.002234320748817134,0.001907976218002189,0.0020376180067757836,0.002272621384466046,0.001975784969667831,0.0019749738714197294,0.0021305981862588964,0.0021658490570209753,0.0023512041086351937,0.001769034108251668,0.001616324558710219,0.0022343805346250784,0.0023207756869882096,0.0016152035556812091,0.001928481443397952,0.0019016551070328634,0.0021399902879637193,0.0025323974851550264,0.0022244787522528865,0.0026048753492984127,0.0017567122570275632,0.0019351460047463856,0.0019024210832254396,0.0014905083350303552,0.0015459345271706245,0.001790607962861992,0.001693899103955711,0.0015539004695680244,0.001792352072360894,0.002047742285315743,0.0018506440725779224,0.001832563887556931,0.00166710730631616,0.002215934619098232,0.001567043453648561,0.0015962647801929604,0.0019719785091132343,0.0015593697836889435,0.001767316840005662,0.0020697854284008736,0.0015209924120304248,0.0017217195369146263,0.0017419259107718768,0.0017151861367197812,0.0018318308026168831,0.0032131408754568756,0.0017628105395876416,0.0016873144345839373,0.0017394865146874753,0.002345953247865683,0.0018240718414295424,0.0025847671367751246,0.0019334580989952168,0.0019870984320282895,0.0017416971275227124,0.0019319546029620458,0.0016812564670422188,0.0014574141895628712,0.0020780823702971044,0.0018572733875526263,0.00149621382706244,0.001723414163361565,0.0013540451342287066,0.0015461736596110956,0.0017263062600454504,0.0015425070164740882,0.0014454597022562298,0.0014722985568655174,0.002002681794856267,0.001670368495161823,0.0014203585337015559,0.0015384788462091655,0.001614430116154672,0.0013829309596638248,0.0014924958434604694,0.0016609349888435491,0.0016553092619085036,0.0016125261592626404,0.0017115298074570726,0.0018277686047420074,0.001995017662777806,0.0014298239911205313,0.0016972682336763886,0.0014220042882769715,0.0016489597737234546,0.0017323896957278837,0.0014608110192629478,0.001738086379763639,0.0015248020354192704,0.0015485743734347268,0.0014452862005884853,0.0019919548675501613,0.002019459731272537,0.0014843271984430972,0.0016160658292545614,0.0013566068190495285,0.0014602928484523188,0.002195404400379303,0.001844901787417972,0.001290922683305264,0.001430271362121939,0.0014297827130596917,0.001489627375162803,0.001561486409791337,0.001331801369283976,0.0013373020318274,0.0026781985855378796,0.0014713636839505954,0.0014810413252980856,0.0013750923824956997,0.0016453556590216507,0.0016026052586169224,0.00188235005329813,0.001768366348330622,0.0013657318669491646,0.001417493105936649,0.0013028629270664762,0.001613063557567912,0.0015845735916433584,0.0015427799296324676,0.0014672640984448907,0.0014452261629833557,0.001329553952529566,0.0017330546136108342,0.0012440997289671573,0.0020149770487764367,0.0013663777479839124,0.0012568542786109984,0.001358500210924095,0.0012351101002096084,0.0012459331980168695,0.0016752722966772494,0.0012537158144051942,0.0015505641339781035,0.0018189911216528814,0.0019282699916433291,0.0012241307530928864,0.0015143876459732066,0.0016140336408855373,0.001209110496408735,0.0018680015251202656,0.0018643722284109113,0.0016323223787234322,0.0014561164085596298,0.00143706021775502,0.0013420803229104768,0.0013895938797524262,0.0014017368879383743,0.0016563162979345476,0.0013105405142708692,0.001280758813091585,0.001425169904721545,0.0013235632226844265,0.0011901908722219549,0.0012010083425256393,0.0012869275174380982,0.0012972931406366524,0.0012704584544153067,0.001178746010972124,0.001256252563456492,0.0014047209056371594,0.001394555666562421,0.0012703305895157744,0.0019446523654735072,0.0016573582722915316,0.0011516438798424317,0.0013520094910061007,0.0013580291405754436,0.0015026933357925312,0.0011777506880933063,0.0015265813582639597,0.0012953813309425468,0.0012133332166239996,0.0013968091002885211,0.00122211820523129,0.0011109806949748877,0.001361160448836058,0.0012079203815926704,0.001274555870868119,0.001426795926245892,0.001179960367970922,0.0013090518958542203,0.001706615388602688,0.0011333183367773262,0.0011309115242296725,0.001138552298849145,0.0016673164258402342,0.001216794513597603,0.0015000981701213574,0.0011358040190704711,0.0023058322009766536,0.001517068459639284,0.0011271131489807844,0.0010664435134601538,0.0015276937063370068,0.0014869255943124424,0.0010082209764017064,0.001839440806148825,0.0012426731680922755,0.001745140703533661,0.0011230692328895661,0.0014492204299018708,0.0011332658470380695,0.0016291766107642206,0.0014907399688198577,0.001771361747916181,0.0011810704276326708,0.001196894971614578,0.001242363048139227,0.0010937799510266108,0.0015089421018335467,0.0012402043542484595,0.0011432930562917268,0.0011541874797392135,0.0011447510970468643,0.0012697285937872621,0.0013550757600538684,0.0012621785611505463,0.0015583347484699629,0.000995356868821709,0.0011971707304081556,0.0010424603327449536,0.0011567316875463415,0.00163132284952359,0.0011698127945942616,0.001490804756562529,0.0013156864864704606,0.0013004315983022698,0.0014224115649913176,0.001124107674891757,0.0010506123550605092,0.0010553574175809332,0.001221925001905373,0.0017680752868083924,0.0016873650840781838,0.001662392606121603,0.0013175619964937815,0.0011687923927158326,0.0011615416681226552,0.0013918727783491479,0.0010442591687269361,0.001466186650442692,0.001120812670011178,0.0010958950951227165,0.0014074635979708996,0.0010618278812329295,0.0014343960007935177,0.0013984768786153682,0.001771057241405308,0.0012251883048663606,0.001069765861879961,0.0024335148529766987,0.0011806411433538547,0.0013857041400585199,0.001212111873724864,0.0011281280335577813,0.0010288483891609972,0.0013438287132885307,0.00102586044522468,0.0010894189599843884,0.0012145458466865206,0.0010111887971648234,0.001115268635729673,0.0016418949679963375,0.0014814578161543507,0.0013927498919329491,0.00112291278573946,0.0012190982129089952,0.001480062834570561,0.0009484753961638243,0.001055115804611182,0.0011497662906937846,0.0009367569020080767,0.0009710300493700262,0.001322404740461975,0.0012632372839444348,0.000949787856779438,0.0010862313199518877,0.0011418669708884123,0.001178414446401169,0.0011077315247031662,0.0013981337088102663,0.001134185634849049,0.0013499940085627683,0.0010273608109610303,0.0013918938138783815,0.000905544729085817,0.0011723157750269963,0.0013877756941378157,0.0010060565943471314,0.0009674178403697573,0.001693897854126048,0.0010523817031395757,0.0012075383787754964,0.000943178809843068,0.0012078165708455059,0.0014688173868808519,0.0013731620594953301,0.0010301287592064297,0.0010242872016983148,0.0013556052430982837,0.0009972373387590575,0.0012767266444835728,0.0012253427327338481,0.001092854902289515,0.001060607612232437,0.0011574671397069365,0.00112665415312467,0.001203263305347371,0.0012114098000607003,0.0013088193490546657,0.0010216487411362526,0.0009997884817800767,0.0010742937382101343,0.0009132880131188215,0.0013522758558026273,0.0010159534277601084,0.001077751516890346,0.0010982623562187982,0.0009500473668063687,0.0010923220731221203,0.0009716593956684673,0.0010527019072428681,0.0012225682652304262,0.0010440526623344258,0.0010458431702062717,0.0009786817369448922,0.000973945231604641,0.0012450203007830078,0.0010708400288340374,0.001327018873187912,0.0010798907149753146,0.0010696468414382989,0.0011185815115066853,0.001479610148686497,0.0008572915960050951,0.001079606756749772,0.001156615940631587,0.0012520540697275127,0.001236191724447973,0.0010155140957925886,0.0009399860233377163,0.001292308045909583,0.0009573479959665369,0.0008878100766758487,0.0009710315488713134,0.0012974548457697912,0.0011258765161063606,0.0009653977639358386,0.0013134923235126092,0.0010750050870034571,0.0009584931875487497,0.0010871151609351502,0.0011162722968559168,0.0013091111502720023,0.0009249912271095608,0.0010608543700399923,0.0014723312604146895,0.0012796089917112643,0.0009276675138219647,0.001011460227335887,0.0010846830146476166,0.0010635039163818792,0.0011358772838760292,0.0011991086204044437,0.001101494892506881,0.0010709375807861118,0.0009647977695044318,0.0011477308129379002,0.0013939405208076821,0.0009252358246934757,0.0010540379635437674,0.0010079508359554443,0.0012065158958096853,0.0010096689874536536,0.001042434311140946,0.0011256753298286557,0.0010659695515314934,0.0009766288891073652,0.0010377322480584798,0.0009663626656271099,0.0012417774892077267,0.0009219094068060493,0.0008518557993595729,0.0012108909444925322,0.001250659145370356,0.0013676533551384392,0.0012520292919034955,0.0009476187590868056,0.000944847396209972,0.0012540002448322104,0.0013937400192875163,0.0011142580397165475,0.0012580813281499687,0.0009461973052801502,0.0010018302776832447,0.0009193684081049908,0.0012558696626716952,0.0013105950813369009,0.0008188491973965795,0.0010668199643129065,0.001001475058238315,0.001025727785223823,0.00134384776158206,0.0015946450016037508,0.0012495929769010105,0.0013768002485694216,0.0009568619186691731,0.0009937508730217814,0.0010695790957327242,0.0009611734078563959,0.001239156034275408,0.0014994198906371433,0.0012940606321443626,0.0009231966223013117,0.001692614585469906,0.0014667091318903219,0.0013454429265059363,0.0009421612534363325,0.0010934823084415952,0.0008600713489603335,0.000901264362848165,0.0011303961748555511,0.0010273707672506258,0.0009624380651034749,0.0009079198428204681,0.000820894482489309,0.0012671843951363954,0.0010899570639757964,0.0010917100001105599,0.0009322530283263016,0.0009143161229341908,0.0008136259190466129,0.0010876436838801698,0.001324228077127567,0.0009744713932152817,0.0009115878811427863,0.0013068666883739068,0.0010214286625484694,0.0010762582585382998,0.0010332827514503151,0.0008128585980281632,0.0007969019874038301,0.0009826319208800312,0.0009684182958235295,0.0011710563525452874,0.0009437536364918302,0.0011493951468754644,0.0014578771867051596,0.0012363429839220526,0.0010512768708854873,0.0008848397876463014,0.000827807283161072,0.0010133482417055103,0.0008898405917381261,0.0012967231712209878,0.0009721059936198165,0.0009665001047058345,0.0009575615198157854,0.001057624389329831,0.0009364530022630175,0.0009013335104427415,0.0009552296193831945,0.0010690826273868593,0.0009084250992150935,0.0013025429840801347,0.0013050409615971148,0.0008859595244951818,0.0008253130976442938,0.0008241490472704591,0.0010795061129244734,0.001124624317260773,0.0012248697918918236,0.0009791405411735386,0.0013675454914376264,0.000986813858126583,0.0009304740781087449,0.0008512720571284109,0.0007909014134332956,0.0008505702499768519,0.0013090155360137186,0.0011074780300128787,0.0008110904535069392,0.0009682403427412671,0.0010587979824899622,0.0009183072160636441,0.0007698890629480855,0.0009671004263100769,0.0009669759557674,0.0011563202493112493,0.0011686466515242132,0.0010225033700489701,0.0010425867668151583,0.000739848039281722,0.0008827123694184623,0.0008175239024822486,0.0008105351421210308,0.0008876220837531067,0.0007103635879492471,0.00106722150397555,0.0008596550480964898,0.0008552263651417276,0.0011418479399263775,0.0009044490969122461,0.000917902834362905,0.001219890604261309,0.001152461047383716,0.0009723583828550607,0.0009078509295280772,0.0008597995867112944,0.0009894996297446321,0.0010909632677630929,0.0009652108442577209,0.0012032653220139151,0.0007692624548622773,0.0017365153173895113,0.0007960609115563395,0.0010746701941315314,0.0013403179257417495,0.0007768853119864872,0.0010579267042241677,0.0009887500069616886,0.000918491525553282,0.0011529392952601728,0.0008872773295877962,0.0011919372321990726,0.0009788741374629015,0.001160444325853788,0.000852562897522107,0.0009585946734230757,0.0008464504042810374,0.0007954296638621436,0.0009084635264085856,0.0009476068487529528,0.0009374312827235422,0.0007626010689379521,0.0007094244897467597,0.0013284589362780699,0.0008653803104587067,0.0010078479491731445,0.0007421505129621416,0.0009446182475278803,0.000740488708278248,0.0007791780952358975,0.0008302675051617258,0.0007943245856970381,0.0013028774374515195,0.0009285644933861272,0.0008798681809096022,0.0011227044170288097,0.0007976832632184698,0.0011433306479763784,0.0009446896599890832,0.0007737009196471569,0.0011333638201781622,0.0013866238717873988,0.0010679460927226654,0.0010689219726076915,0.0009788682820338211,0.0008460424065111163,0.0010862442610191517,0.001032331263845305,0.0010930679681621952,0.0009845206329240621,0.001410551652707306,0.00103686020737043,0.0008658691333264133,0.0007259954456069894,0.0013777425311887741,0.001007647134214535,0.0008994176249043347,0.001198757395705501,0.000876901711185536,0.001329840750831148,0.0008371474865230135,0.0009190922315569929,0.0010697442143527643,0.0006939767623775419,0.0007240357579862218,0.0008985416663174904,0.0010355960316445908,0.0007231081976539591,0.0010360198569931403,0.0008579678684695404,0.0008085463248360693,0.000790207682758193,0.001012360980587729,0.0009010854902156639,0.0010665531366346717,0.0013263465204208127,0.0012389168112533523,0.0009683745490057456,0.000789934852987193,0.0007398053462515072,0.001034630624887408,0.000803223371425947,0.0008326637198274767,0.001103362278473888,0.0007998769021438685,0.0010484533062011128,0.0010725503811597028,0.0009801165299526719,0.0007511643464598554,0.001096990485636392,0.0008486450284855503,0.0008340818191724149,0.0008402684841794224,0.0009082115307290714,0.000673580982753735,0.0008952006749322199,0.0009467753753709617,0.0013522388318061745,0.0008159693009403189,0.0010183425832754314,0.0008965079202395183,0.0009840404311668525,0.0006984159792838827,0.0007864744222613072,0.0007690926672030094,0.0008712087795818539,0.0009984701233876744,0.000746700517523228,0.0008589179927726496,0.0007950326230303709,0.0008722825747263209,0.0009325295650750775,0.000802971009005468,0.0007802415375919552,0.0008952985522585785,0.0009208333404182739,0.0009764682179777308,0.000792306417199061,0.0007880069792867125,0.0007202185089032825,0.0010658311467942143,0.0007595927848577437,0.001014963229608021,0.0011708980342477896,0.0006735748890983568,0.000905867646549033,0.0008008094263142708,0.0007308707168663255,0.0011471416147195556,0.0009396780900960642,0.0007081692143973863,0.0008311853466131672,0.0008431447061953355,0.0007275215518828273,0.0007475051934715737,0.0006676670149154438,0.0008414942320577508,0.0007898286536003703,0.0007200570696287296,0.0009521170584040202,0.0007477407033026763,0.000906113864464183,0.0010372407376645866,0.0011123538548990122,0.0009241234753123913,0.0012929010426683163,0.0010553996562316825,0.0006738211581904671,0.0008459569679656893,0.0009251128230767136,0.0009885234828564873,0.0009350905550010711,0.001424019002248376,0.0007457043988672033,0.0008430288775282483,0.0008928415436151155,0.0008271803253387844,0.0008874377973176267,0.0008850404995969717,0.0007514314659939179,0.0008282701463930393,0.0008720179826473775,0.0007714317196566779,0.0007641070579267578,0.0010411047108217634,0.0008755487547154026,0.001037603576426928,0.0012675051330824205,0.0008172596504930093,0.0009047332125927814,0.0009588381174815756,0.0007317892633498845,0.0009644920888665561,0.0006868134078104049,0.0008311950736692217,0.000731348154577165,0.0008475567155983299,0.0006643113272403252,0.0007969114111587301,0.0006909506613574399,0.0010469905921556264,0.0007992027557305887,0.0007691109005892858,0.0008694509479539008,0.0008064592487683646,0.001112966908121042,0.0007056051482946162,0.0009211246628939499,0.0008925604810571989,0.0008799263120503321,0.0008601931169343944,0.0008234322787879892,0.0007188000148580818,0.0007981106984230239,0.0010380570471333864,0.000720933045220059,0.0008969270392697765,0.0009006789450211911,0.0008407824372237004,0.0007228723442995544,0.0009713862372530897,0.0007805258292035106,0.001237657750116954,0.0006135986618216286,0.0006608278011534301,0.0007826389054561118,0.0008500893703292993,0.001119479705092989,0.0007666810589000122,0.0008704181048650232,0.0007725324682182412,0.0008741148508459936,0.0007102064934841702,0.0014659888359581988,0.0006809265490456516,0.0008956431180665144,0.0008444644102311348,0.0008274227896773288,0.0009211871839714435,0.000708286860582335,0.001016187384623898,0.0007550393488242427,0.0006978037617341982,0.0009895201320851514,0.0008020379316987826,0.0007308765803071346,0.0007810199257506979,0.0006799292184930463,0.0009124045604591394,0.0006857035018430416,0.0006385506788043703,0.0007597543338439271,0.0011819843833957369,0.000974450374363524,0.0011037059410820517,0.0006987896896349371,0.0012697390564508067,0.0008840203027533932,0.0010300836765555288,0.0005861970830154134,0.0008326197413235819,0.0009018572904444247,0.0006588272651620837,0.0008260131346943443,0.0008466982971379806,0.0008931634316529576,0.0008298419821442345,0.000988897782478356,0.0007051535820905015,0.0009755121211762007,0.0008261125792129216,0.000635800027063514,0.0006083317470195274,0.0008733383874641731,0.000658181007249082,0.0006302802011192766,0.0006817916872207432,0.0008161589697858821,0.000819615773160764,0.0007207797476603241,0.0007909308952865389,0.0006558482626419033,0.0008238594239352669,0.0005869803300423003,0.0007754340215214643,0.000740603959773866,0.0005713507192656712,0.0011458594330424295,0.0006998150056460872,0.0007101466718687037,0.0010140140887854746,0.0008781617755865616,0.0008022259851182507,0.0008731707963265813,0.000759505865123552,0.0008281338704865049,0.0008041218169729403,0.0007876695563435931,0.0006206389789644817,0.0009198135809496756,0.0009678591742884012,0.0008904755135456603,0.0008666892952921413,0.0007199516658556093,0.0007463254195080777,0.000694695146613116,0.0007201397588432065,0.0007588295756546216,0.0010878574953341249,0.0007679473827501466,0.0006314355522273841,0.0006443595438816302,0.0007761417097723362,0.0006307546998337539,0.0006712265809725844,0.0006638869028106813,0.0006400419360228155,0.0006820130892152888,0.0006356423047405217,0.0006486745780135055,0.0008250819337671999,0.0007521122428483926,0.0007888580812402907,0.0006910904647136275,0.0006648433233514491,0.0007042326732915355,0.0008765269601272858,0.0007398587718914692,0.0007691762422857638,0.000708486762203883,0.0008451154756718159,0.0008105807376860673,0.0005506509180858292,0.0007405524043002679,0.0010214814398924329,0.0007935392036262293,0.0009587111597059274,0.0006883523176460831,0.0006074337648447561,0.0010995953889914234,0.0006033383683285812,0.0006952410028512286,0.0008399208969687729,0.0005792467184547921,0.0007189675248973595,0.0005770518244675811,0.0004813999098331898,0.0009917007552216542,0.0005627119154381576,0.0006434638192157753,0.0010690656189775367,0.0007752974710905966,0.0007169115071948826,0.0006343560400248892,0.0007465954986400902,0.0006090853840055132,0.0006180542314835834,0.0006875332372637173,0.0007058198622943247,0.0007610465381935427,0.0006173352355770558,0.0005793078438564612,0.0005493147658076912,0.000556272084548745,0.0009690240277971528,0.000539807737654525,0.0007367098147737574,0.0006057844424340351,0.0005200789153891135,0.0006917971619627218,0.0006093460330059438,0.0005636977514492746,0.000725544984857918,0.0006847452191476386,0.0006060438994854542,0.0005665769101724845,0.0008446190441145007,0.00068786531376778,0.0012908708971265828,0.0005792366066722597,0.0006400653616632491,0.0005848962815904864,0.0007747459113192378,0.0007683726654157796,0.0007391602515106958,0.0006390545017535934,0.0005798644667132914,0.000534188806709148,0.0007546177814751236,0.0006765763602661638,0.00061479062097032,0.0006922570131117416,0.0009366904489703875,0.0007410043663491777,0.0009214610439853408,0.0006711945816380066,0.0007036012365859462,0.0006056242144020442,0.0008262328491572375,0.0005286236127166161,0.0005706555273493731,0.0007506104735879939,0.0007343998973799367,0.0007831997948036833,0.0005081002683878426,0.0008786013016341192,0.0006952234099127268,0.00098878032317924,0.00062248406338563,0.0005513098346935376,0.0009091030346854914,0.0006417196951649581,0.0005540231393527219,0.0006351066922332066,0.0006901547289845858,0.0006343102456381795,0.0007631895555839926,0.0008133337893484034,0.0008562632914556693,0.0006691413018211534,0.000825628048342684,0.0005285771864661266,0.0007109774253396526,0.0008350736885056883,0.0005495053754590996,0.0008654348263477781,0.0006605221327784042,0.0006143947765021847,0.0006408482336104335,0.0007025175116396395,0.0007614356026137143,0.0007145978298477745,0.0006749128005231909,0.0007777607432707852,0.0005363945293650973,0.0005943766723810747,0.0007771608180018518,0.0005417875819669492,0.000821202574166982,0.0007674081011981379,0.0006671881359109781,0.0005351245240439148,0.000635634008023281,0.0006662510478348481,0.0006776603881866158,0.0007955093465528315,0.0005699672088422028,0.00106111958327316,0.0007240616236067785,0.0005940156071538398,0.000934093899886239,0.0008815115112013424,0.0007297358249335057,0.0008093785982463885,0.0006693119503324851,0.0007128459963884749,0.0007002969848625153,0.0007644808155306605,0.0008564736699656678,0.0005413966403497132,0.0008911299195501619,0.0006440986095655584,0.0008047113704869231,0.0009294293982400611,0.0005614372440208315,0.0004773628348589278,0.0007083020488577214,0.0006973079215732581,0.0008447732039978413,0.0007337231332569624,0.0007452006697696581,0.0006170431792924411,0.000557030195349388,0.0007463731403067562,0.0007493399141495001,0.0005935451891888037,0.0005660493005645263,0.0006805485017333452,0.0006414215623929552,0.0005584407254093421,0.000651161642248083,0.0005666642813430576,0.0008660530834327965,0.0006268504440321409,0.000597065399509457,0.0005009694515761469,0.0005460903998477426,0.000984242248082052,0.0007231651476369857,0.0006078363082625411,0.0005543013034634334,0.0006480989158559026,0.0005767715719117773,0.0007295058729529925,0.0006166142351033292,0.0008766247866036935,0.0005494480987937514,0.0005561601791761062,0.0006557203311959721,0.0008435820056363584,0.0006311636063626056,0.0007182495791812982,0.0005200084342504852,0.0006050463683126244,0.0005622511140000221,0.0009934853574684874,0.0006117960966252355,0.0006653380122760395,0.000708254088034194,0.0005935297705353436,0.0005430046863346413,0.0006056371123040764,0.0006887441470936527,0.00048258011348694665,0.0007685454528951453,0.00044123040245037546,0.0006189221490744836,0.0005765655815399911,0.0006698835188237782,0.0011800387190796142,0.0005944083465048729,0.0005674013038024599,0.0007616711008359856,0.00040824565860858776,0.0008179218731650538,0.0005972267900596195,0.0007381006148892319,0.0005434099957608524,0.000791359554977533,0.0007997788398937332,0.0009327436248926195,0.0005412719933855023,0.000519108083383625,0.0005113259100111913,0.0007729640855451293,0.0007392110287020862,0.001293369557439046,0.0006987753004068509,0.0005624344767976468,0.0007165772895972255,0.0005307479119294564,0.0006078672176750189,0.0009302386433262839,0.0005019595221128429,0.0006945946574632309,0.0007620717219294185,0.0005460336648733512,0.0004276734374736938,0.0007018853649967925,0.0005881767497617709,0.0006033871424243147,0.0005707299169035252,0.0006755389454002817,0.0007603803022994838,0.0004577146526040206,0.0005294401205165751,0.0007825515817018917,0.0005573732778429985,0.0006777743458698159,0.0005968487908176847,0.0005644694386963115,0.0006055792050012335,0.000490136857581419,0.00042871630252234305,0.0007555272982500263,0.000968564302873735,0.0005418310384004471,0.0006297015790367143,0.0006280273229820298,0.000589681846015103,0.0005121617577152505,0.0005786867342690487,0.0005939640869972495,0.0007733391521673838,0.0006418335553993775,0.0006992672202164265,0.000512929816466751,0.000696450816382382,0.0008062947146775033,0.000661786918703655,0.0010847855065661493,0.0004956419309084512,0.0006384946125640608,0.001006250554045631,0.0007143690729228612,0.0005882003358002814,0.0008030484847101812,0.000582236509176306,0.0007855880104941891,0.0005690622679088683,0.0007053444002103583,0.0007315085791417638,0.000852245895330679,0.0005954979363635308,0.0004280671558906638,0.0007417588782486286,0.0007169416661209459,0.000589671533121832,0.0004981073661736119,0.000827048403070978,0.0006667590949271042,0.0008650731108624886,0.000661226286221913,0.0005145550715629786,0.0007062170275531479,0.0006050486362858393,0.0005386783275426251,0.001049054330875417,0.0007640793546772656,0.0007919525883613112,0.0006119141402900261,0.000584247160220278,0.00042394221228288405,0.0005914969409010216,0.0005348060297089096,0.0006140708668926584,0.0006718342987103702,0.0009316786398700428,0.0006688646131765432,0.0008187520759522894,0.0008459951752454063,0.0007365213099179078,0.0006180270828419166,0.00042482773098751923,0.0008334216072807465,0.0006248344782690173,0.0004345215464617764,0.0005151175327626518,0.0005423749324190692,0.0009087010751428669,0.0006955073625791107,0.000570133349039393,0.0005339052099106687,0.0007352977696795728,0.0007232841446974807,0.0005699457974157432,0.000615039333639656,0.0005544867991794193,0.00046650985166890905,0.00040640036620950495,0.0005232235863137718,0.0006211831334460359,0.0005742884934304303,0.0007026112473928213,0.0008303774249337069,0.0007249788797115174,0.0004777893444635706,0.0006168964016447471,0.0010288695074235916,0.0010989762576469587,0.0008285372535007473,0.0008254062083191395,0.0007698985682918135,0.0005255571124732515,0.0006661266148982444,0.0010738440631009806,0.0007134828475510618,0.0008877890604401656,0.0008937082135019133,0.0007366516295129831,0.0006006735602977131,0.0008869787269033848,0.0006656978301261814,0.0009972163156561783,0.0005590661230701116,0.00041068149470590746,0.0004593812813295648,0.0010798508648007187,0.0004323463663138355,0.00041451623625373156,0.0005809724537899006,0.0005955635259330817,0.0005412778542102367,0.0005276486386474368,0.0006255112046224139,0.0005162495103065615,0.0007865398416225013,0.0005144152680432863,0.0008008921958095384,0.0007548230023939539,0.00045737010747942485,0.0007640327152984447,0.0007207179934197116,0.0005174082169391665,0.0005747308593905227,0.0005218761059418948,0.0007087555686155795,0.0005398445141049144,0.0007153490242375626,0.0005136176313795516,0.00070748938897656,0.0005808144536724817,0.0006074025043877616,0.0005546915407025706,0.0005043524529508922,0.0006563393953400193,0.0006173606221289426,0.0005004447397613752,0.0008419579260569234,0.0007438306607439423,0.0007106809992293482,0.0006061428181730273,0.0007740855426265952,0.000673275970359427,0.0006252104830810424,0.0005376995456132912,0.0007129389805107095,0.0005030306083120123,0.0007702452004717118,0.0006130741359116614,0.0005665314328213212,0.00045178672154904916,0.0007916731350163124,0.0006080898565823589,0.0008126944980421889,0.0006807766803422566,0.0008043007041573566,0.0004250318538907685,0.0005143596189033785,0.0007275610649108029,0.0007659755885899276,0.0008627498841888972,0.000544122172214792,0.0006845315626961064,0.000771078141635085,0.00046360502475702593,0.0006822938275434537,0.0006200405747794514,0.000601131621397655,0.0006140547575954913,0.0005518784198787043,0.000532745643161771,0.0006522762561687843,0.0007624200978865743,0.0006863838419765548,0.00052461608556973,0.0004970581578797128,0.0006603721479866968,0.0008371696320854211,0.0004112349484335589,0.0007270765443413592,0.0006484229145754715,0.00048747049453942985,0.0006813760357974306,0.0004672304349604816,0.0005777697317600459,0.0006060630318203815,0.0007388908684180443,0.0008409133225449183,0.0005401082031475903,0.0007325662396458406,0.0008273171687700127,0.0006388655387576711,0.0006993801193704222,0.0006954426297740069,0.0008423236912257677,0.00042029460517655577,0.0006587871283638093,0.0007041001473645041,0.00046464513041918806,0.0006833899647829363,0.0005475538526073078,0.0010010961315979176,0.0008132769837399965,0.0006857102068423638,0.0004948369549290445,0.0007299137158839953,0.0005809163770852925,0.0005922107671170359,0.00048693666464173015,0.0009302616989556596,0.00047323462630823526,0.0005035066605660688,0.0006128622229103774,0.0006946359232612205,0.0006107123535299109,0.0005648115141646874,0.00047935897780692184,0.0006449438904260359,0.0006491965386987758,0.0010999274378631976,0.0005779947166323264,0.0007587463243111047,0.0010960652781362656,0.0006852845044602546,0.000493108805692807,0.0007108587361584428,0.0005069136777513378,0.0004968999070278892,0.00045963802166921455,0.001414854513753331,0.0008524645440701626,0.0006232489403363401,0.0006865773585774109,0.0007829119186793464,0.0006149985295788417,0.0006950314726034347,0.0005919830051180122,0.0006042665609333852,0.0006869785846381061,0.0004959077603907032,0.00044495453505405337,0.0007438277882939791,0.0005610177160654049,0.0005871428703572705,0.0008872695292707198,0.0008409249727428482,0.0006234250101718653,0.0005885631428427178,0.00044484877557653325,0.00045014507502835413,0.0006615422112446048,0.0004826062887853399,0.0004975902627214391,0.0005939897588647776,0.0005748109322033424,0.0005687002644918629,0.0004771100905733026,0.0009769222678177143,0.0004676466627377399,0.0007582127113023438,0.0005251902833795489,0.0006267704810944564,0.0006170386641111037,0.0006186261014774798,0.0004430745663402571,0.0007628417478055495,0.000549260861753078,0.0006192891787884108,0.00045631154418433755,0.0007656380560986824,0.0006098260724030205,0.0005056940989040383,0.0005024804795334859,0.0006341113727879867,0.00054521579442551,0.0005917615604487488,0.0005162444743628645,0.0006676129005938308,0.00044004598683468327,0.000798996483640264,0.00046132677208548514,0.000480441547838024,0.0006146500236354768,0.0005425737764924408,0.0006122530522701341,0.0005619764448015354,0.0006278492457997263,0.0006085883345640673,0.0010530864976848779,0.0009343445531924496,0.0004114266202112744,0.0004905873046778509,0.0005861305030981037,0.0006862805550983384,0.0005653304773189253,0.0007736340549047199,0.0005919702591118141,0.0006335847187012937,0.00046721266723549244,0.0006015279356146943,0.0006608355651724707,0.000541435574080659,0.0005822604516549873,0.00039158096110900823,0.0008493744978469304,0.00045434868579934443,0.0006161695799144153,0.0006484661595974368,0.000633596819845091,0.000533340332684306,0.0006958786439048545,0.0005071727430455785,0.0005259216009159154,0.0006190688505290034,0.0005553731103911682,0.0004473330679165168,0.0008404523654503413,0.0005147168089065366,0.00047226543139321,0.0006797080893877873,0.0006212161394788391,0.0010758985136112387,0.0006006549985940683,0.0006279499766095071,0.0004215109254576245,0.0009951697833498604,0.0007168147464418846,0.000700491473335103,0.0006121167621386938],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"epoch\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"loss\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"test loss\"}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('857e79ca-c4e2-4fb6-9565-7400cc4c6a8d');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(validation_loss_list, \"test loss\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0283,  0.0467,  0.0514, -0.0150, -0.1277],\n",
      "        [ 0.3988,  0.2750,  0.1265, -0.0010, -0.0572],\n",
      "        [ 0.0397,  0.1307,  0.2489,  0.3416,  0.4503],\n",
      "        ...,\n",
      "        [-0.5458, -0.4631, -0.3697, -0.3541, -0.4000],\n",
      "        [-0.5653, -0.8314, -0.8675, -0.8829, -0.8901],\n",
      "        [-0.3139, -0.5173, -0.6135, -0.6564, -0.6743]], device='cuda:0',\n",
      "       grad_fn=<LeakyReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for _, (X, y) in enumerate(train_loader):\n",
    "    print(model(X))\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# create dataloader without shuffle\n",
    "full_inference_dataset_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# plot_predictions(outputs, full_dataset_loader, linear_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "#plot_actual_predictions(outputs, full_inference_dataset_loader, linear_model, attributes_transform_dict, df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "LinearModel(\n  (linears): ModuleList(\n    (0): Linear(in_features=4, out_features=40, bias=True)\n    (1): Linear(in_features=40, out_features=120, bias=True)\n    (2): Linear(in_features=120, out_features=1200, bias=True)\n    (3): Linear(in_features=1200, out_features=120, bias=True)\n    (4): Linear(in_features=120, out_features=50, bias=True)\n    (5): Linear(in_features=50, out_features=5, bias=True)\n  )\n  (activations): ModuleList(\n    (0-5): 6 x LeakyReLU(negative_slope=0.01)\n  )\n)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"saved_models/\" + \"linear_model0_0006122.pth\")\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "plot_relative_errors(outputs, full_inference_dataset_loader, model, attributes_transform_dict,\n",
    "                     df, 0.01, device, plots_dir, mode='default+hist', bin_count=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### check predictions manually"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "predictor = Predictor(full_inference_dataset_loader, df, attributes_transform_dict, model, inputs, outputs)\n",
    "predictions_dict, actuals_dict = predictor.predict(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def compare_prediction(idx: int, prediction_dict, actuals_dict, attribute):\n",
    "    predicted = prediction_dict[attribute][idx]\n",
    "    actual = actuals_dict[attribute][idx]\n",
    "    relative_error = abs(actual - predicted) / actual\n",
    "    print(f\"{idx}: predicted={predicted}; actual={actual}; relative error={relative_error}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119896: predicted=0.8281782269477844; actual=0.839794; relative error=0.01383167039602995\n"
     ]
    }
   ],
   "source": [
    "compare_prediction(119896, predictions_dict, actuals_dict, 'A10M01N')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-0.7639, -0.9476, -0.9801, -0.9923, -0.9970], device='cuda:0',\n       grad_fn=<LeakyReluBackward0>)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([-1.0, -1, -1, -1]).to(device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-0.7213, -0.9231, -0.9744, -0.9911, -0.9968], device='cuda:0',\n       grad_fn=<LeakyReluBackward0>)"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([-1.0,-1.0,-0.952277, -0.575]).to(device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "LinearModel(\n  (linears): ModuleList(\n    (0): Linear(in_features=4, out_features=40, bias=True)\n    (1): Linear(in_features=40, out_features=120, bias=True)\n    (2): Linear(in_features=120, out_features=1200, bias=True)\n    (3): Linear(in_features=1200, out_features=120, bias=True)\n    (4): Linear(in_features=120, out_features=50, bias=True)\n    (5): Linear(in_features=50, out_features=5, bias=True)\n  )\n  (activations): ModuleList(\n    (0-5): 6 x LeakyReLU(negative_slope=0.01)\n  )\n)"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(cpu)    # attach model to cpu before scripting and saving to prevent cuda meta information saved\n",
    "scripted_model = torch.jit.script(model)\n",
    "model_file_name = \"saved_models/\" + model_name + str(round(test_loss, 7)).replace('.', '_')\n",
    "\n",
    "scripted_model.save(model_file_name + \".pt\") # save torch script model which compatible with pytorch c++ api\n",
    "torch.save(model, model_file_name + \".pth\")   # save model in python services specific format\n",
    "\n",
    "# attach model back to device:\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "#scripted_model(torch.tensor([0.6, 0.362372, 0.04]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "#model(torch.tensor([0.6, 0.362372, 0.04], device=device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}