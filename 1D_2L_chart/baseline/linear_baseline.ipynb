{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# uncomment if libraries are not installed:\n",
    "# %pip install numpy\n",
    "# %pip install pandas\n",
    "# %pip install plotly\n",
    "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# %pip install -U scikit-learn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tools.torch_lib import *\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "from torchmetrics.regression import MeanAbsolutePercentageError\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "gpu = torch.device('cuda')\n",
    "cpu = torch.device('cpu')\n",
    "device = cpu\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = gpu\n",
    "    # The flag below controls whether to allow TF32 on matmul. This flag defaults to False\n",
    "    # in PyTorch 1.12 and later.\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    # The flag below controls whether to allow TF32 on cuDNN. This flag defaults to True.\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "dataset_dir = \"dataset/\"\n",
    "dataset_file_name = \"1D_2L_chart.csv\"\n",
    "plots_dir = \"plots/\"\n",
    "models_dir = \"saved_models/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# create directories manually if doesn't exists:\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.mkdir(dataset_dir)\n",
    "    print(f\"no dir 'dataset' - new one is created. Put {dataset_file_name} dataset inside it\")\n",
    "\n",
    "if not os.path.exists(plots_dir):\n",
    "    os.mkdir(plots_dir)\n",
    "    print(\"no dir 'plots' - new one is created. Graphics will be put here\")\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.mkdir(models_dir)\n",
    "    print(\"no dir 'saved_models' - new one is created. Trained models will be put here\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_dir + dataset_file_name)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['AO/d', 'ro_formation', 'lambda', 'rok'], dtype='object')"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# print attribute's min max"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"AO/d: min={df['AO/d'].min()} max={df['AO/d'].max()}\")\n",
    "print(f\"ro_formation: min={df['ro_formation'].min()} max={df['ro_formation'].max()}\")\n",
    "print(f\"lambda: min={df['lambda'].min()} max={df['lambda'].max()}\")\n",
    "print(f\"rok: min={df['rok'].min()} max={df['rok'].max()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# resistance min max in logarithmic scale:\n",
    "print(f\"AO/d: min={np.log(df['AO/d'].min())} max={np.log(df['AO/d'].max())}\")\n",
    "print(f\"ro_formation: min={np.log(df['ro_formation'].min())} max={np.log(df['ro_formation'].max())}\")\n",
    "print(f\"rok: min={np.log(df['rok'].min())} max={np.log(df['rok'].max())}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add dataframe transforms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "inputs = np.array(['AO/d', 'lambda', 'ro_formation'])\n",
    "outputs = np.array(['rok'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logarithmic_columns = ['ro_formation', 'rok', 'AO/d']\n",
    "# normalize data ('min/max' normalization):\n",
    "interval_th = [-1, 1]     # normalization interval for 'th' activation function\n",
    "interval_sigmoid = [0, 1] # normalization interval for 'sigmoid' activation function\n",
    "normalize_interval = interval_sigmoid\n",
    "\n",
    "df_transformed = df.copy()\n",
    "rok_attr_transformer = AttributeTransformer(df_transformed[outputs].to_numpy())\n",
    "\n",
    "# transform 'rok':\n",
    "forward, backward = np.log, np.exp\n",
    "df_transformed['rok'] = rok_attr_transformer.transform(forward, backward)\n",
    "forward, backward = get_normalize_transforms(rok_attr_transformer.data, normalize_interval)\n",
    "df_transformed['rok'] = rok_attr_transformer.transform(forward, backward)\n",
    "\n",
    "# logarithm resistance:\n",
    "for col in logarithmic_columns:\n",
    "    if col == 'rok':\n",
    "        continue\n",
    "    df_transformed[col] = df_transformed[col].apply(np.log)\n",
    "\n",
    "# add normalization\n",
    "for attribute in df_transformed.columns:\n",
    "    if attribute == 'rok':\n",
    "        continue\n",
    "    transform, _ = get_normalize_transforms(df_transformed[attribute].to_numpy(), normalize_interval)\n",
    "    df_transformed[attribute] = transform(df_transformed[attribute].to_numpy())\n",
    "\n",
    "df_transformed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build Datasets and create dataloaders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, df_, inputs, outputs, device):\n",
    "        self.df = df_\n",
    "        self.inputs = torch.from_numpy(df_[inputs].to_numpy()).float().to(device)\n",
    "        self.outputs = torch.from_numpy(df_[outputs].to_numpy()).float().to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item, label = self.inputs[idx], self.outputs[idx]\n",
    "\n",
    "        return item, label\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "batch_size = 800\n",
    "\n",
    "train_df, test_df = train_test_split(df_transformed, shuffle=True, test_size=0.3)\n",
    "\n",
    "train_dataset = SimpleDataset(train_df, inputs, outputs, device)\n",
    "test_dataset = SimpleDataset(test_df, inputs, outputs, device)\n",
    "full_dataset = SimpleDataset(df_transformed, inputs, outputs, device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "full_dataset_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, layers_dims, act_str_list, output_dim):\n",
    "        super().__init__()\n",
    "        layers_count = len(layers_dims)\n",
    "        assert layers_count > 0\n",
    "\n",
    "        module_list = []\n",
    "        for i in range(layers_count - 1):\n",
    "            module_list.append(nn.Linear(layers_dims[i], layers_dims[i + 1]))\n",
    "        module_list.append(nn.Linear(layers_dims[layers_count - 1], output_dim))\n",
    "\n",
    "        activations_list = []\n",
    "        for i in range(layers_count):\n",
    "            activations_list.append(activations[act_str_list[i]])\n",
    "\n",
    "        self.linears = nn.ModuleList(module_list)\n",
    "        self.activations = nn.ModuleList(activations_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "\n",
    "        for lin, act in zip(self.linears, self.activations):\n",
    "            y = lin(y)\n",
    "            y = act(y)\n",
    "\n",
    "        return y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "layers_dims = [len(inputs),30, 100, 700, 100, 30, len(outputs)]\n",
    "layers_count = len(layers_dims)\n",
    "activations_string_list = ['relu' for i in range(layers_count)]\n",
    "\n",
    "linear_model = LinearModel(layers_dims, activations_string_list, len(outputs)).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "learning_rate = 0.00002\n",
    "epoch_count = 100\n",
    "\n",
    "optimizer = torch.optim.Adam(linear_model.parameters(), lr=learning_rate)\n",
    "loss_function = nn.L1Loss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; train loss=0.390849; validation loss=0.397681\n",
      "Epoch: 1; train loss=0.390386; validation loss=0.397749\n",
      "Epoch: 2; train loss=0.389500; validation loss=0.396882\n",
      "Epoch: 3; train loss=0.388498; validation loss=0.396713\n",
      "Epoch: 4; train loss=0.389062; validation loss=0.396343\n",
      "Epoch: 5; train loss=0.388428; validation loss=0.397178\n",
      "Epoch: 6; train loss=0.389557; validation loss=0.395607\n",
      "Epoch: 7; train loss=0.387528; validation loss=0.395835\n",
      "Epoch: 8; train loss=0.388444; validation loss=0.395786\n",
      "Epoch: 9; train loss=0.388304; validation loss=0.395390\n",
      "Epoch: 10; train loss=0.386128; validation loss=0.395439\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m epoch_validation \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m      2\u001B[0m train_loss_threshold \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.00025\u001B[39m\n\u001B[1;32m----> 4\u001B[0m train_loss_list, validation_loss_list \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch_count\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlinear_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_function\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loss_threshold\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m plot_loss(train_loss_list, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain loss\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\GitHub\\GraduateProd\\1D_2L_chart\\baseline\\torch_lib.py:306\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(epoch_count, model, optimizer, loss_function, train_loader, test_loader, epoch_validation, train_loss_threshold)\u001B[0m\n\u001B[0;32m    303\u001B[0m validation_loss_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m()\n\u001B[0;32m    305\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch_count \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epoch_count):\n\u001B[1;32m--> 306\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_function\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    307\u001B[0m     train_loss_list\u001B[38;5;241m.\u001B[39mappend(train_loss)\n\u001B[0;32m    309\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m epoch_validation:\n",
      "File \u001B[1;32mC:\\GitHub\\GraduateProd\\1D_2L_chart\\baseline\\torch_lib.py:260\u001B[0m, in \u001B[0;36mtrain_loop\u001B[1;34m(dataloader, model, loss_fn, optimizer)\u001B[0m\n\u001B[0;32m    256\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m    258\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m--> 260\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, (X, y) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dataloader):\n\u001B[0;32m    261\u001B[0m     epoch_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m train_step(X, y)\n\u001B[0;32m    263\u001B[0m epoch_loss \u001B[38;5;241m=\u001B[39m epoch_loss \u001B[38;5;241m/\u001B[39m num_batches \u001B[38;5;66;03m# get average loss\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Python\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mC:\\Python\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    672\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    673\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 674\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    675\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    676\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mC:\\Python\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mC:\\Python\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Cell \u001B[1;32mIn[21], line 10\u001B[0m, in \u001B[0;36mSimpleDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__len__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minputs)\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[0;32m     11\u001B[0m     item, label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minputs[idx], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutputs[idx]\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m item, label\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "epoch_validation = True\n",
    "train_loss_threshold = 0.00025\n",
    "\n",
    "train_loss_list, validation_loss_list = train_model(epoch_count, linear_model, optimizer, loss_function, train_loader, test_loader, True, train_loss_threshold)\n",
    "plot_loss(train_loss_list, \"train loss\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_loss = test_loop(test_loader, linear_model, loss_function)\n",
    "print(f\"test loss={test_loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss(validation_loss_list, \"test loss\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions, actual = predict(full_dataset_loader, linear_model, device)\n",
    "assert predictions.size() == actual.size()\n",
    "\n",
    "approximation_graphic = plot_tensor_approximation(actual, predictions, 'rok', 'lines+markers', 12000, 900)\n",
    "approximation_graphic.show()\n",
    "approximation_graphic.write_image(plots_dir + \"pytorch_linear_approximation.pdf\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Linear model final approximation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rok_attr_transformer.set_data_from_tensor(predictions)\n",
    "predictions = torch.tensor(rok_attr_transformer.transform_backward())\n",
    "\n",
    "rok_attr_transformer.set_data_from_tensor(actual)\n",
    "actual = torch.tensor(rok_attr_transformer.transform_backward())\n",
    "\n",
    "#actual = torch.tensor(df[outputs].to_numpy().flatten())\n",
    "\n",
    "approximation_graphic = plot_tensor_approximation(actual, predictions, 'rok', 'lines+markers', 12000, 900)\n",
    "approximation_graphic.show()\n",
    "approximation_graphic.write_image(plots_dir + \"pytorch_linear_approximation_real.pdf\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### plot subject graphic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rok_attr_transformer_dropped = copy.deepcopy(rok_attr_transformer)\n",
    "rok_attr_transformer_dropped.drop_transform(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subject_graphic_plotter = SubjectGraphicPlotter(df_transformed, linear_model, rok_attr_transformer_dropped, 'lambda', 'AO/d', inputs, 'rok')\n",
    "subject_graphic_plotter.set_single_dim(500, 400)\n",
    "subject_graphic = subject_graphic_plotter.plot_subject_graphic()\n",
    "subject_graphic.write_image(plots_dir + \"linear_subject_graphic.pdf\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### plot relative error"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mape = MeanAbsolutePercentageError()\n",
    "print(f\"mape={mape(predictions, actual)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plot_relative_error(actual, predictions, 0.05, 'linear relative error', 10000, 500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig.show('browser')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig.write_image(plots_dir + \"linear_relative_error.pdf\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linear_model.to(cpu)    # attach model to cpu before scripting and saving to prevent cuda meta information saved\n",
    "scripted_model = torch.jit.script(linear_model)\n",
    "model_name = models_dir + \"linear_\" + str(round(test_loss, 7)).replace('.', '_')\n",
    "\n",
    "scripted_model.save(model_name + \".pt\") # save torch script model which compatible with pytorch c++ api\n",
    "torch.save(linear_model, model_name + \".pth\")   # save model in python services specific format"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# order AO/d, lambda, ro_formation\n",
    "scripted_model(torch.tensor([0.6, 0.362372, 0.04]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "linear_model(torch.tensor([0.6, 0.362372, 0.04]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}