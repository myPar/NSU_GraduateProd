{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tools.torch_lib import *\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "from torchmetrics.regression import MeanAbsolutePercentageError"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "gpu = torch.device('cuda')\n",
    "cpu = torch.device('cpu')\n",
    "device = cpu\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = gpu\n",
    "    # The flag below controls whether to allow TF32 on matmul. This flag defaults to False\n",
    "    # in PyTorch 1.12 and later.\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    # The flag below controls whether to allow TF32 on cuDNN. This flag defaults to True.\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dataset_dir = \"dataset/\"\n",
    "dataset_file_name = \"pz_3L.csv\"\n",
    "plots_dir = \"plots/\"\n",
    "test_plots_dir = \"test_plots/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   ro_well  ro_formation  invasion_zone_h  invasion_zone_ro        PZ  r_well\n0     0.01           0.1              0.0               0.1  0.119657   0.040\n1     0.01           0.1              0.0               0.1  0.120473   0.042\n2     0.01           0.1              0.0               0.1  0.121212   0.044\n3     0.01           0.1              0.0               0.1  0.121874   0.046\n4     0.01           0.1              0.0               0.1  0.122460   0.048",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ro_well</th>\n      <th>ro_formation</th>\n      <th>invasion_zone_h</th>\n      <th>invasion_zone_ro</th>\n      <th>PZ</th>\n      <th>r_well</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.01</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>0.1</td>\n      <td>0.119657</td>\n      <td>0.040</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.01</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>0.1</td>\n      <td>0.120473</td>\n      <td>0.042</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.01</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>0.1</td>\n      <td>0.121212</td>\n      <td>0.044</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.01</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>0.1</td>\n      <td>0.121874</td>\n      <td>0.046</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.01</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>0.1</td>\n      <td>0.122460</td>\n      <td>0.048</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(dataset_dir + dataset_file_name)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['ro_well', 'ro_formation', 'invasion_zone_h', 'invasion_zone_ro', 'PZ',\n       'r_well'],\n      dtype='object')"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# print attribute's min max"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ro_well: min=0.01 max=1000.0\n",
      "ro_formation: min=0.1 max=10000.0\n",
      "invasion_zone_h: min=0.0 max=2.4\n",
      "invasion_zone_ro: min=0.1 max=10000.0\n",
      "PZ: min=0.0915816 max=15345.2\n",
      "r_well: min=0.04 max=0.2\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(f\"{column}: min={df[column].min()} max={df[column].max()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ro_well: min=-4.605170185988091 max=6.907755278982137\n",
      "ro_formation: min=-2.3025850929940455 max=9.210340371976184\n",
      "invasion_zone_h: min=-inf max=0.8754687373538999\n",
      "invasion_zone_ro: min=-2.3025850929940455 max=9.210340371976184\n",
      "PZ: min=-2.3905249008422538 max=9.63855800053032\n",
      "r_well: min=-3.2188758248682006 max=-1.6094379124341003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrey\\AppData\\Local\\Temp\\ipykernel_35560\\1465013420.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  print(f\"{column}: min={np.log(df[column].min())} max={np.log(df[column].max())}\")\n"
     ]
    }
   ],
   "source": [
    "# attributes in logarithmic scale:\n",
    "for column in df.columns:\n",
    "    if column == 'd_well':\n",
    "        continue\n",
    "    print(f\"{column}: min={np.log(df[column].min())} max={np.log(df[column].max())}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add dataframe transforms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "inputs = np.array(['ro_well', 'ro_formation', 'r_well', 'invasion_zone_h', 'invasion_zone_ro'])\n",
    "outputs = np.array(['PZ']) # 'A02M01N' dropped"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "          ro_well  ro_formation  invasion_zone_h  invasion_zone_ro        PZ  \\\n0             0.0           0.0              0.0               0.0  0.022229   \n1             0.0           0.0              0.0               0.0  0.022794   \n2             0.0           0.0              0.0               0.0  0.023303   \n3             0.0           0.0              0.0               0.0  0.023756   \n4             0.0           0.0              0.0               0.0  0.024154   \n...           ...           ...              ...               ...       ...   \n10881670      1.0           1.0              1.0               1.0  0.974364   \n10881671      1.0           1.0              1.0               1.0  0.972347   \n10881672      1.0           1.0              1.0               1.0  0.970280   \n10881673      1.0           1.0              1.0               1.0  0.965016   \n10881674      1.0           1.0              1.0               1.0  0.959768   \n\n           r_well  \n0         0.00000  \n1         0.01250  \n2         0.02500  \n3         0.03750  \n4         0.05000  \n...           ...  \n10881670  0.56250  \n10881671  0.62500  \n10881672  0.68750  \n10881673  0.84375  \n10881674  1.00000  \n\n[10881675 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ro_well</th>\n      <th>ro_formation</th>\n      <th>invasion_zone_h</th>\n      <th>invasion_zone_ro</th>\n      <th>PZ</th>\n      <th>r_well</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.022229</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.022794</td>\n      <td>0.01250</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.023303</td>\n      <td>0.02500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.023756</td>\n      <td>0.03750</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.024154</td>\n      <td>0.05000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10881670</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.974364</td>\n      <td>0.56250</td>\n    </tr>\n    <tr>\n      <th>10881671</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.972347</td>\n      <td>0.62500</td>\n    </tr>\n    <tr>\n      <th>10881672</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.970280</td>\n      <td>0.68750</td>\n    </tr>\n    <tr>\n      <th>10881673</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.965016</td>\n      <td>0.84375</td>\n    </tr>\n    <tr>\n      <th>10881674</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.959768</td>\n      <td>1.00000</td>\n    </tr>\n  </tbody>\n</table>\n<p>10881675 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logarithmic_columns = ['ro_formation', 'ro_well', 'invasion_zone_ro']\n",
    "# normalize data ('min/max' normalization):\n",
    "interval_th = [-1, 1]     # normalization interval for 'th' activation function\n",
    "interval_sigmoid = [0, 1] # normalization interval for 'sigmoid' activation function\n",
    "normalize_interval = interval_sigmoid\n",
    "\n",
    "attributes_transform_dict = {}\n",
    "df_transformed = df.copy()\n",
    "\n",
    "# transform output attributes:\n",
    "for output_attr in outputs:\n",
    "    attr_transformer = attributes_transform_dict[output_attr] = AttributeTransformer(df_transformed[output_attr].to_numpy())\n",
    "\n",
    "    # logarithmic transform\n",
    "    forward, backward = np.log, np.exp\n",
    "    df_transformed[output_attr] = attr_transformer.transform(forward, backward)\n",
    "    # scaling transform\n",
    "    #forward, backward = get_standard_scaler_transform(attr_transformer.data)\n",
    "    #df_transformed[output_attr] = attr_transformer.transform(forward, backward)\n",
    "    # # normalize transform\n",
    "    forward, backward = get_normalize_transforms(attr_transformer.data, normalize_interval)\n",
    "    df_transformed[output_attr] = attr_transformer.transform(forward, backward)\n",
    "\n",
    "# logarithm resistance:\n",
    "for col in logarithmic_columns:\n",
    "    if col in outputs:\n",
    "        continue\n",
    "    df_transformed[col] = df_transformed[col].apply(np.log)\n",
    "\n",
    "# add normalization\n",
    "for attribute in df_transformed.columns:\n",
    "    if attribute in outputs:\n",
    "        continue\n",
    "    transform, _ = get_normalize_transforms(df_transformed[attribute].to_numpy(), normalize_interval)\n",
    "    #transform, _ = get_standard_scaler_transform(df_transformed[attribute].to_numpy())  # use scaling instead of min-max norm\n",
    "    df_transformed[attribute] = transform(df_transformed[attribute].to_numpy())\n",
    "\n",
    "df_transformed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def print_inference_statistic(attributes, df_):\n",
    "    means = []\n",
    "    stds = []\n",
    "    mins = []\n",
    "    maxes = []\n",
    "\n",
    "    for column in attributes:\n",
    "        col_data = df_[column].to_numpy()\n",
    "\n",
    "        if column in logarithmic_columns or column in outputs:\n",
    "            col_data = np.log(col_data)  # first transform - log\n",
    "\n",
    "        # col_mean = np.mean(col_data)\n",
    "        # col_std = np.std(col_data)\n",
    "\n",
    "        # means.append(col_mean)\n",
    "        # stds.append(col_std)\n",
    "        #\n",
    "        # col_data = (col_data - col_mean) / col_std\n",
    "\n",
    "        mins.append(np.min(col_data))\n",
    "        maxes.append(np.max(col_data))\n",
    "\n",
    "    # print(f\"means={means}\")\n",
    "    # print(f\"stds={stds}\")\n",
    "    print(f\"mins={mins}\")\n",
    "    print(f\"maxes={maxes}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mins=[-4.605170185988091, -2.3025850929940455, 0.04, 0.0, -2.3025850929940455]\n",
      "maxes=[6.907755278982137, 9.210340371976184, 0.2, 2.4, 9.210340371976184]\n"
     ]
    }
   ],
   "source": [
    "print_inference_statistic(inputs, df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mins=[-2.3905249008422538]\n",
      "maxes=[9.63855800053032]\n"
     ]
    }
   ],
   "source": [
    "print_inference_statistic(outputs, df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build Datasets and create dataloaders"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, df_, inputs, outputs, device):\n",
    "        self.df = df_\n",
    "        self.inputs = torch.from_numpy(df_[inputs].to_numpy()).float().to(device)\n",
    "        self.outputs = torch.from_numpy(df_[outputs].to_numpy()).float().to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item, label = self.inputs[idx], self.outputs[idx]\n",
    "\n",
    "        return item, label\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "train_df, test_df = train_test_split(df_transformed, shuffle=True, test_size=0.3)\n",
    "test_df, validation_df = train_test_split(test_df, shuffle=True, test_size=0.33)\n",
    "\n",
    "train_dataset = SimpleDataset(train_df, inputs, outputs, device)\n",
    "test_dataset = SimpleDataset(test_df, inputs, outputs, device)\n",
    "validation_dataset = SimpleDataset(validation_df, inputs, outputs, device)\n",
    "full_dataset = SimpleDataset(df_transformed, inputs, outputs, device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\n",
    "full_dataset_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class WeightedMAE(nn.Module):\n",
    "    def __init__(self, weights):\n",
    "        super(WeightedMAE, self).__init__()\n",
    "        self.mae = nn.L1Loss()\n",
    "        self.weights = weights\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        weighted_inputs = inputs * self.weights\n",
    "\n",
    "        return self.mae(weighted_inputs, targets)\n",
    "\n",
    "    def to(self, device):\n",
    "        super().to(device)\n",
    "        self.weights = self.weights.to(device)\n",
    "\n",
    "\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, layers_dims, act_str_list, output_dim):\n",
    "        super().__init__()\n",
    "        layers_count = len(layers_dims)\n",
    "        assert layers_count > 0\n",
    "\n",
    "        module_list = []\n",
    "        for i in range(layers_count - 1):\n",
    "            module_list.append(nn.Linear(layers_dims[i], layers_dims[i + 1]))\n",
    "        module_list.append(nn.Linear(layers_dims[layers_count - 1], output_dim))\n",
    "\n",
    "        activations_list = []\n",
    "        for i in range(layers_count):\n",
    "            activations_list.append(activations[act_str_list[i]])\n",
    "\n",
    "        self.linears = nn.ModuleList(module_list)\n",
    "        self.activations = nn.ModuleList(activations_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "\n",
    "        for lin, act in zip(self.linears, self.activations):\n",
    "            y = lin(y)\n",
    "            y = act(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "# add batch normalization\n",
    "class LinearNormalizedModel(nn.Module):\n",
    "    def __init__(self, layers_dims, act_str_list, output_dim):\n",
    "        super().__init__()\n",
    "        layers_count = len(layers_dims)\n",
    "        assert layers_count > 0\n",
    "\n",
    "        linears_list = []\n",
    "        batch_norm_list = []\n",
    "\n",
    "        for i in range(layers_count - 1):\n",
    "            in_features, out_features = layers_dims[i], layers_dims[i + 1]\n",
    "            linears_list.append(nn.Linear(in_features, out_features))\n",
    "            batch_norm_list.append(nn.BatchNorm1d(out_features))\n",
    "\n",
    "        linears_list.append(nn.Linear(layers_dims[layers_count - 1], output_dim))\n",
    "        batch_norm_list.append(nn.BatchNorm1d(output_dim))\n",
    "\n",
    "        activations_list = []\n",
    "        for i in range(layers_count):\n",
    "            activations_list.append(activations[act_str_list[i]])\n",
    "\n",
    "        self.linears = nn.ModuleList(linears_list)\n",
    "        self.activations = nn.ModuleList(activations_list)\n",
    "        self.batch_normalizations = nn.ModuleList(batch_norm_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "\n",
    "        for lin, act, norm in zip(self.linears, self.activations, self.batch_normalizations):\n",
    "            y = lin(y)\n",
    "            y = norm(y)\n",
    "            y = act(y)\n",
    "\n",
    "        return y\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "LinearModel(\n  (linears): ModuleList(\n    (0): Linear(in_features=5, out_features=50, bias=True)\n    (1): Linear(in_features=50, out_features=120, bias=True)\n    (2): Linear(in_features=120, out_features=1200, bias=True)\n    (3): Linear(in_features=1200, out_features=120, bias=True)\n    (4): Linear(in_features=120, out_features=10, bias=True)\n    (5): Linear(in_features=10, out_features=1, bias=True)\n  )\n  (activations): ModuleList(\n    (0-5): 6 x LeakyReLU(negative_slope=0.01)\n  )\n)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers_dims = [len(inputs), 50, 120, 1200, 120, 10]\n",
    "layers_count = len(layers_dims)\n",
    "activations_string_list = ['leaky-relu' for i in range(layers_count)]\n",
    "#activations_string_list[-1] = 'sigmoid'\n",
    "\n",
    "linear_model = LinearModel(layers_dims, activations_string_list, len(outputs)).to(device)\n",
    "#linear_bn_model = LinearBNormModel(layers_dims, activations_string_list, len(outputs)).to(device)\n",
    "#linear_ln_model = LinearLNormModel(layers_dims, activations_string_list, len(outputs)).to(device)\n",
    "\n",
    "model = linear_model\n",
    "model_name = \"linear_model\"\n",
    "linear_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "epoch_count = 200\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#loss_function = WeightedMAE(torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0], dtype=float))\n",
    "loss_function = nn.L1Loss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0; train loss=0.010797; validation loss=0.003467\n",
      "Epoch: 1; train loss=0.002717; validation loss=0.001840\n",
      "Epoch: 2; train loss=0.002131; validation loss=0.001664\n",
      "Epoch: 3; train loss=0.002149; validation loss=0.001293\n",
      "Epoch: 4; train loss=0.001960; validation loss=0.002604\n",
      "Epoch: 5; train loss=0.001670; validation loss=0.003044\n",
      "Epoch: 6; train loss=0.001625; validation loss=0.001737\n",
      "Epoch: 7; train loss=0.001514; validation loss=0.001930\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m epoch_validation \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m      2\u001B[0m train_loss_threshold \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0003\u001B[39m\n\u001B[1;32m----> 4\u001B[0m train_loss_list, validation_loss_list \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch_count\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_function\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loss_threshold\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m plot_loss(train_loss_list, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain loss\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mC:\\GitHub\\NSU_Graduate\\NSU_Graduate\\Pytorch\\Local\\tools\\torch_lib.py:584\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(epoch_count, model, optimizer, loss_function, train_loader, test_loader, epoch_validation, train_loss_threshold)\u001B[0m\n\u001B[0;32m    581\u001B[0m validation_loss_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m()\n\u001B[0;32m    583\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch_count \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epoch_count):\n\u001B[1;32m--> 584\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_function\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    585\u001B[0m     train_loss_list\u001B[38;5;241m.\u001B[39mappend(train_loss)\n\u001B[0;32m    587\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m epoch_validation:\n",
      "File \u001B[1;32mC:\\GitHub\\NSU_Graduate\\NSU_Graduate\\Pytorch\\Local\\tools\\torch_lib.py:540\u001B[0m, in \u001B[0;36mtrain_loop\u001B[1;34m(dataloader, model, loss_fn, optimizer)\u001B[0m\n\u001B[0;32m    537\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m    539\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, (X, y) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(dataloader):\n\u001B[1;32m--> 540\u001B[0m     epoch_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    542\u001B[0m epoch_loss \u001B[38;5;241m=\u001B[39m epoch_loss \u001B[38;5;241m/\u001B[39m num_batches  \u001B[38;5;66;03m# get average loss\u001B[39;00m\n\u001B[0;32m    544\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m epoch_loss\n",
      "File \u001B[1;32mC:\\GitHub\\NSU_Graduate\\NSU_Graduate\\Pytorch\\Local\\tools\\torch_lib.py:534\u001B[0m, in \u001B[0;36mtrain_loop.<locals>.train_step\u001B[1;34m(X, y)\u001B[0m\n\u001B[0;32m    531\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(pred, y)\n\u001B[0;32m    533\u001B[0m \u001B[38;5;66;03m# Backpropagation\u001B[39;00m\n\u001B[1;32m--> 534\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    535\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m    537\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32mC:\\Python\\Lib\\site-packages\\torch\\_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    491\u001B[0m     )\n\u001B[1;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "epoch_validation = True\n",
    "train_loss_threshold = 0.0003\n",
    "\n",
    "train_loss_list, validation_loss_list = train_model(epoch_count, model, optimizer, loss_function, train_loader, validation_loader, True, train_loss_threshold)\n",
    "plot_loss(train_loss_list, \"train loss\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_loss = test_loop(test_loader, model, loss_function)\n",
    "print(f\"test loss={test_loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_loss(validation_loss_list, \"test loss\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for _, (X, y) in enumerate(train_loader):\n",
    "    print(model(X))\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot_predictions(outputs, full_dataset_loader, linear_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#plot_actual_predictions(outputs, full_inference_dataset_loader, linear_model, attributes_transform_dict, df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_relative_errors(outputs, full_dataset_loader, model, attributes_transform_dict,\n",
    "                     df, 0.01, device, plots_dir, mode='default+hist', bin_count=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot test predictions:\n",
    "plot_relative_errors(outputs, test_loader, model, attributes_transform_dict,\n",
    "                     df, 0.01, device, plots_dir + test_plots_dir, mode='default+hist', bin_count=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### check predictions manually"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictor = Predictor(full_dataset_loader, df, attributes_transform_dict, model, inputs, outputs)\n",
    "predictions_dict, actuals_dict = predictor.predict(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compare_prediction(idx: int, prediction_dict, actuals_dict, attribute):\n",
    "    predicted = prediction_dict[attribute][idx]\n",
    "    actual = actuals_dict[attribute][idx]\n",
    "    relative_error = abs(actual - predicted) / actual\n",
    "    print(f\"{idx}: predicted={predicted}; actual={actual}; relative error={relative_error}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.to(cpu)    # attach model to cpu before scripting and saving to prevent cuda meta information saved\n",
    "scripted_model = torch.jit.script(model)\n",
    "model_file_name = \"saved_models/\" + model_name + str(round(test_loss, 7)).replace('.', '_')\n",
    "\n",
    "scripted_model.save(model_file_name + \".pt\") # save torch script model which compatible with pytorch c++ api\n",
    "torch.save(model, model_file_name + \".pth\")   # save model in python services specific format\n",
    "\n",
    "# attach model back to device:\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scripted_model(torch.tensor([0.6, 0.362372, 0.04]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model(torch.tensor([0.6, 0.362372, 0.04], device=device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}